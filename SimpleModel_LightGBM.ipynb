{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "k1OAMPSL6YXc"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZRi3FU7f6C-"
      },
      "source": [
        "# if you have google drive permission then use this\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "!ln -s   /gdrive/MyDrive/colab/Credit_Card/data/ /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK3__xMg9RgV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "88f69f9e-2150-4312-e01e-bbfa6c02d1f9"
      },
      "source": [
        "!pip3 install gdown\n",
        "\n",
        "!mkdir -p ./data/\n",
        "import gdown\n",
        "\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=%s'%(\"1NZ8jMoqcCDpydHxWm6j415HwVS093l4U\")\n",
        "output = './data/X_sample.csv'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=%s'%(\"18w2LpyPbydD9qoVQ33GZI2LOjyRY2LaI\")\n",
        "output = './data/y_sample.csv'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=%s'%(\"1-0TD5rSfzG3frbgT4fseGBn-Dn5OpGKy\")\n",
        "output = './data/X_test.csv'\n",
        "gdown.download(url, output, quiet=False)\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=%s'%(\"1-1p1dHQVV2JnGP4eMfzJsQwErum_wuMG\")\n",
        "output = './data/y_test.csv'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1NZ8jMoqcCDpydHxWm6j415HwVS093l4U\n",
            "To: /content/data/X_sample.csv\n",
            "48.9MB [00:00, 224MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18w2LpyPbydD9qoVQ33GZI2LOjyRY2LaI\n",
            "To: /content/data/y_sample.csv\n",
            "100%|██████████| 288k/288k [00:00<00:00, 57.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-0TD5rSfzG3frbgT4fseGBn-Dn5OpGKy\n",
            "To: /content/data/X_test.csv\n",
            "609MB [00:02, 223MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-1p1dHQVV2JnGP4eMfzJsQwErum_wuMG\n",
            "To: /content/data/y_test.csv\n",
            "3.59MB [00:00, 110MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./data/y_test.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-9rZ_t1fvuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4ebc43-6284-4bfc-d7aa-fa59a63029ad"
      },
      "source": [
        "!pip3  install -U mlxtend\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mlxtend\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/30/781c0b962a70848db83339567ecab656638c62f05adb064cb33c0ae49244/mlxtend-0.18.0-py2.py3-none-any.whl (1.3MB)\n",
            "\r\u001b[K     |▎                               | 10kB 22.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 15.6MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 13.9MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 13.3MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51kB 7.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 7.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 8.1MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92kB 9.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102kB 7.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 7.4MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 7.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133kB 7.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143kB 7.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153kB 7.4MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 7.4MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174kB 7.4MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184kB 7.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194kB 7.4MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 215kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 225kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 256kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 276kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 296kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 327kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 337kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 389kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 430kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 440kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 450kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 481kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 491kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 501kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 542kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 552kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 563kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 593kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 604kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 614kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 645kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 655kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 665kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 696kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 706kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 727kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 768kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 778kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 788kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 808kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 819kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 829kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 839kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 860kB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 870kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 880kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 890kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 901kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 911kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 921kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 931kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 942kB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 952kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 962kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 972kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 983kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 993kB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.0MB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0MB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.0MB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.0MB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.0MB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1MB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1MB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1MB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.1MB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.1MB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1MB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.1MB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2MB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.2MB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2MB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.2MB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2MB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.2MB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3MB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.3MB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.3MB 7.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.3MB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.3MB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.3MB 7.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3MB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 7.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.13.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (3.2.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.24.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.1.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from mlxtend) (57.0.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.16.2 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from mlxtend) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.1)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.2->mlxtend) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend) (1.15.0)\n",
            "Installing collected packages: mlxtend\n",
            "  Found existing installation: mlxtend 0.14.0\n",
            "    Uninstalling mlxtend-0.14.0:\n",
            "      Successfully uninstalled mlxtend-0.14.0\n",
            "Successfully installed mlxtend-0.18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7I4duEii_Ee"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score , average_precision_score\n",
        "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve ,auc , log_loss ,  classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq41A0JuHzWs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fA_eepKf04-"
      },
      "source": [
        "df_X = pd.read_csv(\"./data/X_sample.csv\")\n",
        "df_X = df_X.set_index(\"txkey\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQoVsOdWh1eF"
      },
      "source": [
        "df_y = pd.read_csv(\"./data/y_sample.csv\")\n",
        "df_y = df_y.set_index(\"txkey\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ULh9oudgTHI"
      },
      "source": [
        "import lightgbm as lgb\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFSD8HVlgu2z"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_X_train, df_X_val = train_test_split(df_X, test_size=0.25, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "encqeBTZhtzr"
      },
      "source": [
        "df_y_train = df_y.loc[df_X_train.index]\n",
        "df_y_val = df_y.loc[df_X_val.index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drPz--UDINny"
      },
      "source": [
        "class FraudNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(367, 16)\n",
        "        self.fc2 = nn.Linear(16, 18)\n",
        "        self.fc3 = nn.Linear(18, 20)\n",
        "        self.fc4 = nn.Linear(20, 24)\n",
        "        self.fc5 = nn.Linear(24, 1)\n",
        "        self.bn1 = nn.BatchNorm1d(18)\n",
        "        self.bn2 = nn.BatchNorm1d(24)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.bn1(x)\n",
        "        x = F.dropout(x, p=0.3)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.bn2(x)\n",
        "        x = F.sigmoid(self.fc5(x))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8opOvNoIOMx"
      },
      "source": [
        "net = FraudNet().cuda()\n",
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "\n",
        "training_epochs = 100\n",
        "minibatch_size = 64\n",
        "\n",
        "train = data_utils.TensorDataset(torch.from_numpy(df_X_train.values).float(), torch.from_numpy(df_y_train.values).float())\n",
        "train_loader = data_utils.DataLoader(train, batch_size=minibatch_size, shuffle=True)\n",
        "\n",
        "val = data_utils.TensorDataset(torch.from_numpy(df_X_val.values).float(), torch.from_numpy(df_y_val.values).float())\n",
        "val_loader = data_utils.DataLoader(val, batch_size=minibatch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCpeGA6EJgfK",
        "outputId": "2116ca9b-0864-44b0-d484-0f33cffd5ef2"
      },
      "source": [
        "for i in range(training_epochs):\n",
        "    net.train()\n",
        "    for b, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        y_pred = net(inputs.cuda())\n",
        "        loss = loss_fn(y_pred, labels.cuda())\n",
        "\n",
        "        if b % 100:\n",
        "            print('Epochs: {}, batch: {} loss: {}'.format(i, b, loss))\n",
        "        #reset gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # update weights\n",
        "        optimizer.step()\n",
        "    net.eval()     # Optional when not using Model Specific layer\n",
        "    for b, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        y_pred = net(inputs.cuda())\n",
        "        loss = loss_fn(y_pred, labels.cuda())\n",
        "\n",
        "        if b % 100:\n",
        "            print('Epochs: {}, batch: {} loss: {}'.format(i, b, loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m串流輸出內容已截斷至最後 5000 行。\u001b[0m\n",
            "Epochs: 92, batch: 329 loss: 0.0960298404097557\n",
            "Epochs: 92, batch: 330 loss: 0.12502092123031616\n",
            "Epochs: 92, batch: 331 loss: 0.05947546288371086\n",
            "Epochs: 92, batch: 332 loss: 0.09243568778038025\n",
            "Epochs: 92, batch: 333 loss: 0.14318878948688507\n",
            "Epochs: 92, batch: 334 loss: 0.11521896719932556\n",
            "Epochs: 92, batch: 335 loss: 0.10843313485383987\n",
            "Epochs: 92, batch: 336 loss: 0.15774807333946228\n",
            "Epochs: 92, batch: 337 loss: 0.19337040185928345\n",
            "Epochs: 92, batch: 338 loss: 0.07710376381874084\n",
            "Epochs: 92, batch: 339 loss: 0.11568503081798553\n",
            "Epochs: 92, batch: 340 loss: 0.04466857388615608\n",
            "Epochs: 92, batch: 341 loss: 0.06719991564750671\n",
            "Epochs: 92, batch: 342 loss: 0.21048420667648315\n",
            "Epochs: 92, batch: 343 loss: 0.13139638304710388\n",
            "Epochs: 92, batch: 344 loss: 0.1016920655965805\n",
            "Epochs: 92, batch: 345 loss: 0.15208888053894043\n",
            "Epochs: 92, batch: 346 loss: 0.05821620672941208\n",
            "Epochs: 92, batch: 347 loss: 0.15355363488197327\n",
            "Epochs: 92, batch: 348 loss: 0.09142349660396576\n",
            "Epochs: 92, batch: 349 loss: 0.10927558690309525\n",
            "Epochs: 92, batch: 350 loss: 0.050624050199985504\n",
            "Epochs: 92, batch: 351 loss: 0.0742294117808342\n",
            "Epochs: 92, batch: 352 loss: 0.17812496423721313\n",
            "Epochs: 92, batch: 353 loss: 0.1359609067440033\n",
            "Epochs: 92, batch: 354 loss: 0.05373178794980049\n",
            "Epochs: 92, batch: 355 loss: 0.06856942176818848\n",
            "Epochs: 92, batch: 356 loss: 0.15021662414073944\n",
            "Epochs: 92, batch: 357 loss: 0.0733661949634552\n",
            "Epochs: 92, batch: 358 loss: 0.06271098554134369\n",
            "Epochs: 93, batch: 1 loss: 0.06125184893608093\n",
            "Epochs: 93, batch: 2 loss: 0.07101137936115265\n",
            "Epochs: 93, batch: 3 loss: 0.09731987118721008\n",
            "Epochs: 93, batch: 4 loss: 0.14884985983371735\n",
            "Epochs: 93, batch: 5 loss: 0.23005200922489166\n",
            "Epochs: 93, batch: 6 loss: 0.06851831078529358\n",
            "Epochs: 93, batch: 7 loss: 0.105464406311512\n",
            "Epochs: 93, batch: 8 loss: 0.24726322293281555\n",
            "Epochs: 93, batch: 9 loss: 0.12104040384292603\n",
            "Epochs: 93, batch: 10 loss: 0.05309388041496277\n",
            "Epochs: 93, batch: 11 loss: 0.04345639795064926\n",
            "Epochs: 93, batch: 12 loss: 0.18651531636714935\n",
            "Epochs: 93, batch: 13 loss: 0.08484923094511032\n",
            "Epochs: 93, batch: 14 loss: 0.12020611017942429\n",
            "Epochs: 93, batch: 15 loss: 0.13324344158172607\n",
            "Epochs: 93, batch: 16 loss: 0.1281893253326416\n",
            "Epochs: 93, batch: 17 loss: 0.04443700611591339\n",
            "Epochs: 93, batch: 18 loss: 0.06985853612422943\n",
            "Epochs: 93, batch: 19 loss: 0.16837674379348755\n",
            "Epochs: 93, batch: 20 loss: 0.10423073172569275\n",
            "Epochs: 93, batch: 21 loss: 0.10072513669729233\n",
            "Epochs: 93, batch: 22 loss: 0.10156659781932831\n",
            "Epochs: 93, batch: 23 loss: 0.0407290980219841\n",
            "Epochs: 93, batch: 24 loss: 0.02110840380191803\n",
            "Epochs: 93, batch: 25 loss: 0.12682229280471802\n",
            "Epochs: 93, batch: 26 loss: 0.13188788294792175\n",
            "Epochs: 93, batch: 27 loss: 0.13037599623203278\n",
            "Epochs: 93, batch: 28 loss: 0.11728931218385696\n",
            "Epochs: 93, batch: 29 loss: 0.13723090291023254\n",
            "Epochs: 93, batch: 30 loss: 0.10027855634689331\n",
            "Epochs: 93, batch: 31 loss: 0.0884590595960617\n",
            "Epochs: 93, batch: 32 loss: 0.13581109046936035\n",
            "Epochs: 93, batch: 33 loss: 0.08238618075847626\n",
            "Epochs: 93, batch: 34 loss: 0.20297883450984955\n",
            "Epochs: 93, batch: 35 loss: 0.3524004817008972\n",
            "Epochs: 93, batch: 36 loss: 0.1686086356639862\n",
            "Epochs: 93, batch: 37 loss: 0.1171559989452362\n",
            "Epochs: 93, batch: 38 loss: 0.05821726471185684\n",
            "Epochs: 93, batch: 39 loss: 0.12577706575393677\n",
            "Epochs: 93, batch: 40 loss: 0.1837831437587738\n",
            "Epochs: 93, batch: 41 loss: 0.09020273387432098\n",
            "Epochs: 93, batch: 42 loss: 0.05705039203166962\n",
            "Epochs: 93, batch: 43 loss: 0.03246244788169861\n",
            "Epochs: 93, batch: 44 loss: 0.13875599205493927\n",
            "Epochs: 93, batch: 45 loss: 0.02827727235853672\n",
            "Epochs: 93, batch: 46 loss: 0.09041116386651993\n",
            "Epochs: 93, batch: 47 loss: 0.09139417111873627\n",
            "Epochs: 93, batch: 48 loss: 0.0876728743314743\n",
            "Epochs: 93, batch: 49 loss: 0.1742762327194214\n",
            "Epochs: 93, batch: 50 loss: 0.07186072319746017\n",
            "Epochs: 93, batch: 51 loss: 0.11453697085380554\n",
            "Epochs: 93, batch: 52 loss: 0.12427806109189987\n",
            "Epochs: 93, batch: 53 loss: 0.03666245564818382\n",
            "Epochs: 93, batch: 54 loss: 0.09741786867380142\n",
            "Epochs: 93, batch: 55 loss: 0.03760765865445137\n",
            "Epochs: 93, batch: 56 loss: 0.06400875747203827\n",
            "Epochs: 93, batch: 57 loss: 0.15881472826004028\n",
            "Epochs: 93, batch: 58 loss: 0.10853689908981323\n",
            "Epochs: 93, batch: 59 loss: 0.10569915175437927\n",
            "Epochs: 93, batch: 60 loss: 0.0915892943739891\n",
            "Epochs: 93, batch: 61 loss: 0.26356613636016846\n",
            "Epochs: 93, batch: 62 loss: 0.17977336049079895\n",
            "Epochs: 93, batch: 63 loss: 0.08153228461742401\n",
            "Epochs: 93, batch: 64 loss: 0.048583224415779114\n",
            "Epochs: 93, batch: 65 loss: 0.24510960280895233\n",
            "Epochs: 93, batch: 66 loss: 0.13343997299671173\n",
            "Epochs: 93, batch: 67 loss: 0.2124377191066742\n",
            "Epochs: 93, batch: 68 loss: 0.05434685945510864\n",
            "Epochs: 93, batch: 69 loss: 0.09914793074131012\n",
            "Epochs: 93, batch: 70 loss: 0.14606548845767975\n",
            "Epochs: 93, batch: 71 loss: 0.10005488246679306\n",
            "Epochs: 93, batch: 72 loss: 0.2960830330848694\n",
            "Epochs: 93, batch: 73 loss: 0.14928805828094482\n",
            "Epochs: 93, batch: 74 loss: 0.04979025200009346\n",
            "Epochs: 93, batch: 75 loss: 0.09593363106250763\n",
            "Epochs: 93, batch: 76 loss: 0.06658155471086502\n",
            "Epochs: 93, batch: 77 loss: 0.18566501140594482\n",
            "Epochs: 93, batch: 78 loss: 0.11124364286661148\n",
            "Epochs: 93, batch: 79 loss: 0.10669438540935516\n",
            "Epochs: 93, batch: 80 loss: 0.1467626690864563\n",
            "Epochs: 93, batch: 81 loss: 0.10411819070577621\n",
            "Epochs: 93, batch: 82 loss: 0.07756312936544418\n",
            "Epochs: 93, batch: 83 loss: 0.23077929019927979\n",
            "Epochs: 93, batch: 84 loss: 0.09460412710905075\n",
            "Epochs: 93, batch: 85 loss: 0.08599072694778442\n",
            "Epochs: 93, batch: 86 loss: 0.08283352106809616\n",
            "Epochs: 93, batch: 87 loss: 0.11439381539821625\n",
            "Epochs: 93, batch: 88 loss: 0.06765204668045044\n",
            "Epochs: 93, batch: 89 loss: 0.028511738404631615\n",
            "Epochs: 93, batch: 90 loss: 0.03772667422890663\n",
            "Epochs: 93, batch: 91 loss: 0.1066913902759552\n",
            "Epochs: 93, batch: 92 loss: 0.15260860323905945\n",
            "Epochs: 93, batch: 93 loss: 0.06633513420820236\n",
            "Epochs: 93, batch: 94 loss: 0.16217957437038422\n",
            "Epochs: 93, batch: 95 loss: 0.03628842532634735\n",
            "Epochs: 93, batch: 96 loss: 0.07501469552516937\n",
            "Epochs: 93, batch: 97 loss: 0.13134711980819702\n",
            "Epochs: 93, batch: 98 loss: 0.24460750818252563\n",
            "Epochs: 93, batch: 99 loss: 0.22030547261238098\n",
            "Epochs: 93, batch: 101 loss: 0.042291849851608276\n",
            "Epochs: 93, batch: 102 loss: 0.09212768822908401\n",
            "Epochs: 93, batch: 103 loss: 0.15247510373592377\n",
            "Epochs: 93, batch: 104 loss: 0.05033344402909279\n",
            "Epochs: 93, batch: 105 loss: 0.03626778721809387\n",
            "Epochs: 93, batch: 106 loss: 0.03797276318073273\n",
            "Epochs: 93, batch: 107 loss: 0.20292893052101135\n",
            "Epochs: 93, batch: 108 loss: 0.22327952086925507\n",
            "Epochs: 93, batch: 109 loss: 0.19916361570358276\n",
            "Epochs: 93, batch: 110 loss: 0.1528259962797165\n",
            "Epochs: 93, batch: 111 loss: 0.14519870281219482\n",
            "Epochs: 93, batch: 112 loss: 0.14482590556144714\n",
            "Epochs: 93, batch: 113 loss: 0.11480166018009186\n",
            "Epochs: 93, batch: 114 loss: 0.10580261796712875\n",
            "Epochs: 93, batch: 115 loss: 0.07962522655725479\n",
            "Epochs: 93, batch: 116 loss: 0.08064455538988113\n",
            "Epochs: 93, batch: 117 loss: 0.20795442163944244\n",
            "Epochs: 93, batch: 118 loss: 0.16163961589336395\n",
            "Epochs: 93, batch: 119 loss: 0.17861545085906982\n",
            "Epochs: 93, batch: 120 loss: 0.10211897641420364\n",
            "Epochs: 93, batch: 121 loss: 0.055302105844020844\n",
            "Epochs: 93, batch: 122 loss: 0.28878358006477356\n",
            "Epochs: 93, batch: 123 loss: 0.1731804460287094\n",
            "Epochs: 93, batch: 124 loss: 0.20598241686820984\n",
            "Epochs: 93, batch: 125 loss: 0.1166955977678299\n",
            "Epochs: 93, batch: 126 loss: 0.10415652394294739\n",
            "Epochs: 93, batch: 127 loss: 0.1518261730670929\n",
            "Epochs: 93, batch: 128 loss: 0.08725617080926895\n",
            "Epochs: 93, batch: 129 loss: 0.07818186283111572\n",
            "Epochs: 93, batch: 130 loss: 0.0638175830245018\n",
            "Epochs: 93, batch: 131 loss: 0.12096540629863739\n",
            "Epochs: 93, batch: 132 loss: 0.1365804672241211\n",
            "Epochs: 93, batch: 133 loss: 0.07287970930337906\n",
            "Epochs: 93, batch: 134 loss: 0.2010360062122345\n",
            "Epochs: 93, batch: 135 loss: 0.25826895236968994\n",
            "Epochs: 93, batch: 136 loss: 0.12589068710803986\n",
            "Epochs: 93, batch: 137 loss: 0.15101467072963715\n",
            "Epochs: 93, batch: 138 loss: 0.051879797130823135\n",
            "Epochs: 93, batch: 139 loss: 0.1100631058216095\n",
            "Epochs: 93, batch: 140 loss: 0.18894994258880615\n",
            "Epochs: 93, batch: 141 loss: 0.1198405846953392\n",
            "Epochs: 93, batch: 142 loss: 0.1838248074054718\n",
            "Epochs: 93, batch: 143 loss: 0.09750203788280487\n",
            "Epochs: 93, batch: 144 loss: 0.0484757199883461\n",
            "Epochs: 93, batch: 145 loss: 0.05757153779268265\n",
            "Epochs: 93, batch: 146 loss: 0.06134481728076935\n",
            "Epochs: 93, batch: 147 loss: 0.09997591376304626\n",
            "Epochs: 93, batch: 148 loss: 0.06269323080778122\n",
            "Epochs: 93, batch: 149 loss: 0.05343867838382721\n",
            "Epochs: 93, batch: 150 loss: 0.1279975026845932\n",
            "Epochs: 93, batch: 151 loss: 0.196888729929924\n",
            "Epochs: 93, batch: 152 loss: 0.1311502456665039\n",
            "Epochs: 93, batch: 153 loss: 0.06745408475399017\n",
            "Epochs: 93, batch: 154 loss: 0.05831379070878029\n",
            "Epochs: 93, batch: 155 loss: 0.09178824722766876\n",
            "Epochs: 93, batch: 156 loss: 0.30098921060562134\n",
            "Epochs: 93, batch: 157 loss: 0.16766420006752014\n",
            "Epochs: 93, batch: 158 loss: 0.0912177711725235\n",
            "Epochs: 93, batch: 159 loss: 0.2271638959646225\n",
            "Epochs: 93, batch: 160 loss: 0.27838146686553955\n",
            "Epochs: 93, batch: 161 loss: 0.32391196489334106\n",
            "Epochs: 93, batch: 162 loss: 0.15366938710212708\n",
            "Epochs: 93, batch: 163 loss: 0.10628839582204819\n",
            "Epochs: 93, batch: 164 loss: 0.04278852790594101\n",
            "Epochs: 93, batch: 165 loss: 0.1839638650417328\n",
            "Epochs: 93, batch: 166 loss: 0.10098810493946075\n",
            "Epochs: 93, batch: 167 loss: 0.19828778505325317\n",
            "Epochs: 93, batch: 168 loss: 0.07777327299118042\n",
            "Epochs: 93, batch: 169 loss: 0.14580261707305908\n",
            "Epochs: 93, batch: 170 loss: 0.09048254042863846\n",
            "Epochs: 93, batch: 171 loss: 0.09452641010284424\n",
            "Epochs: 93, batch: 172 loss: 0.1692274808883667\n",
            "Epochs: 93, batch: 173 loss: 0.046450674533843994\n",
            "Epochs: 93, batch: 174 loss: 0.03932619094848633\n",
            "Epochs: 93, batch: 175 loss: 0.15686243772506714\n",
            "Epochs: 93, batch: 176 loss: 0.14992591738700867\n",
            "Epochs: 93, batch: 177 loss: 0.22615855932235718\n",
            "Epochs: 93, batch: 178 loss: 0.07848367840051651\n",
            "Epochs: 93, batch: 179 loss: 0.09363937377929688\n",
            "Epochs: 93, batch: 180 loss: 0.09569582343101501\n",
            "Epochs: 93, batch: 181 loss: 0.07237401604652405\n",
            "Epochs: 93, batch: 182 loss: 0.20371291041374207\n",
            "Epochs: 93, batch: 183 loss: 0.06204327568411827\n",
            "Epochs: 93, batch: 184 loss: 0.12230003625154495\n",
            "Epochs: 93, batch: 185 loss: 0.12812721729278564\n",
            "Epochs: 93, batch: 186 loss: 0.10706984996795654\n",
            "Epochs: 93, batch: 187 loss: 0.23524582386016846\n",
            "Epochs: 93, batch: 188 loss: 0.18429671227931976\n",
            "Epochs: 93, batch: 189 loss: 0.15037789940834045\n",
            "Epochs: 93, batch: 190 loss: 0.04803524166345596\n",
            "Epochs: 93, batch: 191 loss: 0.05240500345826149\n",
            "Epochs: 93, batch: 192 loss: 0.11178483068943024\n",
            "Epochs: 93, batch: 193 loss: 0.10806376487016678\n",
            "Epochs: 93, batch: 194 loss: 0.13181181252002716\n",
            "Epochs: 93, batch: 195 loss: 0.14259710907936096\n",
            "Epochs: 93, batch: 196 loss: 0.10170786082744598\n",
            "Epochs: 93, batch: 197 loss: 0.028183747082948685\n",
            "Epochs: 93, batch: 198 loss: 0.10614259541034698\n",
            "Epochs: 93, batch: 199 loss: 0.1609744131565094\n",
            "Epochs: 93, batch: 201 loss: 0.06492656469345093\n",
            "Epochs: 93, batch: 202 loss: 0.09245313704013824\n",
            "Epochs: 93, batch: 203 loss: 0.06998954713344574\n",
            "Epochs: 93, batch: 204 loss: 0.08453720062971115\n",
            "Epochs: 93, batch: 205 loss: 0.23401057720184326\n",
            "Epochs: 93, batch: 206 loss: 0.04200120270252228\n",
            "Epochs: 93, batch: 207 loss: 0.15960505604743958\n",
            "Epochs: 93, batch: 208 loss: 0.22416375577449799\n",
            "Epochs: 93, batch: 209 loss: 0.18405266106128693\n",
            "Epochs: 93, batch: 210 loss: 0.10584276914596558\n",
            "Epochs: 93, batch: 211 loss: 0.07047230005264282\n",
            "Epochs: 93, batch: 212 loss: 0.13210222125053406\n",
            "Epochs: 93, batch: 213 loss: 0.16468125581741333\n",
            "Epochs: 93, batch: 214 loss: 0.16757473349571228\n",
            "Epochs: 93, batch: 215 loss: 0.1306019127368927\n",
            "Epochs: 93, batch: 216 loss: 0.1454961895942688\n",
            "Epochs: 93, batch: 217 loss: 0.039431482553482056\n",
            "Epochs: 93, batch: 218 loss: 0.07404442131519318\n",
            "Epochs: 93, batch: 219 loss: 0.1710309386253357\n",
            "Epochs: 93, batch: 220 loss: 0.07261227071285248\n",
            "Epochs: 93, batch: 221 loss: 0.07387078553438187\n",
            "Epochs: 93, batch: 222 loss: 0.1575154960155487\n",
            "Epochs: 93, batch: 223 loss: 0.10796170681715012\n",
            "Epochs: 93, batch: 224 loss: 0.1847037672996521\n",
            "Epochs: 93, batch: 225 loss: 0.09316189587116241\n",
            "Epochs: 93, batch: 226 loss: 0.08810943365097046\n",
            "Epochs: 93, batch: 227 loss: 0.10489733517169952\n",
            "Epochs: 93, batch: 228 loss: 0.1695997714996338\n",
            "Epochs: 93, batch: 229 loss: 0.10418866574764252\n",
            "Epochs: 93, batch: 230 loss: 0.10907034575939178\n",
            "Epochs: 93, batch: 231 loss: 0.0707201212644577\n",
            "Epochs: 93, batch: 232 loss: 0.0525871105492115\n",
            "Epochs: 93, batch: 233 loss: 0.2921234965324402\n",
            "Epochs: 93, batch: 234 loss: 0.14421342313289642\n",
            "Epochs: 93, batch: 235 loss: 0.2536470592021942\n",
            "Epochs: 93, batch: 236 loss: 0.06004095822572708\n",
            "Epochs: 93, batch: 237 loss: 0.13864116370677948\n",
            "Epochs: 93, batch: 238 loss: 0.08550195395946503\n",
            "Epochs: 93, batch: 239 loss: 0.04854352027177811\n",
            "Epochs: 93, batch: 240 loss: 0.08144555985927582\n",
            "Epochs: 93, batch: 241 loss: 0.1262596994638443\n",
            "Epochs: 93, batch: 242 loss: 0.1447712630033493\n",
            "Epochs: 93, batch: 243 loss: 0.11642660200595856\n",
            "Epochs: 93, batch: 244 loss: 0.12135647237300873\n",
            "Epochs: 93, batch: 245 loss: 0.04435041919350624\n",
            "Epochs: 93, batch: 246 loss: 0.10020610690116882\n",
            "Epochs: 93, batch: 247 loss: 0.13008682429790497\n",
            "Epochs: 93, batch: 248 loss: 0.23219233751296997\n",
            "Epochs: 93, batch: 249 loss: 0.20764364302158356\n",
            "Epochs: 93, batch: 250 loss: 0.14343255758285522\n",
            "Epochs: 93, batch: 251 loss: 0.09757103025913239\n",
            "Epochs: 93, batch: 252 loss: 0.05209137871861458\n",
            "Epochs: 93, batch: 253 loss: 0.08438991755247116\n",
            "Epochs: 93, batch: 254 loss: 0.045469772070646286\n",
            "Epochs: 93, batch: 255 loss: 0.1930759847164154\n",
            "Epochs: 93, batch: 256 loss: 0.08351579308509827\n",
            "Epochs: 93, batch: 257 loss: 0.0667068138718605\n",
            "Epochs: 93, batch: 258 loss: 0.07867494225502014\n",
            "Epochs: 93, batch: 259 loss: 0.1029932051897049\n",
            "Epochs: 93, batch: 260 loss: 0.26619476079940796\n",
            "Epochs: 93, batch: 261 loss: 0.1304914802312851\n",
            "Epochs: 93, batch: 262 loss: 0.1464582234621048\n",
            "Epochs: 93, batch: 263 loss: 0.22113282978534698\n",
            "Epochs: 93, batch: 264 loss: 0.12547898292541504\n",
            "Epochs: 93, batch: 265 loss: 0.18865863978862762\n",
            "Epochs: 93, batch: 266 loss: 0.14385034143924713\n",
            "Epochs: 93, batch: 267 loss: 0.07509954273700714\n",
            "Epochs: 93, batch: 268 loss: 0.17980822920799255\n",
            "Epochs: 93, batch: 269 loss: 0.05438751354813576\n",
            "Epochs: 93, batch: 270 loss: 0.09931834787130356\n",
            "Epochs: 93, batch: 271 loss: 0.21079927682876587\n",
            "Epochs: 93, batch: 272 loss: 0.09198066592216492\n",
            "Epochs: 93, batch: 273 loss: 0.11275078356266022\n",
            "Epochs: 93, batch: 274 loss: 0.12297588586807251\n",
            "Epochs: 93, batch: 275 loss: 0.10183079540729523\n",
            "Epochs: 93, batch: 276 loss: 0.0899096429347992\n",
            "Epochs: 93, batch: 277 loss: 0.0865144357085228\n",
            "Epochs: 93, batch: 278 loss: 0.18636275827884674\n",
            "Epochs: 93, batch: 279 loss: 0.2112155556678772\n",
            "Epochs: 93, batch: 280 loss: 0.12293056398630142\n",
            "Epochs: 93, batch: 281 loss: 0.22386610507965088\n",
            "Epochs: 93, batch: 282 loss: 0.026606261730194092\n",
            "Epochs: 93, batch: 283 loss: 0.12909112870693207\n",
            "Epochs: 93, batch: 284 loss: 0.10927340388298035\n",
            "Epochs: 93, batch: 285 loss: 0.11286136507987976\n",
            "Epochs: 93, batch: 286 loss: 0.2812691926956177\n",
            "Epochs: 93, batch: 287 loss: 0.13100773096084595\n",
            "Epochs: 93, batch: 288 loss: 0.12587189674377441\n",
            "Epochs: 93, batch: 289 loss: 0.15984395146369934\n",
            "Epochs: 93, batch: 290 loss: 0.15827122330665588\n",
            "Epochs: 93, batch: 291 loss: 0.05466996133327484\n",
            "Epochs: 93, batch: 292 loss: 0.15213774144649506\n",
            "Epochs: 93, batch: 293 loss: 0.11565154790878296\n",
            "Epochs: 93, batch: 294 loss: 0.18134690821170807\n",
            "Epochs: 93, batch: 295 loss: 0.12273852527141571\n",
            "Epochs: 93, batch: 296 loss: 0.21246080100536346\n",
            "Epochs: 93, batch: 297 loss: 0.1440235674381256\n",
            "Epochs: 93, batch: 298 loss: 0.17338776588439941\n",
            "Epochs: 93, batch: 299 loss: 0.11058291792869568\n",
            "Epochs: 93, batch: 301 loss: 0.03779261186718941\n",
            "Epochs: 93, batch: 302 loss: 0.1952088475227356\n",
            "Epochs: 93, batch: 303 loss: 0.1563110649585724\n",
            "Epochs: 93, batch: 304 loss: 0.07418247312307358\n",
            "Epochs: 93, batch: 305 loss: 0.11955173313617706\n",
            "Epochs: 93, batch: 306 loss: 0.08988264948129654\n",
            "Epochs: 93, batch: 307 loss: 0.20411740243434906\n",
            "Epochs: 93, batch: 308 loss: 0.07462915033102036\n",
            "Epochs: 93, batch: 309 loss: 0.10394259542226791\n",
            "Epochs: 93, batch: 310 loss: 0.1776905357837677\n",
            "Epochs: 93, batch: 311 loss: 0.048978179693222046\n",
            "Epochs: 93, batch: 312 loss: 0.0817943885922432\n",
            "Epochs: 93, batch: 313 loss: 0.13215798139572144\n",
            "Epochs: 93, batch: 314 loss: 0.08730844408273697\n",
            "Epochs: 93, batch: 315 loss: 0.08119527995586395\n",
            "Epochs: 93, batch: 316 loss: 0.08170470595359802\n",
            "Epochs: 93, batch: 317 loss: 0.06755239516496658\n",
            "Epochs: 93, batch: 318 loss: 0.08673599362373352\n",
            "Epochs: 93, batch: 319 loss: 0.2196626365184784\n",
            "Epochs: 93, batch: 320 loss: 0.12849818170070648\n",
            "Epochs: 93, batch: 321 loss: 0.07703454792499542\n",
            "Epochs: 93, batch: 322 loss: 0.12623989582061768\n",
            "Epochs: 93, batch: 323 loss: 0.06693554669618607\n",
            "Epochs: 93, batch: 324 loss: 0.1091994196176529\n",
            "Epochs: 93, batch: 325 loss: 0.1135399267077446\n",
            "Epochs: 93, batch: 326 loss: 0.11452190577983856\n",
            "Epochs: 93, batch: 327 loss: 0.05605786293745041\n",
            "Epochs: 93, batch: 328 loss: 0.17397001385688782\n",
            "Epochs: 93, batch: 329 loss: 0.14817941188812256\n",
            "Epochs: 93, batch: 330 loss: 0.08371886610984802\n",
            "Epochs: 93, batch: 331 loss: 0.06399263441562653\n",
            "Epochs: 93, batch: 332 loss: 0.08631660044193268\n",
            "Epochs: 93, batch: 333 loss: 0.2234688401222229\n",
            "Epochs: 93, batch: 334 loss: 0.06624971330165863\n",
            "Epochs: 93, batch: 335 loss: 0.11148819327354431\n",
            "Epochs: 93, batch: 336 loss: 0.19544130563735962\n",
            "Epochs: 93, batch: 337 loss: 0.22042608261108398\n",
            "Epochs: 93, batch: 338 loss: 0.1796531081199646\n",
            "Epochs: 93, batch: 339 loss: 0.15490560233592987\n",
            "Epochs: 93, batch: 340 loss: 0.18319039046764374\n",
            "Epochs: 93, batch: 341 loss: 0.13402271270751953\n",
            "Epochs: 93, batch: 342 loss: 0.15560808777809143\n",
            "Epochs: 93, batch: 343 loss: 0.15607815980911255\n",
            "Epochs: 93, batch: 344 loss: 0.13218115270137787\n",
            "Epochs: 93, batch: 345 loss: 0.16614368557929993\n",
            "Epochs: 93, batch: 346 loss: 0.07164150476455688\n",
            "Epochs: 93, batch: 347 loss: 0.080903060734272\n",
            "Epochs: 93, batch: 348 loss: 0.22132208943367004\n",
            "Epochs: 93, batch: 349 loss: 0.10383862257003784\n",
            "Epochs: 93, batch: 350 loss: 0.09719973057508469\n",
            "Epochs: 93, batch: 351 loss: 0.06866103410720825\n",
            "Epochs: 93, batch: 352 loss: 0.11886543780565262\n",
            "Epochs: 93, batch: 353 loss: 0.07628673315048218\n",
            "Epochs: 93, batch: 354 loss: 0.14110352098941803\n",
            "Epochs: 93, batch: 355 loss: 0.13292303681373596\n",
            "Epochs: 93, batch: 356 loss: 0.1218024343252182\n",
            "Epochs: 93, batch: 357 loss: 0.1355915367603302\n",
            "Epochs: 93, batch: 358 loss: 0.0692400112748146\n",
            "Epochs: 93, batch: 1 loss: 0.13413351774215698\n",
            "Epochs: 93, batch: 2 loss: 0.1706600934267044\n",
            "Epochs: 93, batch: 3 loss: 0.025447813794016838\n",
            "Epochs: 93, batch: 4 loss: 0.07882048189640045\n",
            "Epochs: 93, batch: 5 loss: 0.13892613351345062\n",
            "Epochs: 93, batch: 6 loss: 0.05333414673805237\n",
            "Epochs: 93, batch: 7 loss: 0.08497171103954315\n",
            "Epochs: 93, batch: 8 loss: 0.06097789481282234\n",
            "Epochs: 93, batch: 9 loss: 0.06485302746295929\n",
            "Epochs: 93, batch: 10 loss: 0.12582482397556305\n",
            "Epochs: 93, batch: 11 loss: 0.12342369556427002\n",
            "Epochs: 93, batch: 12 loss: 0.1186923161149025\n",
            "Epochs: 93, batch: 13 loss: 0.12485559284687042\n",
            "Epochs: 93, batch: 14 loss: 0.09450998902320862\n",
            "Epochs: 93, batch: 15 loss: 0.14167067408561707\n",
            "Epochs: 93, batch: 16 loss: 0.09222721308469772\n",
            "Epochs: 93, batch: 17 loss: 0.08242790400981903\n",
            "Epochs: 93, batch: 18 loss: 0.04323556646704674\n",
            "Epochs: 93, batch: 19 loss: 0.14649233222007751\n",
            "Epochs: 93, batch: 20 loss: 0.26410168409347534\n",
            "Epochs: 93, batch: 21 loss: 0.27629607915878296\n",
            "Epochs: 93, batch: 22 loss: 0.269069105386734\n",
            "Epochs: 93, batch: 23 loss: 0.09404757618904114\n",
            "Epochs: 93, batch: 24 loss: 0.0933387279510498\n",
            "Epochs: 93, batch: 25 loss: 0.18481101095676422\n",
            "Epochs: 93, batch: 26 loss: 0.04656089097261429\n",
            "Epochs: 93, batch: 27 loss: 0.09930954873561859\n",
            "Epochs: 93, batch: 28 loss: 0.06748181581497192\n",
            "Epochs: 93, batch: 29 loss: 0.06007968634366989\n",
            "Epochs: 93, batch: 30 loss: 0.061186667531728745\n",
            "Epochs: 93, batch: 31 loss: 0.08154459297657013\n",
            "Epochs: 93, batch: 32 loss: 0.21049918234348297\n",
            "Epochs: 93, batch: 33 loss: 0.10517805814743042\n",
            "Epochs: 93, batch: 34 loss: 0.10598010569810867\n",
            "Epochs: 93, batch: 35 loss: 0.11485382914543152\n",
            "Epochs: 93, batch: 36 loss: 0.1788640320301056\n",
            "Epochs: 93, batch: 37 loss: 0.08366888016462326\n",
            "Epochs: 93, batch: 38 loss: 0.16809168457984924\n",
            "Epochs: 93, batch: 39 loss: 0.19133126735687256\n",
            "Epochs: 93, batch: 40 loss: 0.05286632478237152\n",
            "Epochs: 93, batch: 41 loss: 0.10835889726877213\n",
            "Epochs: 93, batch: 42 loss: 0.185922309756279\n",
            "Epochs: 93, batch: 43 loss: 0.07164016366004944\n",
            "Epochs: 93, batch: 44 loss: 0.0679478645324707\n",
            "Epochs: 93, batch: 45 loss: 0.23411080241203308\n",
            "Epochs: 93, batch: 46 loss: 0.14036336541175842\n",
            "Epochs: 93, batch: 47 loss: 0.1272779405117035\n",
            "Epochs: 93, batch: 48 loss: 0.19430968165397644\n",
            "Epochs: 93, batch: 49 loss: 0.12957139313220978\n",
            "Epochs: 93, batch: 50 loss: 0.07503373920917511\n",
            "Epochs: 93, batch: 51 loss: 0.12686090171337128\n",
            "Epochs: 93, batch: 52 loss: 0.17621837556362152\n",
            "Epochs: 93, batch: 53 loss: 0.14184412360191345\n",
            "Epochs: 93, batch: 54 loss: 0.22672218084335327\n",
            "Epochs: 93, batch: 55 loss: 0.111698679625988\n",
            "Epochs: 93, batch: 56 loss: 0.04806087166070938\n",
            "Epochs: 93, batch: 57 loss: 0.06802508980035782\n",
            "Epochs: 93, batch: 58 loss: 0.04554809257388115\n",
            "Epochs: 93, batch: 59 loss: 0.14105334877967834\n",
            "Epochs: 93, batch: 60 loss: 0.150599867105484\n",
            "Epochs: 93, batch: 61 loss: 0.06387537717819214\n",
            "Epochs: 93, batch: 62 loss: 0.04063405096530914\n",
            "Epochs: 93, batch: 63 loss: 0.10656863451004028\n",
            "Epochs: 93, batch: 64 loss: 0.2121824026107788\n",
            "Epochs: 93, batch: 65 loss: 0.09998612105846405\n",
            "Epochs: 93, batch: 66 loss: 0.045735619962215424\n",
            "Epochs: 93, batch: 67 loss: 0.05690130218863487\n",
            "Epochs: 93, batch: 68 loss: 0.11591757088899612\n",
            "Epochs: 93, batch: 69 loss: 0.09527315199375153\n",
            "Epochs: 93, batch: 70 loss: 0.2044098675251007\n",
            "Epochs: 93, batch: 71 loss: 0.17000016570091248\n",
            "Epochs: 93, batch: 72 loss: 0.18776489794254303\n",
            "Epochs: 93, batch: 73 loss: 0.07695004343986511\n",
            "Epochs: 93, batch: 74 loss: 0.0838652104139328\n",
            "Epochs: 93, batch: 75 loss: 0.0515817329287529\n",
            "Epochs: 93, batch: 76 loss: 0.17213097214698792\n",
            "Epochs: 93, batch: 77 loss: 0.07912587374448776\n",
            "Epochs: 93, batch: 78 loss: 0.2681065499782562\n",
            "Epochs: 93, batch: 79 loss: 0.10755304992198944\n",
            "Epochs: 93, batch: 80 loss: 0.16368448734283447\n",
            "Epochs: 93, batch: 81 loss: 0.05998889356851578\n",
            "Epochs: 93, batch: 82 loss: 0.1427733302116394\n",
            "Epochs: 93, batch: 83 loss: 0.16603821516036987\n",
            "Epochs: 93, batch: 84 loss: 0.18884676694869995\n",
            "Epochs: 93, batch: 85 loss: 0.18500298261642456\n",
            "Epochs: 93, batch: 86 loss: 0.15888766944408417\n",
            "Epochs: 93, batch: 87 loss: 0.050669293850660324\n",
            "Epochs: 93, batch: 88 loss: 0.10793515294790268\n",
            "Epochs: 93, batch: 89 loss: 0.08070544898509979\n",
            "Epochs: 93, batch: 90 loss: 0.147502601146698\n",
            "Epochs: 93, batch: 91 loss: 0.09910456836223602\n",
            "Epochs: 93, batch: 92 loss: 0.11193208396434784\n",
            "Epochs: 93, batch: 93 loss: 0.1060669869184494\n",
            "Epochs: 93, batch: 94 loss: 0.08673827350139618\n",
            "Epochs: 93, batch: 95 loss: 0.12254107743501663\n",
            "Epochs: 93, batch: 96 loss: 0.08790906518697739\n",
            "Epochs: 93, batch: 97 loss: 0.13578778505325317\n",
            "Epochs: 93, batch: 98 loss: 0.1479264199733734\n",
            "Epochs: 93, batch: 99 loss: 0.20398184657096863\n",
            "Epochs: 93, batch: 101 loss: 0.03533346951007843\n",
            "Epochs: 93, batch: 102 loss: 0.06387705355882645\n",
            "Epochs: 93, batch: 103 loss: 0.0794384628534317\n",
            "Epochs: 93, batch: 104 loss: 0.1148006021976471\n",
            "Epochs: 93, batch: 105 loss: 0.06862212717533112\n",
            "Epochs: 93, batch: 106 loss: 0.11332134902477264\n",
            "Epochs: 93, batch: 107 loss: 0.31509652733802795\n",
            "Epochs: 93, batch: 108 loss: 0.06332479417324066\n",
            "Epochs: 93, batch: 109 loss: 0.057949699461460114\n",
            "Epochs: 93, batch: 110 loss: 0.1593037098646164\n",
            "Epochs: 93, batch: 111 loss: 0.07128353416919708\n",
            "Epochs: 93, batch: 112 loss: 0.2266317903995514\n",
            "Epochs: 93, batch: 113 loss: 0.10639920830726624\n",
            "Epochs: 93, batch: 114 loss: 0.07127779722213745\n",
            "Epochs: 93, batch: 115 loss: 0.10382597893476486\n",
            "Epochs: 93, batch: 116 loss: 0.048840899020433426\n",
            "Epochs: 93, batch: 117 loss: 0.06415189802646637\n",
            "Epochs: 93, batch: 118 loss: 0.11323723196983337\n",
            "Epochs: 93, batch: 119 loss: 0.21634185314178467\n",
            "Epochs: 93, batch: 120 loss: 0.17753545939922333\n",
            "Epochs: 93, batch: 121 loss: 0.12570634484291077\n",
            "Epochs: 93, batch: 122 loss: 0.1477247178554535\n",
            "Epochs: 93, batch: 123 loss: 0.2737598717212677\n",
            "Epochs: 93, batch: 124 loss: 0.0351111926138401\n",
            "Epochs: 93, batch: 125 loss: 0.17046645283699036\n",
            "Epochs: 93, batch: 126 loss: 0.1807902306318283\n",
            "Epochs: 93, batch: 127 loss: 0.07054121792316437\n",
            "Epochs: 93, batch: 128 loss: 0.11075432598590851\n",
            "Epochs: 93, batch: 129 loss: 0.06256374716758728\n",
            "Epochs: 93, batch: 130 loss: 0.13757500052452087\n",
            "Epochs: 93, batch: 131 loss: 0.135833740234375\n",
            "Epochs: 93, batch: 132 loss: 0.2593028247356415\n",
            "Epochs: 93, batch: 133 loss: 0.22236347198486328\n",
            "Epochs: 93, batch: 134 loss: 0.10559089481830597\n",
            "Epochs: 93, batch: 135 loss: 0.06953773647546768\n",
            "Epochs: 93, batch: 136 loss: 0.1326063573360443\n",
            "Epochs: 93, batch: 137 loss: 0.11448957026004791\n",
            "Epochs: 93, batch: 138 loss: 0.09679722785949707\n",
            "Epochs: 93, batch: 139 loss: 0.2805401086807251\n",
            "Epochs: 93, batch: 140 loss: 0.034965500235557556\n",
            "Epochs: 93, batch: 141 loss: 0.17221257090568542\n",
            "Epochs: 93, batch: 142 loss: 0.10487887263298035\n",
            "Epochs: 93, batch: 143 loss: 0.04642327129840851\n",
            "Epochs: 93, batch: 144 loss: 0.05206739529967308\n",
            "Epochs: 93, batch: 145 loss: 0.2543473243713379\n",
            "Epochs: 93, batch: 146 loss: 0.17527714371681213\n",
            "Epochs: 93, batch: 147 loss: 0.06378690898418427\n",
            "Epochs: 93, batch: 148 loss: 0.20007967948913574\n",
            "Epochs: 93, batch: 149 loss: 0.06418365240097046\n",
            "Epochs: 93, batch: 150 loss: 0.14834831655025482\n",
            "Epochs: 93, batch: 151 loss: 0.08173979818820953\n",
            "Epochs: 93, batch: 152 loss: 0.13674141466617584\n",
            "Epochs: 93, batch: 153 loss: 0.23259451985359192\n",
            "Epochs: 93, batch: 154 loss: 0.07259218394756317\n",
            "Epochs: 93, batch: 155 loss: 0.06580419838428497\n",
            "Epochs: 93, batch: 156 loss: 0.07797214388847351\n",
            "Epochs: 93, batch: 157 loss: 0.19574400782585144\n",
            "Epochs: 93, batch: 158 loss: 0.07040120661258698\n",
            "Epochs: 93, batch: 159 loss: 0.1856488585472107\n",
            "Epochs: 93, batch: 160 loss: 0.14569950103759766\n",
            "Epochs: 93, batch: 161 loss: 0.1368914544582367\n",
            "Epochs: 93, batch: 162 loss: 0.12688928842544556\n",
            "Epochs: 93, batch: 163 loss: 0.12069419771432877\n",
            "Epochs: 93, batch: 164 loss: 0.04198604077100754\n",
            "Epochs: 93, batch: 165 loss: 0.0790385901927948\n",
            "Epochs: 93, batch: 166 loss: 0.27110180258750916\n",
            "Epochs: 93, batch: 167 loss: 0.06479623913764954\n",
            "Epochs: 93, batch: 168 loss: 0.1239394098520279\n",
            "Epochs: 93, batch: 169 loss: 0.17341500520706177\n",
            "Epochs: 93, batch: 170 loss: 0.055685967206954956\n",
            "Epochs: 93, batch: 171 loss: 0.10476866364479065\n",
            "Epochs: 93, batch: 172 loss: 0.20032411813735962\n",
            "Epochs: 93, batch: 173 loss: 0.05634266510605812\n",
            "Epochs: 93, batch: 174 loss: 0.07276728004217148\n",
            "Epochs: 93, batch: 175 loss: 0.04880514740943909\n",
            "Epochs: 93, batch: 176 loss: 0.045331284403800964\n",
            "Epochs: 93, batch: 177 loss: 0.09757978469133377\n",
            "Epochs: 93, batch: 178 loss: 0.21026316285133362\n",
            "Epochs: 93, batch: 179 loss: 0.058884840458631516\n",
            "Epochs: 93, batch: 180 loss: 0.06112293154001236\n",
            "Epochs: 93, batch: 181 loss: 0.12996496260166168\n",
            "Epochs: 93, batch: 182 loss: 0.15837028622627258\n",
            "Epochs: 93, batch: 183 loss: 0.04231604188680649\n",
            "Epochs: 93, batch: 184 loss: 0.04722157493233681\n",
            "Epochs: 93, batch: 185 loss: 0.07252651453018188\n",
            "Epochs: 93, batch: 186 loss: 0.18292450904846191\n",
            "Epochs: 93, batch: 187 loss: 0.08673040568828583\n",
            "Epochs: 93, batch: 188 loss: 0.1104820966720581\n",
            "Epochs: 93, batch: 189 loss: 0.07835898548364639\n",
            "Epochs: 93, batch: 190 loss: 0.059566427022218704\n",
            "Epochs: 93, batch: 191 loss: 0.2338646948337555\n",
            "Epochs: 93, batch: 192 loss: 0.049987997859716415\n",
            "Epochs: 93, batch: 193 loss: 0.16699036955833435\n",
            "Epochs: 93, batch: 194 loss: 0.06698505580425262\n",
            "Epochs: 93, batch: 195 loss: 0.22672459483146667\n",
            "Epochs: 93, batch: 196 loss: 0.03302259370684624\n",
            "Epochs: 93, batch: 197 loss: 0.09878533333539963\n",
            "Epochs: 93, batch: 198 loss: 0.10619458556175232\n",
            "Epochs: 93, batch: 199 loss: 0.07286696135997772\n",
            "Epochs: 93, batch: 201 loss: 0.1508413702249527\n",
            "Epochs: 93, batch: 202 loss: 0.2813374996185303\n",
            "Epochs: 93, batch: 203 loss: 0.1591455489397049\n",
            "Epochs: 93, batch: 204 loss: 0.13335029780864716\n",
            "Epochs: 93, batch: 205 loss: 0.14977136254310608\n",
            "Epochs: 93, batch: 206 loss: 0.2473236322402954\n",
            "Epochs: 93, batch: 207 loss: 0.07152338325977325\n",
            "Epochs: 93, batch: 208 loss: 0.05921357870101929\n",
            "Epochs: 93, batch: 209 loss: 0.07310406863689423\n",
            "Epochs: 93, batch: 210 loss: 0.10217592120170593\n",
            "Epochs: 93, batch: 211 loss: 0.12547840178012848\n",
            "Epochs: 93, batch: 212 loss: 0.11035799235105515\n",
            "Epochs: 93, batch: 213 loss: 0.07321762293577194\n",
            "Epochs: 93, batch: 214 loss: 0.17913199961185455\n",
            "Epochs: 93, batch: 215 loss: 0.15908338129520416\n",
            "Epochs: 93, batch: 216 loss: 0.06942015886306763\n",
            "Epochs: 93, batch: 217 loss: 0.054731082171201706\n",
            "Epochs: 93, batch: 218 loss: 0.11230489611625671\n",
            "Epochs: 93, batch: 219 loss: 0.0880139172077179\n",
            "Epochs: 93, batch: 220 loss: 0.13140983879566193\n",
            "Epochs: 93, batch: 221 loss: 0.06546029448509216\n",
            "Epochs: 93, batch: 222 loss: 0.1458870768547058\n",
            "Epochs: 93, batch: 223 loss: 0.06724390387535095\n",
            "Epochs: 93, batch: 224 loss: 0.0810696929693222\n",
            "Epochs: 93, batch: 225 loss: 0.08110962063074112\n",
            "Epochs: 93, batch: 226 loss: 0.09507668018341064\n",
            "Epochs: 93, batch: 227 loss: 0.12406755238771439\n",
            "Epochs: 93, batch: 228 loss: 0.17496192455291748\n",
            "Epochs: 93, batch: 229 loss: 0.11027765274047852\n",
            "Epochs: 93, batch: 230 loss: 0.14739885926246643\n",
            "Epochs: 93, batch: 231 loss: 0.07652349025011063\n",
            "Epochs: 93, batch: 232 loss: 0.11558709293603897\n",
            "Epochs: 93, batch: 233 loss: 0.1394423544406891\n",
            "Epochs: 93, batch: 234 loss: 0.052968740463256836\n",
            "Epochs: 93, batch: 235 loss: 0.2136010080575943\n",
            "Epochs: 93, batch: 236 loss: 0.09825287759304047\n",
            "Epochs: 93, batch: 237 loss: 0.13607683777809143\n",
            "Epochs: 93, batch: 238 loss: 0.07455384731292725\n",
            "Epochs: 93, batch: 239 loss: 0.05311209335923195\n",
            "Epochs: 93, batch: 240 loss: 0.03198336064815521\n",
            "Epochs: 93, batch: 241 loss: 0.05951281264424324\n",
            "Epochs: 93, batch: 242 loss: 0.14426520466804504\n",
            "Epochs: 93, batch: 243 loss: 0.10557860136032104\n",
            "Epochs: 93, batch: 244 loss: 0.04029933363199234\n",
            "Epochs: 93, batch: 245 loss: 0.0940692350268364\n",
            "Epochs: 93, batch: 246 loss: 0.11850803345441818\n",
            "Epochs: 93, batch: 247 loss: 0.11124928295612335\n",
            "Epochs: 93, batch: 248 loss: 0.06964783370494843\n",
            "Epochs: 93, batch: 249 loss: 0.12030526995658875\n",
            "Epochs: 93, batch: 250 loss: 0.05452021211385727\n",
            "Epochs: 93, batch: 251 loss: 0.08526081591844559\n",
            "Epochs: 93, batch: 252 loss: 0.10013607144355774\n",
            "Epochs: 93, batch: 253 loss: 0.20388540625572205\n",
            "Epochs: 93, batch: 254 loss: 0.054089486598968506\n",
            "Epochs: 93, batch: 255 loss: 0.10018756985664368\n",
            "Epochs: 93, batch: 256 loss: 0.17585131525993347\n",
            "Epochs: 93, batch: 257 loss: 0.1445302665233612\n",
            "Epochs: 93, batch: 258 loss: 0.05780312418937683\n",
            "Epochs: 93, batch: 259 loss: 0.0841895341873169\n",
            "Epochs: 93, batch: 260 loss: 0.1270555704832077\n",
            "Epochs: 93, batch: 261 loss: 0.10581304132938385\n",
            "Epochs: 93, batch: 262 loss: 0.05888534337282181\n",
            "Epochs: 93, batch: 263 loss: 0.13277089595794678\n",
            "Epochs: 93, batch: 264 loss: 0.2767511010169983\n",
            "Epochs: 93, batch: 265 loss: 0.04801562801003456\n",
            "Epochs: 93, batch: 266 loss: 0.0857144221663475\n",
            "Epochs: 93, batch: 267 loss: 0.12693865597248077\n",
            "Epochs: 93, batch: 268 loss: 0.13156414031982422\n",
            "Epochs: 93, batch: 269 loss: 0.037631209939718246\n",
            "Epochs: 93, batch: 270 loss: 0.07353416830301285\n",
            "Epochs: 93, batch: 271 loss: 0.2640537619590759\n",
            "Epochs: 93, batch: 272 loss: 0.15201818943023682\n",
            "Epochs: 93, batch: 273 loss: 0.10289888083934784\n",
            "Epochs: 93, batch: 274 loss: 0.04810437560081482\n",
            "Epochs: 93, batch: 275 loss: 0.12840069830417633\n",
            "Epochs: 93, batch: 276 loss: 0.08601866662502289\n",
            "Epochs: 93, batch: 277 loss: 0.07407038658857346\n",
            "Epochs: 93, batch: 278 loss: 0.1481046974658966\n",
            "Epochs: 93, batch: 279 loss: 0.06682043522596359\n",
            "Epochs: 93, batch: 280 loss: 0.054659273475408554\n",
            "Epochs: 93, batch: 281 loss: 0.09668196737766266\n",
            "Epochs: 93, batch: 282 loss: 0.15247689187526703\n",
            "Epochs: 93, batch: 283 loss: 0.08002637326717377\n",
            "Epochs: 93, batch: 284 loss: 0.1354285180568695\n",
            "Epochs: 93, batch: 285 loss: 0.10514429956674576\n",
            "Epochs: 93, batch: 286 loss: 0.09003308415412903\n",
            "Epochs: 93, batch: 287 loss: 0.24897900223731995\n",
            "Epochs: 93, batch: 288 loss: 0.06500257551670074\n",
            "Epochs: 93, batch: 289 loss: 0.14746060967445374\n",
            "Epochs: 93, batch: 290 loss: 0.11524461209774017\n",
            "Epochs: 93, batch: 291 loss: 0.12061955034732819\n",
            "Epochs: 93, batch: 292 loss: 0.12061519920825958\n",
            "Epochs: 93, batch: 293 loss: 0.19619548320770264\n",
            "Epochs: 93, batch: 294 loss: 0.07850992679595947\n",
            "Epochs: 93, batch: 295 loss: 0.0780525952577591\n",
            "Epochs: 93, batch: 296 loss: 0.21129600703716278\n",
            "Epochs: 93, batch: 297 loss: 0.0969109982252121\n",
            "Epochs: 93, batch: 298 loss: 0.05491364002227783\n",
            "Epochs: 93, batch: 299 loss: 0.09713111072778702\n",
            "Epochs: 93, batch: 301 loss: 0.06624011695384979\n",
            "Epochs: 93, batch: 302 loss: 0.12110212445259094\n",
            "Epochs: 93, batch: 303 loss: 0.07102568447589874\n",
            "Epochs: 93, batch: 304 loss: 0.15483763813972473\n",
            "Epochs: 93, batch: 305 loss: 0.14900659024715424\n",
            "Epochs: 93, batch: 306 loss: 0.07463555783033371\n",
            "Epochs: 93, batch: 307 loss: 0.06158813089132309\n",
            "Epochs: 93, batch: 308 loss: 0.1880948841571808\n",
            "Epochs: 93, batch: 309 loss: 0.16412866115570068\n",
            "Epochs: 93, batch: 310 loss: 0.05936311557888985\n",
            "Epochs: 93, batch: 311 loss: 0.09608042985200882\n",
            "Epochs: 93, batch: 312 loss: 0.14402571320533752\n",
            "Epochs: 93, batch: 313 loss: 0.14196407794952393\n",
            "Epochs: 93, batch: 314 loss: 0.12050467729568481\n",
            "Epochs: 93, batch: 315 loss: 0.07866420596837997\n",
            "Epochs: 93, batch: 316 loss: 0.05843773111701012\n",
            "Epochs: 93, batch: 317 loss: 0.26194578409194946\n",
            "Epochs: 93, batch: 318 loss: 0.10887501388788223\n",
            "Epochs: 93, batch: 319 loss: 0.13433989882469177\n",
            "Epochs: 93, batch: 320 loss: 0.27315399050712585\n",
            "Epochs: 93, batch: 321 loss: 0.1465712934732437\n",
            "Epochs: 93, batch: 322 loss: 0.18771925568580627\n",
            "Epochs: 93, batch: 323 loss: 0.0721079483628273\n",
            "Epochs: 93, batch: 324 loss: 0.08202897012233734\n",
            "Epochs: 93, batch: 325 loss: 0.05813903361558914\n",
            "Epochs: 93, batch: 326 loss: 0.07230788469314575\n",
            "Epochs: 93, batch: 327 loss: 0.16287678480148315\n",
            "Epochs: 93, batch: 328 loss: 0.0579996183514595\n",
            "Epochs: 93, batch: 329 loss: 0.08953586220741272\n",
            "Epochs: 93, batch: 330 loss: 0.06969503313302994\n",
            "Epochs: 93, batch: 331 loss: 0.1556917130947113\n",
            "Epochs: 93, batch: 332 loss: 0.22570720314979553\n",
            "Epochs: 93, batch: 333 loss: 0.12061648070812225\n",
            "Epochs: 93, batch: 334 loss: 0.08252954483032227\n",
            "Epochs: 93, batch: 335 loss: 0.17453017830848694\n",
            "Epochs: 93, batch: 336 loss: 0.09714816510677338\n",
            "Epochs: 93, batch: 337 loss: 0.08584132045507431\n",
            "Epochs: 93, batch: 338 loss: 0.10290223360061646\n",
            "Epochs: 93, batch: 339 loss: 0.07359188050031662\n",
            "Epochs: 93, batch: 340 loss: 0.09115041792392731\n",
            "Epochs: 93, batch: 341 loss: 0.13991433382034302\n",
            "Epochs: 93, batch: 342 loss: 0.06956794857978821\n",
            "Epochs: 93, batch: 343 loss: 0.11853481829166412\n",
            "Epochs: 93, batch: 344 loss: 0.1383948028087616\n",
            "Epochs: 93, batch: 345 loss: 0.18375465273857117\n",
            "Epochs: 93, batch: 346 loss: 0.26519399881362915\n",
            "Epochs: 93, batch: 347 loss: 0.10415623337030411\n",
            "Epochs: 93, batch: 348 loss: 0.06479640305042267\n",
            "Epochs: 93, batch: 349 loss: 0.20659196376800537\n",
            "Epochs: 93, batch: 350 loss: 0.2411154955625534\n",
            "Epochs: 93, batch: 351 loss: 0.09989993274211884\n",
            "Epochs: 93, batch: 352 loss: 0.15640373528003693\n",
            "Epochs: 93, batch: 353 loss: 0.052383020520210266\n",
            "Epochs: 93, batch: 354 loss: 0.08063825964927673\n",
            "Epochs: 93, batch: 355 loss: 0.031081393361091614\n",
            "Epochs: 93, batch: 356 loss: 0.14695948362350464\n",
            "Epochs: 93, batch: 357 loss: 0.17159593105316162\n",
            "Epochs: 93, batch: 358 loss: 0.2577550411224365\n",
            "Epochs: 94, batch: 1 loss: 0.08241917192935944\n",
            "Epochs: 94, batch: 2 loss: 0.1171899139881134\n",
            "Epochs: 94, batch: 3 loss: 0.09069996327161789\n",
            "Epochs: 94, batch: 4 loss: 0.1125769168138504\n",
            "Epochs: 94, batch: 5 loss: 0.2840235233306885\n",
            "Epochs: 94, batch: 6 loss: 0.14717447757720947\n",
            "Epochs: 94, batch: 7 loss: 0.024694010615348816\n",
            "Epochs: 94, batch: 8 loss: 0.17334645986557007\n",
            "Epochs: 94, batch: 9 loss: 0.19379417598247528\n",
            "Epochs: 94, batch: 10 loss: 0.14157117903232574\n",
            "Epochs: 94, batch: 11 loss: 0.10451991856098175\n",
            "Epochs: 94, batch: 12 loss: 0.08010724186897278\n",
            "Epochs: 94, batch: 13 loss: 0.16864468157291412\n",
            "Epochs: 94, batch: 14 loss: 0.16850262880325317\n",
            "Epochs: 94, batch: 15 loss: 0.22675833106040955\n",
            "Epochs: 94, batch: 16 loss: 0.14850355684757233\n",
            "Epochs: 94, batch: 17 loss: 0.11424657702445984\n",
            "Epochs: 94, batch: 18 loss: 0.061987005174160004\n",
            "Epochs: 94, batch: 19 loss: 0.04299624264240265\n",
            "Epochs: 94, batch: 20 loss: 0.08743347227573395\n",
            "Epochs: 94, batch: 21 loss: 0.07701823860406876\n",
            "Epochs: 94, batch: 22 loss: 0.055141255259513855\n",
            "Epochs: 94, batch: 23 loss: 0.1587504893541336\n",
            "Epochs: 94, batch: 24 loss: 0.20378756523132324\n",
            "Epochs: 94, batch: 25 loss: 0.20206482708454132\n",
            "Epochs: 94, batch: 26 loss: 0.18442736566066742\n",
            "Epochs: 94, batch: 27 loss: 0.0772712305188179\n",
            "Epochs: 94, batch: 28 loss: 0.08165100961923599\n",
            "Epochs: 94, batch: 29 loss: 0.09659036993980408\n",
            "Epochs: 94, batch: 30 loss: 0.15828529000282288\n",
            "Epochs: 94, batch: 31 loss: 0.16603529453277588\n",
            "Epochs: 94, batch: 32 loss: 0.13878659904003143\n",
            "Epochs: 94, batch: 33 loss: 0.06342276930809021\n",
            "Epochs: 94, batch: 34 loss: 0.13832028210163116\n",
            "Epochs: 94, batch: 35 loss: 0.09920832514762878\n",
            "Epochs: 94, batch: 36 loss: 0.07035313546657562\n",
            "Epochs: 94, batch: 37 loss: 0.1169569194316864\n",
            "Epochs: 94, batch: 38 loss: 0.10350373387336731\n",
            "Epochs: 94, batch: 39 loss: 0.1645960509777069\n",
            "Epochs: 94, batch: 40 loss: 0.1869177222251892\n",
            "Epochs: 94, batch: 41 loss: 0.05931343138217926\n",
            "Epochs: 94, batch: 42 loss: 0.06785738468170166\n",
            "Epochs: 94, batch: 43 loss: 0.1525067687034607\n",
            "Epochs: 94, batch: 44 loss: 0.08830365538597107\n",
            "Epochs: 94, batch: 45 loss: 0.14564967155456543\n",
            "Epochs: 94, batch: 46 loss: 0.08175220340490341\n",
            "Epochs: 94, batch: 47 loss: 0.14954039454460144\n",
            "Epochs: 94, batch: 48 loss: 0.1261354684829712\n",
            "Epochs: 94, batch: 49 loss: 0.031341951340436935\n",
            "Epochs: 94, batch: 50 loss: 0.07387882471084595\n",
            "Epochs: 94, batch: 51 loss: 0.2628936767578125\n",
            "Epochs: 94, batch: 52 loss: 0.1105542853474617\n",
            "Epochs: 94, batch: 53 loss: 0.13463956117630005\n",
            "Epochs: 94, batch: 54 loss: 0.1275034248828888\n",
            "Epochs: 94, batch: 55 loss: 0.09283571690320969\n",
            "Epochs: 94, batch: 56 loss: 0.18441590666770935\n",
            "Epochs: 94, batch: 57 loss: 0.14672192931175232\n",
            "Epochs: 94, batch: 58 loss: 0.08368770033121109\n",
            "Epochs: 94, batch: 59 loss: 0.0581577830016613\n",
            "Epochs: 94, batch: 60 loss: 0.10079095512628555\n",
            "Epochs: 94, batch: 61 loss: 0.1737707257270813\n",
            "Epochs: 94, batch: 62 loss: 0.25279849767684937\n",
            "Epochs: 94, batch: 63 loss: 0.20375385880470276\n",
            "Epochs: 94, batch: 64 loss: 0.06878313422203064\n",
            "Epochs: 94, batch: 65 loss: 0.20607581734657288\n",
            "Epochs: 94, batch: 66 loss: 0.04114123061299324\n",
            "Epochs: 94, batch: 67 loss: 0.07331947982311249\n",
            "Epochs: 94, batch: 68 loss: 0.1335492879152298\n",
            "Epochs: 94, batch: 69 loss: 0.11570402979850769\n",
            "Epochs: 94, batch: 70 loss: 0.033726006746292114\n",
            "Epochs: 94, batch: 71 loss: 0.03732163459062576\n",
            "Epochs: 94, batch: 72 loss: 0.2819667458534241\n",
            "Epochs: 94, batch: 73 loss: 0.13014771044254303\n",
            "Epochs: 94, batch: 74 loss: 0.11747415363788605\n",
            "Epochs: 94, batch: 75 loss: 0.06828446686267853\n",
            "Epochs: 94, batch: 76 loss: 0.06826828420162201\n",
            "Epochs: 94, batch: 77 loss: 0.05712350085377693\n",
            "Epochs: 94, batch: 78 loss: 0.11210143566131592\n",
            "Epochs: 94, batch: 79 loss: 0.096208855509758\n",
            "Epochs: 94, batch: 80 loss: 0.09102948755025864\n",
            "Epochs: 94, batch: 81 loss: 0.10510993748903275\n",
            "Epochs: 94, batch: 82 loss: 0.19427448511123657\n",
            "Epochs: 94, batch: 83 loss: 0.13003554940223694\n",
            "Epochs: 94, batch: 84 loss: 0.0950867086648941\n",
            "Epochs: 94, batch: 85 loss: 0.06876061856746674\n",
            "Epochs: 94, batch: 86 loss: 0.06767281144857407\n",
            "Epochs: 94, batch: 87 loss: 0.13083547353744507\n",
            "Epochs: 94, batch: 88 loss: 0.25759124755859375\n",
            "Epochs: 94, batch: 89 loss: 0.1583547443151474\n",
            "Epochs: 94, batch: 90 loss: 0.12074381113052368\n",
            "Epochs: 94, batch: 91 loss: 0.10363645851612091\n",
            "Epochs: 94, batch: 92 loss: 0.07192903012037277\n",
            "Epochs: 94, batch: 93 loss: 0.15337465703487396\n",
            "Epochs: 94, batch: 94 loss: 0.13261619210243225\n",
            "Epochs: 94, batch: 95 loss: 0.12699554860591888\n",
            "Epochs: 94, batch: 96 loss: 0.20689719915390015\n",
            "Epochs: 94, batch: 97 loss: 0.12717294692993164\n",
            "Epochs: 94, batch: 98 loss: 0.25249040126800537\n",
            "Epochs: 94, batch: 99 loss: 0.14455704391002655\n",
            "Epochs: 94, batch: 101 loss: 0.1993769258260727\n",
            "Epochs: 94, batch: 102 loss: 0.09202292561531067\n",
            "Epochs: 94, batch: 103 loss: 0.14654728770256042\n",
            "Epochs: 94, batch: 104 loss: 0.07467660307884216\n",
            "Epochs: 94, batch: 105 loss: 0.11724980920553207\n",
            "Epochs: 94, batch: 106 loss: 0.1309436559677124\n",
            "Epochs: 94, batch: 107 loss: 0.14758838713169098\n",
            "Epochs: 94, batch: 108 loss: 0.07801952213048935\n",
            "Epochs: 94, batch: 109 loss: 0.2213539332151413\n",
            "Epochs: 94, batch: 110 loss: 0.10928680747747421\n",
            "Epochs: 94, batch: 111 loss: 0.042638931423425674\n",
            "Epochs: 94, batch: 112 loss: 0.11116375774145126\n",
            "Epochs: 94, batch: 113 loss: 0.12317727506160736\n",
            "Epochs: 94, batch: 114 loss: 0.2484651803970337\n",
            "Epochs: 94, batch: 115 loss: 0.1297902911901474\n",
            "Epochs: 94, batch: 116 loss: 0.12147706747055054\n",
            "Epochs: 94, batch: 117 loss: 0.05500343441963196\n",
            "Epochs: 94, batch: 118 loss: 0.1311497837305069\n",
            "Epochs: 94, batch: 119 loss: 0.04388006031513214\n",
            "Epochs: 94, batch: 120 loss: 0.1133909672498703\n",
            "Epochs: 94, batch: 121 loss: 0.149626687169075\n",
            "Epochs: 94, batch: 122 loss: 0.06761991232633591\n",
            "Epochs: 94, batch: 123 loss: 0.06703457981348038\n",
            "Epochs: 94, batch: 124 loss: 0.17829599976539612\n",
            "Epochs: 94, batch: 125 loss: 0.1772347390651703\n",
            "Epochs: 94, batch: 126 loss: 0.12386464327573776\n",
            "Epochs: 94, batch: 127 loss: 0.17245720326900482\n",
            "Epochs: 94, batch: 128 loss: 0.07451054453849792\n",
            "Epochs: 94, batch: 129 loss: 0.11283397674560547\n",
            "Epochs: 94, batch: 130 loss: 0.025732601061463356\n",
            "Epochs: 94, batch: 131 loss: 0.11824778467416763\n",
            "Epochs: 94, batch: 132 loss: 0.10181032866239548\n",
            "Epochs: 94, batch: 133 loss: 0.14886648952960968\n",
            "Epochs: 94, batch: 134 loss: 0.03654415160417557\n",
            "Epochs: 94, batch: 135 loss: 0.07906675338745117\n",
            "Epochs: 94, batch: 136 loss: 0.22613371908664703\n",
            "Epochs: 94, batch: 137 loss: 0.059473276138305664\n",
            "Epochs: 94, batch: 138 loss: 0.18637298047542572\n",
            "Epochs: 94, batch: 139 loss: 0.07735022902488708\n",
            "Epochs: 94, batch: 140 loss: 0.06923191249370575\n",
            "Epochs: 94, batch: 141 loss: 0.1246166080236435\n",
            "Epochs: 94, batch: 142 loss: 0.1624661087989807\n",
            "Epochs: 94, batch: 143 loss: 0.20470377802848816\n",
            "Epochs: 94, batch: 144 loss: 0.056276701390743256\n",
            "Epochs: 94, batch: 145 loss: 0.09943675249814987\n",
            "Epochs: 94, batch: 146 loss: 0.07501205056905746\n",
            "Epochs: 94, batch: 147 loss: 0.0708976462483406\n",
            "Epochs: 94, batch: 148 loss: 0.13815279304981232\n",
            "Epochs: 94, batch: 149 loss: 0.032313305884599686\n",
            "Epochs: 94, batch: 150 loss: 0.10119304805994034\n",
            "Epochs: 94, batch: 151 loss: 0.07933182269334793\n",
            "Epochs: 94, batch: 152 loss: 0.05877126753330231\n",
            "Epochs: 94, batch: 153 loss: 0.13037671148777008\n",
            "Epochs: 94, batch: 154 loss: 0.28649958968162537\n",
            "Epochs: 94, batch: 155 loss: 0.09153924137353897\n",
            "Epochs: 94, batch: 156 loss: 0.09365048259496689\n",
            "Epochs: 94, batch: 157 loss: 0.15526840090751648\n",
            "Epochs: 94, batch: 158 loss: 0.10575351864099503\n",
            "Epochs: 94, batch: 159 loss: 0.08849337697029114\n",
            "Epochs: 94, batch: 160 loss: 0.1684616357088089\n",
            "Epochs: 94, batch: 161 loss: 0.17711187899112701\n",
            "Epochs: 94, batch: 162 loss: 0.12175813317298889\n",
            "Epochs: 94, batch: 163 loss: 0.10489048063755035\n",
            "Epochs: 94, batch: 164 loss: 0.028961993753910065\n",
            "Epochs: 94, batch: 165 loss: 0.11576990783214569\n",
            "Epochs: 94, batch: 166 loss: 0.21713252365589142\n",
            "Epochs: 94, batch: 167 loss: 0.1498560905456543\n",
            "Epochs: 94, batch: 168 loss: 0.04883149266242981\n",
            "Epochs: 94, batch: 169 loss: 0.15750327706336975\n",
            "Epochs: 94, batch: 170 loss: 0.0804184228181839\n",
            "Epochs: 94, batch: 171 loss: 0.05846254900097847\n",
            "Epochs: 94, batch: 172 loss: 0.11548316478729248\n",
            "Epochs: 94, batch: 173 loss: 0.07042770087718964\n",
            "Epochs: 94, batch: 174 loss: 0.23223739862442017\n",
            "Epochs: 94, batch: 175 loss: 0.08488661050796509\n",
            "Epochs: 94, batch: 176 loss: 0.15353330969810486\n",
            "Epochs: 94, batch: 177 loss: 0.1385728120803833\n",
            "Epochs: 94, batch: 178 loss: 0.13423028588294983\n",
            "Epochs: 94, batch: 179 loss: 0.11028646677732468\n",
            "Epochs: 94, batch: 180 loss: 0.03500349819660187\n",
            "Epochs: 94, batch: 181 loss: 0.09657017141580582\n",
            "Epochs: 94, batch: 182 loss: 0.042021285742521286\n",
            "Epochs: 94, batch: 183 loss: 0.09300528466701508\n",
            "Epochs: 94, batch: 184 loss: 0.05917069688439369\n",
            "Epochs: 94, batch: 185 loss: 0.07233346253633499\n",
            "Epochs: 94, batch: 186 loss: 0.1461467295885086\n",
            "Epochs: 94, batch: 187 loss: 0.05752647668123245\n",
            "Epochs: 94, batch: 188 loss: 0.10843835771083832\n",
            "Epochs: 94, batch: 189 loss: 0.15238964557647705\n",
            "Epochs: 94, batch: 190 loss: 0.1247713565826416\n",
            "Epochs: 94, batch: 191 loss: 0.058226972818374634\n",
            "Epochs: 94, batch: 192 loss: 0.07662762701511383\n",
            "Epochs: 94, batch: 193 loss: 0.23699653148651123\n",
            "Epochs: 94, batch: 194 loss: 0.13792069256305695\n",
            "Epochs: 94, batch: 195 loss: 0.20828688144683838\n",
            "Epochs: 94, batch: 196 loss: 0.17949968576431274\n",
            "Epochs: 94, batch: 197 loss: 0.05716211721301079\n",
            "Epochs: 94, batch: 198 loss: 0.14129184186458588\n",
            "Epochs: 94, batch: 199 loss: 0.10944440960884094\n",
            "Epochs: 94, batch: 201 loss: 0.04983755573630333\n",
            "Epochs: 94, batch: 202 loss: 0.12736910581588745\n",
            "Epochs: 94, batch: 203 loss: 0.19055262207984924\n",
            "Epochs: 94, batch: 204 loss: 0.12591278553009033\n",
            "Epochs: 94, batch: 205 loss: 0.1670721471309662\n",
            "Epochs: 94, batch: 206 loss: 0.07863762974739075\n",
            "Epochs: 94, batch: 207 loss: 0.15987250208854675\n",
            "Epochs: 94, batch: 208 loss: 0.05254978686571121\n",
            "Epochs: 94, batch: 209 loss: 0.19098612666130066\n",
            "Epochs: 94, batch: 210 loss: 0.04763563349843025\n",
            "Epochs: 94, batch: 211 loss: 0.19250600039958954\n",
            "Epochs: 94, batch: 212 loss: 0.07842251658439636\n",
            "Epochs: 94, batch: 213 loss: 0.2360600233078003\n",
            "Epochs: 94, batch: 214 loss: 0.22402049601078033\n",
            "Epochs: 94, batch: 215 loss: 0.08761249482631683\n",
            "Epochs: 94, batch: 216 loss: 0.19494369626045227\n",
            "Epochs: 94, batch: 217 loss: 0.3397483229637146\n",
            "Epochs: 94, batch: 218 loss: 0.15282247960567474\n",
            "Epochs: 94, batch: 219 loss: 0.1235777959227562\n",
            "Epochs: 94, batch: 220 loss: 0.11368495970964432\n",
            "Epochs: 94, batch: 221 loss: 0.07024307548999786\n",
            "Epochs: 94, batch: 222 loss: 0.07586067914962769\n",
            "Epochs: 94, batch: 223 loss: 0.2253383994102478\n",
            "Epochs: 94, batch: 224 loss: 0.25850871205329895\n",
            "Epochs: 94, batch: 225 loss: 0.10153625905513763\n",
            "Epochs: 94, batch: 226 loss: 0.08081704378128052\n",
            "Epochs: 94, batch: 227 loss: 0.17195361852645874\n",
            "Epochs: 94, batch: 228 loss: 0.13295698165893555\n",
            "Epochs: 94, batch: 229 loss: 0.03183619678020477\n",
            "Epochs: 94, batch: 230 loss: 0.14884053170681\n",
            "Epochs: 94, batch: 231 loss: 0.10646232962608337\n",
            "Epochs: 94, batch: 232 loss: 0.07324891537427902\n",
            "Epochs: 94, batch: 233 loss: 0.20487231016159058\n",
            "Epochs: 94, batch: 234 loss: 0.07197816669940948\n",
            "Epochs: 94, batch: 235 loss: 0.08504433184862137\n",
            "Epochs: 94, batch: 236 loss: 0.2876059412956238\n",
            "Epochs: 94, batch: 237 loss: 0.17908409237861633\n",
            "Epochs: 94, batch: 238 loss: 0.05603768676519394\n",
            "Epochs: 94, batch: 239 loss: 0.17737531661987305\n",
            "Epochs: 94, batch: 240 loss: 0.1503828912973404\n",
            "Epochs: 94, batch: 241 loss: 0.14009828865528107\n",
            "Epochs: 94, batch: 242 loss: 0.1638369858264923\n",
            "Epochs: 94, batch: 243 loss: 0.06785470992326736\n",
            "Epochs: 94, batch: 244 loss: 0.04798891395330429\n",
            "Epochs: 94, batch: 245 loss: 0.10675163567066193\n",
            "Epochs: 94, batch: 246 loss: 0.16324204206466675\n",
            "Epochs: 94, batch: 247 loss: 0.06818996369838715\n",
            "Epochs: 94, batch: 248 loss: 0.10012778639793396\n",
            "Epochs: 94, batch: 249 loss: 0.1354072093963623\n",
            "Epochs: 94, batch: 250 loss: 0.16386917233467102\n",
            "Epochs: 94, batch: 251 loss: 0.08578522503376007\n",
            "Epochs: 94, batch: 252 loss: 0.2783147096633911\n",
            "Epochs: 94, batch: 253 loss: 0.09683986753225327\n",
            "Epochs: 94, batch: 254 loss: 0.1011141687631607\n",
            "Epochs: 94, batch: 255 loss: 0.05511651188135147\n",
            "Epochs: 94, batch: 256 loss: 0.08290879428386688\n",
            "Epochs: 94, batch: 257 loss: 0.16827097535133362\n",
            "Epochs: 94, batch: 258 loss: 0.08105280995368958\n",
            "Epochs: 94, batch: 259 loss: 0.1282343864440918\n",
            "Epochs: 94, batch: 260 loss: 0.05676424503326416\n",
            "Epochs: 94, batch: 261 loss: 0.060057416558265686\n",
            "Epochs: 94, batch: 262 loss: 0.3569420576095581\n",
            "Epochs: 94, batch: 263 loss: 0.045281656086444855\n",
            "Epochs: 94, batch: 264 loss: 0.2596208155155182\n",
            "Epochs: 94, batch: 265 loss: 0.01975860446691513\n",
            "Epochs: 94, batch: 266 loss: 0.11982068419456482\n",
            "Epochs: 94, batch: 267 loss: 0.07898668944835663\n",
            "Epochs: 94, batch: 268 loss: 0.1852872669696808\n",
            "Epochs: 94, batch: 269 loss: 0.11645100265741348\n",
            "Epochs: 94, batch: 270 loss: 0.20253118872642517\n",
            "Epochs: 94, batch: 271 loss: 0.19659096002578735\n",
            "Epochs: 94, batch: 272 loss: 0.10872381925582886\n",
            "Epochs: 94, batch: 273 loss: 0.04710446670651436\n",
            "Epochs: 94, batch: 274 loss: 0.06755141913890839\n",
            "Epochs: 94, batch: 275 loss: 0.09584856033325195\n",
            "Epochs: 94, batch: 276 loss: 0.23801186680793762\n",
            "Epochs: 94, batch: 277 loss: 0.12693797051906586\n",
            "Epochs: 94, batch: 278 loss: 0.18605917692184448\n",
            "Epochs: 94, batch: 279 loss: 0.1493990421295166\n",
            "Epochs: 94, batch: 280 loss: 0.047369781881570816\n",
            "Epochs: 94, batch: 281 loss: 0.1704232394695282\n",
            "Epochs: 94, batch: 282 loss: 0.13074739277362823\n",
            "Epochs: 94, batch: 283 loss: 0.10185776650905609\n",
            "Epochs: 94, batch: 284 loss: 0.23143944144248962\n",
            "Epochs: 94, batch: 285 loss: 0.11705736815929413\n",
            "Epochs: 94, batch: 286 loss: 0.11342230439186096\n",
            "Epochs: 94, batch: 287 loss: 0.10830413550138474\n",
            "Epochs: 94, batch: 288 loss: 0.20320844650268555\n",
            "Epochs: 94, batch: 289 loss: 0.1865798830986023\n",
            "Epochs: 94, batch: 290 loss: 0.19874873757362366\n",
            "Epochs: 94, batch: 291 loss: 0.12267614901065826\n",
            "Epochs: 94, batch: 292 loss: 0.06649889796972275\n",
            "Epochs: 94, batch: 293 loss: 0.03726987540721893\n",
            "Epochs: 94, batch: 294 loss: 0.17467397451400757\n",
            "Epochs: 94, batch: 295 loss: 0.12564809620380402\n",
            "Epochs: 94, batch: 296 loss: 0.04470208287239075\n",
            "Epochs: 94, batch: 297 loss: 0.1148996502161026\n",
            "Epochs: 94, batch: 298 loss: 0.09117215871810913\n",
            "Epochs: 94, batch: 299 loss: 0.17008863389492035\n",
            "Epochs: 94, batch: 301 loss: 0.3296106159687042\n",
            "Epochs: 94, batch: 302 loss: 0.22640998661518097\n",
            "Epochs: 94, batch: 303 loss: 0.19023624062538147\n",
            "Epochs: 94, batch: 304 loss: 0.12384966760873795\n",
            "Epochs: 94, batch: 305 loss: 0.22554613649845123\n",
            "Epochs: 94, batch: 306 loss: 0.089642733335495\n",
            "Epochs: 94, batch: 307 loss: 0.08269985020160675\n",
            "Epochs: 94, batch: 308 loss: 0.1702171266078949\n",
            "Epochs: 94, batch: 309 loss: 0.14084765315055847\n",
            "Epochs: 94, batch: 310 loss: 0.054905764758586884\n",
            "Epochs: 94, batch: 311 loss: 0.06302279978990555\n",
            "Epochs: 94, batch: 312 loss: 0.08813859522342682\n",
            "Epochs: 94, batch: 313 loss: 0.1918206363916397\n",
            "Epochs: 94, batch: 314 loss: 0.1635420322418213\n",
            "Epochs: 94, batch: 315 loss: 0.2878032922744751\n",
            "Epochs: 94, batch: 316 loss: 0.07291746139526367\n",
            "Epochs: 94, batch: 317 loss: 0.14252600073814392\n",
            "Epochs: 94, batch: 318 loss: 0.13216985762119293\n",
            "Epochs: 94, batch: 319 loss: 0.1947220265865326\n",
            "Epochs: 94, batch: 320 loss: 0.12757393717765808\n",
            "Epochs: 94, batch: 321 loss: 0.09187538176774979\n",
            "Epochs: 94, batch: 322 loss: 0.13301661610603333\n",
            "Epochs: 94, batch: 323 loss: 0.0544218048453331\n",
            "Epochs: 94, batch: 324 loss: 0.08043734729290009\n",
            "Epochs: 94, batch: 325 loss: 0.16205085813999176\n",
            "Epochs: 94, batch: 326 loss: 0.3175354301929474\n",
            "Epochs: 94, batch: 327 loss: 0.12895549833774567\n",
            "Epochs: 94, batch: 328 loss: 0.09664402902126312\n",
            "Epochs: 94, batch: 329 loss: 0.1237158253788948\n",
            "Epochs: 94, batch: 330 loss: 0.04023442044854164\n",
            "Epochs: 94, batch: 331 loss: 0.040557555854320526\n",
            "Epochs: 94, batch: 332 loss: 0.10565578937530518\n",
            "Epochs: 94, batch: 333 loss: 0.10935962945222855\n",
            "Epochs: 94, batch: 334 loss: 0.0880524292588234\n",
            "Epochs: 94, batch: 335 loss: 0.053103260695934296\n",
            "Epochs: 94, batch: 336 loss: 0.2177274078130722\n",
            "Epochs: 94, batch: 337 loss: 0.17174571752548218\n",
            "Epochs: 94, batch: 338 loss: 0.2586427927017212\n",
            "Epochs: 94, batch: 339 loss: 0.17058229446411133\n",
            "Epochs: 94, batch: 340 loss: 0.19015398621559143\n",
            "Epochs: 94, batch: 341 loss: 0.1327851563692093\n",
            "Epochs: 94, batch: 342 loss: 0.12107978761196136\n",
            "Epochs: 94, batch: 343 loss: 0.11578322947025299\n",
            "Epochs: 94, batch: 344 loss: 0.06635573506355286\n",
            "Epochs: 94, batch: 345 loss: 0.11259571462869644\n",
            "Epochs: 94, batch: 346 loss: 0.06741051375865936\n",
            "Epochs: 94, batch: 347 loss: 0.09235771000385284\n",
            "Epochs: 94, batch: 348 loss: 0.024206075817346573\n",
            "Epochs: 94, batch: 349 loss: 0.18602892756462097\n",
            "Epochs: 94, batch: 350 loss: 0.13447585701942444\n",
            "Epochs: 94, batch: 351 loss: 0.09078584611415863\n",
            "Epochs: 94, batch: 352 loss: 0.11308218538761139\n",
            "Epochs: 94, batch: 353 loss: 0.09296652674674988\n",
            "Epochs: 94, batch: 354 loss: 0.06809782981872559\n",
            "Epochs: 94, batch: 355 loss: 0.043825652450323105\n",
            "Epochs: 94, batch: 356 loss: 0.10122984647750854\n",
            "Epochs: 94, batch: 357 loss: 0.08304241299629211\n",
            "Epochs: 94, batch: 358 loss: 0.040917858481407166\n",
            "Epochs: 94, batch: 1 loss: 0.07890282571315765\n",
            "Epochs: 94, batch: 2 loss: 0.14960399270057678\n",
            "Epochs: 94, batch: 3 loss: 0.06833569705486298\n",
            "Epochs: 94, batch: 4 loss: 0.18605507910251617\n",
            "Epochs: 94, batch: 5 loss: 0.07933004200458527\n",
            "Epochs: 94, batch: 6 loss: 0.11040135473012924\n",
            "Epochs: 94, batch: 7 loss: 0.08136336505413055\n",
            "Epochs: 94, batch: 8 loss: 0.1358673870563507\n",
            "Epochs: 94, batch: 9 loss: 0.0797557681798935\n",
            "Epochs: 94, batch: 10 loss: 0.13272613286972046\n",
            "Epochs: 94, batch: 11 loss: 0.06174038350582123\n",
            "Epochs: 94, batch: 12 loss: 0.13884839415550232\n",
            "Epochs: 94, batch: 13 loss: 0.15364642441272736\n",
            "Epochs: 94, batch: 14 loss: 0.1317974478006363\n",
            "Epochs: 94, batch: 15 loss: 0.06104535982012749\n",
            "Epochs: 94, batch: 16 loss: 0.09733399748802185\n",
            "Epochs: 94, batch: 17 loss: 0.15422555804252625\n",
            "Epochs: 94, batch: 18 loss: 0.19804620742797852\n",
            "Epochs: 94, batch: 19 loss: 0.14908358454704285\n",
            "Epochs: 94, batch: 20 loss: 0.16729170083999634\n",
            "Epochs: 94, batch: 21 loss: 0.1473785936832428\n",
            "Epochs: 94, batch: 22 loss: 0.12108472734689713\n",
            "Epochs: 94, batch: 23 loss: 0.19950801134109497\n",
            "Epochs: 94, batch: 24 loss: 0.1320827305316925\n",
            "Epochs: 94, batch: 25 loss: 0.11288401484489441\n",
            "Epochs: 94, batch: 26 loss: 0.14566093683242798\n",
            "Epochs: 94, batch: 27 loss: 0.07972528040409088\n",
            "Epochs: 94, batch: 28 loss: 0.21392254531383514\n",
            "Epochs: 94, batch: 29 loss: 0.07404400408267975\n",
            "Epochs: 94, batch: 30 loss: 0.2584903836250305\n",
            "Epochs: 94, batch: 31 loss: 0.17725200951099396\n",
            "Epochs: 94, batch: 32 loss: 0.08149243891239166\n",
            "Epochs: 94, batch: 33 loss: 0.15503154695034027\n",
            "Epochs: 94, batch: 34 loss: 0.12619689106941223\n",
            "Epochs: 94, batch: 35 loss: 0.0848478227853775\n",
            "Epochs: 94, batch: 36 loss: 0.12351687997579575\n",
            "Epochs: 94, batch: 37 loss: 0.14781270921230316\n",
            "Epochs: 94, batch: 38 loss: 0.056421179324388504\n",
            "Epochs: 94, batch: 39 loss: 0.04569585621356964\n",
            "Epochs: 94, batch: 40 loss: 0.09682995080947876\n",
            "Epochs: 94, batch: 41 loss: 0.0580388680100441\n",
            "Epochs: 94, batch: 42 loss: 0.15799331665039062\n",
            "Epochs: 94, batch: 43 loss: 0.18683233857154846\n",
            "Epochs: 94, batch: 44 loss: 0.08049692213535309\n",
            "Epochs: 94, batch: 45 loss: 0.07720128446817398\n",
            "Epochs: 94, batch: 46 loss: 0.15330855548381805\n",
            "Epochs: 94, batch: 47 loss: 0.08832171559333801\n",
            "Epochs: 94, batch: 48 loss: 0.1589684933423996\n",
            "Epochs: 94, batch: 49 loss: 0.09112156927585602\n",
            "Epochs: 94, batch: 50 loss: 0.048463910818099976\n",
            "Epochs: 94, batch: 51 loss: 0.18552038073539734\n",
            "Epochs: 94, batch: 52 loss: 0.10969274491071701\n",
            "Epochs: 94, batch: 53 loss: 0.1292271465063095\n",
            "Epochs: 94, batch: 54 loss: 0.14021749794483185\n",
            "Epochs: 94, batch: 55 loss: 0.0788746252655983\n",
            "Epochs: 94, batch: 56 loss: 0.26509177684783936\n",
            "Epochs: 94, batch: 57 loss: 0.15273165702819824\n",
            "Epochs: 94, batch: 58 loss: 0.21920663118362427\n",
            "Epochs: 94, batch: 59 loss: 0.06047862768173218\n",
            "Epochs: 94, batch: 60 loss: 0.1774759590625763\n",
            "Epochs: 94, batch: 61 loss: 0.05744589865207672\n",
            "Epochs: 94, batch: 62 loss: 0.08899973332881927\n",
            "Epochs: 94, batch: 63 loss: 0.14281630516052246\n",
            "Epochs: 94, batch: 64 loss: 0.1116986870765686\n",
            "Epochs: 94, batch: 65 loss: 0.08082694560289383\n",
            "Epochs: 94, batch: 66 loss: 0.15905900299549103\n",
            "Epochs: 94, batch: 67 loss: 0.13283491134643555\n",
            "Epochs: 94, batch: 68 loss: 0.23644493520259857\n",
            "Epochs: 94, batch: 69 loss: 0.052990660071372986\n",
            "Epochs: 94, batch: 70 loss: 0.0857812911272049\n",
            "Epochs: 94, batch: 71 loss: 0.13757547736167908\n",
            "Epochs: 94, batch: 72 loss: 0.10974095016717911\n",
            "Epochs: 94, batch: 73 loss: 0.07152233272790909\n",
            "Epochs: 94, batch: 74 loss: 0.047415487468242645\n",
            "Epochs: 94, batch: 75 loss: 0.15666797757148743\n",
            "Epochs: 94, batch: 76 loss: 0.1385587453842163\n",
            "Epochs: 94, batch: 77 loss: 0.0861181691288948\n",
            "Epochs: 94, batch: 78 loss: 0.29384616017341614\n",
            "Epochs: 94, batch: 79 loss: 0.1467231810092926\n",
            "Epochs: 94, batch: 80 loss: 0.19120517373085022\n",
            "Epochs: 94, batch: 81 loss: 0.12904490530490875\n",
            "Epochs: 94, batch: 82 loss: 0.06115194037556648\n",
            "Epochs: 94, batch: 83 loss: 0.12582871317863464\n",
            "Epochs: 94, batch: 84 loss: 0.0527799166738987\n",
            "Epochs: 94, batch: 85 loss: 0.088070347905159\n",
            "Epochs: 94, batch: 86 loss: 0.13925273716449738\n",
            "Epochs: 94, batch: 87 loss: 0.0803455337882042\n",
            "Epochs: 94, batch: 88 loss: 0.10662689805030823\n",
            "Epochs: 94, batch: 89 loss: 0.029893334954977036\n",
            "Epochs: 94, batch: 90 loss: 0.03431818261742592\n",
            "Epochs: 94, batch: 91 loss: 0.1014283075928688\n",
            "Epochs: 94, batch: 92 loss: 0.14315351843833923\n",
            "Epochs: 94, batch: 93 loss: 0.1353425234556198\n",
            "Epochs: 94, batch: 94 loss: 0.12840136885643005\n",
            "Epochs: 94, batch: 95 loss: 0.07039983570575714\n",
            "Epochs: 94, batch: 96 loss: 0.05143420398235321\n",
            "Epochs: 94, batch: 97 loss: 0.10421554744243622\n",
            "Epochs: 94, batch: 98 loss: 0.0896211713552475\n",
            "Epochs: 94, batch: 99 loss: 0.07333457469940186\n",
            "Epochs: 94, batch: 101 loss: 0.08444613963365555\n",
            "Epochs: 94, batch: 102 loss: 0.05853985995054245\n",
            "Epochs: 94, batch: 103 loss: 0.09345661103725433\n",
            "Epochs: 94, batch: 104 loss: 0.15769827365875244\n",
            "Epochs: 94, batch: 105 loss: 0.23889708518981934\n",
            "Epochs: 94, batch: 106 loss: 0.06275242567062378\n",
            "Epochs: 94, batch: 107 loss: 0.06917539983987808\n",
            "Epochs: 94, batch: 108 loss: 0.04562995582818985\n",
            "Epochs: 94, batch: 109 loss: 0.07401403039693832\n",
            "Epochs: 94, batch: 110 loss: 0.07888031005859375\n",
            "Epochs: 94, batch: 111 loss: 0.18333344161510468\n",
            "Epochs: 94, batch: 112 loss: 0.0774223804473877\n",
            "Epochs: 94, batch: 113 loss: 0.05828633904457092\n",
            "Epochs: 94, batch: 114 loss: 0.16845275461673737\n",
            "Epochs: 94, batch: 115 loss: 0.042789578437805176\n",
            "Epochs: 94, batch: 116 loss: 0.11659400165081024\n",
            "Epochs: 94, batch: 117 loss: 0.27485769987106323\n",
            "Epochs: 94, batch: 118 loss: 0.09059646725654602\n",
            "Epochs: 94, batch: 119 loss: 0.15358015894889832\n",
            "Epochs: 94, batch: 120 loss: 0.1022799015045166\n",
            "Epochs: 94, batch: 121 loss: 0.07110094279050827\n",
            "Epochs: 94, batch: 122 loss: 0.16184499859809875\n",
            "Epochs: 94, batch: 123 loss: 0.15811482071876526\n",
            "Epochs: 94, batch: 124 loss: 0.06137501448392868\n",
            "Epochs: 94, batch: 125 loss: 0.07525988668203354\n",
            "Epochs: 94, batch: 126 loss: 0.0655568391084671\n",
            "Epochs: 94, batch: 127 loss: 0.16694888472557068\n",
            "Epochs: 94, batch: 128 loss: 0.020213697105646133\n",
            "Epochs: 94, batch: 129 loss: 0.11252792179584503\n",
            "Epochs: 94, batch: 130 loss: 0.0998632162809372\n",
            "Epochs: 94, batch: 131 loss: 0.10611538589000702\n",
            "Epochs: 94, batch: 132 loss: 0.17074865102767944\n",
            "Epochs: 94, batch: 133 loss: 0.05692455172538757\n",
            "Epochs: 94, batch: 134 loss: 0.16304658353328705\n",
            "Epochs: 94, batch: 135 loss: 0.08396486937999725\n",
            "Epochs: 94, batch: 136 loss: 0.08491546660661697\n",
            "Epochs: 94, batch: 137 loss: 0.1309559941291809\n",
            "Epochs: 94, batch: 138 loss: 0.2113257795572281\n",
            "Epochs: 94, batch: 139 loss: 0.07291841506958008\n",
            "Epochs: 94, batch: 140 loss: 0.13014090061187744\n",
            "Epochs: 94, batch: 141 loss: 0.07014991343021393\n",
            "Epochs: 94, batch: 142 loss: 0.09431073069572449\n",
            "Epochs: 94, batch: 143 loss: 0.1732092797756195\n",
            "Epochs: 94, batch: 144 loss: 0.11715447902679443\n",
            "Epochs: 94, batch: 145 loss: 0.11780655384063721\n",
            "Epochs: 94, batch: 146 loss: 0.09921370446681976\n",
            "Epochs: 94, batch: 147 loss: 0.1073797345161438\n",
            "Epochs: 94, batch: 148 loss: 0.17121337354183197\n",
            "Epochs: 94, batch: 149 loss: 0.1481180191040039\n",
            "Epochs: 94, batch: 150 loss: 0.07052448391914368\n",
            "Epochs: 94, batch: 151 loss: 0.1399456411600113\n",
            "Epochs: 94, batch: 152 loss: 0.16872601211071014\n",
            "Epochs: 94, batch: 153 loss: 0.09105921536684036\n",
            "Epochs: 94, batch: 154 loss: 0.09131339937448502\n",
            "Epochs: 94, batch: 155 loss: 0.12239378690719604\n",
            "Epochs: 94, batch: 156 loss: 0.18179532885551453\n",
            "Epochs: 94, batch: 157 loss: 0.11193479597568512\n",
            "Epochs: 94, batch: 158 loss: 0.19172225892543793\n",
            "Epochs: 94, batch: 159 loss: 0.08026778697967529\n",
            "Epochs: 94, batch: 160 loss: 0.08451497554779053\n",
            "Epochs: 94, batch: 161 loss: 0.25513899326324463\n",
            "Epochs: 94, batch: 162 loss: 0.10804326087236404\n",
            "Epochs: 94, batch: 163 loss: 0.09163817018270493\n",
            "Epochs: 94, batch: 164 loss: 0.12138016521930695\n",
            "Epochs: 94, batch: 165 loss: 0.18448778986930847\n",
            "Epochs: 94, batch: 166 loss: 0.1077415868639946\n",
            "Epochs: 94, batch: 167 loss: 0.15781471133232117\n",
            "Epochs: 94, batch: 168 loss: 0.03605338931083679\n",
            "Epochs: 94, batch: 169 loss: 0.034305162727832794\n",
            "Epochs: 94, batch: 170 loss: 0.03474564105272293\n",
            "Epochs: 94, batch: 171 loss: 0.04252251237630844\n",
            "Epochs: 94, batch: 172 loss: 0.10148898512125015\n",
            "Epochs: 94, batch: 173 loss: 0.04258409142494202\n",
            "Epochs: 94, batch: 174 loss: 0.11114996671676636\n",
            "Epochs: 94, batch: 175 loss: 0.22051414847373962\n",
            "Epochs: 94, batch: 176 loss: 0.19056694209575653\n",
            "Epochs: 94, batch: 177 loss: 0.043793220072984695\n",
            "Epochs: 94, batch: 178 loss: 0.084662064909935\n",
            "Epochs: 94, batch: 179 loss: 0.16787177324295044\n",
            "Epochs: 94, batch: 180 loss: 0.07063900679349899\n",
            "Epochs: 94, batch: 181 loss: 0.09626974165439606\n",
            "Epochs: 94, batch: 182 loss: 0.16925768554210663\n",
            "Epochs: 94, batch: 183 loss: 0.10081876069307327\n",
            "Epochs: 94, batch: 184 loss: 0.09428244829177856\n",
            "Epochs: 94, batch: 185 loss: 0.040593355894088745\n",
            "Epochs: 94, batch: 186 loss: 0.05397435277700424\n",
            "Epochs: 94, batch: 187 loss: 0.10152018815279007\n",
            "Epochs: 94, batch: 188 loss: 0.05347094312310219\n",
            "Epochs: 94, batch: 189 loss: 0.10131760686635971\n",
            "Epochs: 94, batch: 190 loss: 0.06227073073387146\n",
            "Epochs: 94, batch: 191 loss: 0.18642795085906982\n",
            "Epochs: 94, batch: 192 loss: 0.12144073843955994\n",
            "Epochs: 94, batch: 193 loss: 0.053372882306575775\n",
            "Epochs: 94, batch: 194 loss: 0.07801086455583572\n",
            "Epochs: 94, batch: 195 loss: 0.25483372807502747\n",
            "Epochs: 94, batch: 196 loss: 0.0503547266125679\n",
            "Epochs: 94, batch: 197 loss: 0.11769016832113266\n",
            "Epochs: 94, batch: 198 loss: 0.10630303621292114\n",
            "Epochs: 94, batch: 199 loss: 0.05299007520079613\n",
            "Epochs: 94, batch: 201 loss: 0.09373845905065536\n",
            "Epochs: 94, batch: 202 loss: 0.19511006772518158\n",
            "Epochs: 94, batch: 203 loss: 0.140501469373703\n",
            "Epochs: 94, batch: 204 loss: 0.08025693893432617\n",
            "Epochs: 94, batch: 205 loss: 0.1984601616859436\n",
            "Epochs: 94, batch: 206 loss: 0.16594427824020386\n",
            "Epochs: 94, batch: 207 loss: 0.05588500201702118\n",
            "Epochs: 94, batch: 208 loss: 0.23923106491565704\n",
            "Epochs: 94, batch: 209 loss: 0.07055281847715378\n",
            "Epochs: 94, batch: 210 loss: 0.18787133693695068\n",
            "Epochs: 94, batch: 211 loss: 0.07760406285524368\n",
            "Epochs: 94, batch: 212 loss: 0.0536612905561924\n",
            "Epochs: 94, batch: 213 loss: 0.09584023803472519\n",
            "Epochs: 94, batch: 214 loss: 0.04238379746675491\n",
            "Epochs: 94, batch: 215 loss: 0.12972211837768555\n",
            "Epochs: 94, batch: 216 loss: 0.06817110627889633\n",
            "Epochs: 94, batch: 217 loss: 0.06075121462345123\n",
            "Epochs: 94, batch: 218 loss: 0.10960853099822998\n",
            "Epochs: 94, batch: 219 loss: 0.15947817265987396\n",
            "Epochs: 94, batch: 220 loss: 0.06855720281600952\n",
            "Epochs: 94, batch: 221 loss: 0.1518045961856842\n",
            "Epochs: 94, batch: 222 loss: 0.21762527525424957\n",
            "Epochs: 94, batch: 223 loss: 0.10793014615774155\n",
            "Epochs: 94, batch: 224 loss: 0.1953287571668625\n",
            "Epochs: 94, batch: 225 loss: 0.13272574543952942\n",
            "Epochs: 94, batch: 226 loss: 0.09881772100925446\n",
            "Epochs: 94, batch: 227 loss: 0.06321396678686142\n",
            "Epochs: 94, batch: 228 loss: 0.14805659651756287\n",
            "Epochs: 94, batch: 229 loss: 0.09758006781339645\n",
            "Epochs: 94, batch: 230 loss: 0.050495099276304245\n",
            "Epochs: 94, batch: 231 loss: 0.2184889018535614\n",
            "Epochs: 94, batch: 232 loss: 0.05772008001804352\n",
            "Epochs: 94, batch: 233 loss: 0.12617191672325134\n",
            "Epochs: 94, batch: 234 loss: 0.19948351383209229\n",
            "Epochs: 94, batch: 235 loss: 0.09728343039751053\n",
            "Epochs: 94, batch: 236 loss: 0.052735693752765656\n",
            "Epochs: 94, batch: 237 loss: 0.20629659295082092\n",
            "Epochs: 94, batch: 238 loss: 0.12086272239685059\n",
            "Epochs: 94, batch: 239 loss: 0.1360471397638321\n",
            "Epochs: 94, batch: 240 loss: 0.10133598744869232\n",
            "Epochs: 94, batch: 241 loss: 0.09945489466190338\n",
            "Epochs: 94, batch: 242 loss: 0.15102414786815643\n",
            "Epochs: 94, batch: 243 loss: 0.07498631626367569\n",
            "Epochs: 94, batch: 244 loss: 0.11714938282966614\n",
            "Epochs: 94, batch: 245 loss: 0.15383023023605347\n",
            "Epochs: 94, batch: 246 loss: 0.13781535625457764\n",
            "Epochs: 94, batch: 247 loss: 0.04502098262310028\n",
            "Epochs: 94, batch: 248 loss: 0.06821192055940628\n",
            "Epochs: 94, batch: 249 loss: 0.12632900476455688\n",
            "Epochs: 94, batch: 250 loss: 0.09292538464069366\n",
            "Epochs: 94, batch: 251 loss: 0.11262530088424683\n",
            "Epochs: 94, batch: 252 loss: 0.1137424036860466\n",
            "Epochs: 94, batch: 253 loss: 0.032051313668489456\n",
            "Epochs: 94, batch: 254 loss: 0.050325870513916016\n",
            "Epochs: 94, batch: 255 loss: 0.20988082885742188\n",
            "Epochs: 94, batch: 256 loss: 0.15030133724212646\n",
            "Epochs: 94, batch: 257 loss: 0.07936809211969376\n",
            "Epochs: 94, batch: 258 loss: 0.12670719623565674\n",
            "Epochs: 94, batch: 259 loss: 0.21450068056583405\n",
            "Epochs: 94, batch: 260 loss: 0.10077618807554245\n",
            "Epochs: 94, batch: 261 loss: 0.09367354214191437\n",
            "Epochs: 94, batch: 262 loss: 0.10872651636600494\n",
            "Epochs: 94, batch: 263 loss: 0.06630086153745651\n",
            "Epochs: 94, batch: 264 loss: 0.15163776278495789\n",
            "Epochs: 94, batch: 265 loss: 0.0503225214779377\n",
            "Epochs: 94, batch: 266 loss: 0.04652784392237663\n",
            "Epochs: 94, batch: 267 loss: 0.1352439820766449\n",
            "Epochs: 94, batch: 268 loss: 0.1084248423576355\n",
            "Epochs: 94, batch: 269 loss: 0.04458237439393997\n",
            "Epochs: 94, batch: 270 loss: 0.18512654304504395\n",
            "Epochs: 94, batch: 271 loss: 0.03372141718864441\n",
            "Epochs: 94, batch: 272 loss: 0.1356472223997116\n",
            "Epochs: 94, batch: 273 loss: 0.1525876820087433\n",
            "Epochs: 94, batch: 274 loss: 0.10240821540355682\n",
            "Epochs: 94, batch: 275 loss: 0.13965576887130737\n",
            "Epochs: 94, batch: 276 loss: 0.10877080261707306\n",
            "Epochs: 94, batch: 277 loss: 0.17491669952869415\n",
            "Epochs: 94, batch: 278 loss: 0.058972179889678955\n",
            "Epochs: 94, batch: 279 loss: 0.12124772369861603\n",
            "Epochs: 94, batch: 280 loss: 0.15759441256523132\n",
            "Epochs: 94, batch: 281 loss: 0.09851756691932678\n",
            "Epochs: 94, batch: 282 loss: 0.15140725672245026\n",
            "Epochs: 94, batch: 283 loss: 0.15648359060287476\n",
            "Epochs: 94, batch: 284 loss: 0.09548500180244446\n",
            "Epochs: 94, batch: 285 loss: 0.1820850670337677\n",
            "Epochs: 94, batch: 286 loss: 0.05015293508768082\n",
            "Epochs: 94, batch: 287 loss: 0.19012829661369324\n",
            "Epochs: 94, batch: 288 loss: 0.1364670991897583\n",
            "Epochs: 94, batch: 289 loss: 0.18197350203990936\n",
            "Epochs: 94, batch: 290 loss: 0.06610853224992752\n",
            "Epochs: 94, batch: 291 loss: 0.14861613512039185\n",
            "Epochs: 94, batch: 292 loss: 0.16428491473197937\n",
            "Epochs: 94, batch: 293 loss: 0.1031109094619751\n",
            "Epochs: 94, batch: 294 loss: 0.16125191748142242\n",
            "Epochs: 94, batch: 295 loss: 0.15425220131874084\n",
            "Epochs: 94, batch: 296 loss: 0.08179280161857605\n",
            "Epochs: 94, batch: 297 loss: 0.07016617804765701\n",
            "Epochs: 94, batch: 298 loss: 0.03479933738708496\n",
            "Epochs: 94, batch: 299 loss: 0.06685888767242432\n",
            "Epochs: 94, batch: 301 loss: 0.11311811208724976\n",
            "Epochs: 94, batch: 302 loss: 0.043491147458553314\n",
            "Epochs: 94, batch: 303 loss: 0.1352045238018036\n",
            "Epochs: 94, batch: 304 loss: 0.11078432202339172\n",
            "Epochs: 94, batch: 305 loss: 0.15996235609054565\n",
            "Epochs: 94, batch: 306 loss: 0.09724139422178268\n",
            "Epochs: 94, batch: 307 loss: 0.1921246498823166\n",
            "Epochs: 94, batch: 308 loss: 0.09642854332923889\n",
            "Epochs: 94, batch: 309 loss: 0.07061868906021118\n",
            "Epochs: 94, batch: 310 loss: 0.12801963090896606\n",
            "Epochs: 94, batch: 311 loss: 0.13639026880264282\n",
            "Epochs: 94, batch: 312 loss: 0.08558344841003418\n",
            "Epochs: 94, batch: 313 loss: 0.1790846884250641\n",
            "Epochs: 94, batch: 314 loss: 0.11286408454179764\n",
            "Epochs: 94, batch: 315 loss: 0.20405450463294983\n",
            "Epochs: 94, batch: 316 loss: 0.11105170845985413\n",
            "Epochs: 94, batch: 317 loss: 0.20205160975456238\n",
            "Epochs: 94, batch: 318 loss: 0.11054578423500061\n",
            "Epochs: 94, batch: 319 loss: 0.1981479674577713\n",
            "Epochs: 94, batch: 320 loss: 0.14885729551315308\n",
            "Epochs: 94, batch: 321 loss: 0.054526232182979584\n",
            "Epochs: 94, batch: 322 loss: 0.06926314532756805\n",
            "Epochs: 94, batch: 323 loss: 0.10648868978023529\n",
            "Epochs: 94, batch: 324 loss: 0.04006890207529068\n",
            "Epochs: 94, batch: 325 loss: 0.19809392094612122\n",
            "Epochs: 94, batch: 326 loss: 0.03110358864068985\n",
            "Epochs: 94, batch: 327 loss: 0.12963609397411346\n",
            "Epochs: 94, batch: 328 loss: 0.0923764631152153\n",
            "Epochs: 94, batch: 329 loss: 0.14308223128318787\n",
            "Epochs: 94, batch: 330 loss: 0.11546015739440918\n",
            "Epochs: 94, batch: 331 loss: 0.05370647460222244\n",
            "Epochs: 94, batch: 332 loss: 0.2033040076494217\n",
            "Epochs: 94, batch: 333 loss: 0.12004704773426056\n",
            "Epochs: 94, batch: 334 loss: 0.2188279926776886\n",
            "Epochs: 94, batch: 335 loss: 0.17838653922080994\n",
            "Epochs: 94, batch: 336 loss: 0.13417339324951172\n",
            "Epochs: 94, batch: 337 loss: 0.12885016202926636\n",
            "Epochs: 94, batch: 338 loss: 0.13389675319194794\n",
            "Epochs: 94, batch: 339 loss: 0.16234137117862701\n",
            "Epochs: 94, batch: 340 loss: 0.03709118440747261\n",
            "Epochs: 94, batch: 341 loss: 0.16672776639461517\n",
            "Epochs: 94, batch: 342 loss: 0.108012355864048\n",
            "Epochs: 94, batch: 343 loss: 0.07363082468509674\n",
            "Epochs: 94, batch: 344 loss: 0.12195032089948654\n",
            "Epochs: 94, batch: 345 loss: 0.22156640887260437\n",
            "Epochs: 94, batch: 346 loss: 0.053892940282821655\n",
            "Epochs: 94, batch: 347 loss: 0.07401745766401291\n",
            "Epochs: 94, batch: 348 loss: 0.1248006671667099\n",
            "Epochs: 94, batch: 349 loss: 0.10047513246536255\n",
            "Epochs: 94, batch: 350 loss: 0.054955847561359406\n",
            "Epochs: 94, batch: 351 loss: 0.1435413509607315\n",
            "Epochs: 94, batch: 352 loss: 0.13649040460586548\n",
            "Epochs: 94, batch: 353 loss: 0.09852197766304016\n",
            "Epochs: 94, batch: 354 loss: 0.11013582348823547\n",
            "Epochs: 94, batch: 355 loss: 0.0629175677895546\n",
            "Epochs: 94, batch: 356 loss: 0.04995083808898926\n",
            "Epochs: 94, batch: 357 loss: 0.06836743652820587\n",
            "Epochs: 94, batch: 358 loss: 0.07311838120222092\n",
            "Epochs: 95, batch: 1 loss: 0.2333887815475464\n",
            "Epochs: 95, batch: 2 loss: 0.15836843848228455\n",
            "Epochs: 95, batch: 3 loss: 0.06592166423797607\n",
            "Epochs: 95, batch: 4 loss: 0.3258504271507263\n",
            "Epochs: 95, batch: 5 loss: 0.11441577970981598\n",
            "Epochs: 95, batch: 6 loss: 0.12929747998714447\n",
            "Epochs: 95, batch: 7 loss: 0.08961084485054016\n",
            "Epochs: 95, batch: 8 loss: 0.10895416140556335\n",
            "Epochs: 95, batch: 9 loss: 0.14295504987239838\n",
            "Epochs: 95, batch: 10 loss: 0.05349075049161911\n",
            "Epochs: 95, batch: 11 loss: 0.06663736701011658\n",
            "Epochs: 95, batch: 12 loss: 0.03239661082625389\n",
            "Epochs: 95, batch: 13 loss: 0.12038896977901459\n",
            "Epochs: 95, batch: 14 loss: 0.14360417425632477\n",
            "Epochs: 95, batch: 15 loss: 0.11849136650562286\n",
            "Epochs: 95, batch: 16 loss: 0.16826973855495453\n",
            "Epochs: 95, batch: 17 loss: 0.04694053903222084\n",
            "Epochs: 95, batch: 18 loss: 0.18699201941490173\n",
            "Epochs: 95, batch: 19 loss: 0.09280337393283844\n",
            "Epochs: 95, batch: 20 loss: 0.17535819113254547\n",
            "Epochs: 95, batch: 21 loss: 0.02467901073396206\n",
            "Epochs: 95, batch: 22 loss: 0.19748903810977936\n",
            "Epochs: 95, batch: 23 loss: 0.180402010679245\n",
            "Epochs: 95, batch: 24 loss: 0.08073033392429352\n",
            "Epochs: 95, batch: 25 loss: 0.06284362822771072\n",
            "Epochs: 95, batch: 26 loss: 0.07924054563045502\n",
            "Epochs: 95, batch: 27 loss: 0.08166562020778656\n",
            "Epochs: 95, batch: 28 loss: 0.40099528431892395\n",
            "Epochs: 95, batch: 29 loss: 0.16147756576538086\n",
            "Epochs: 95, batch: 30 loss: 0.1063847541809082\n",
            "Epochs: 95, batch: 31 loss: 0.11146450787782669\n",
            "Epochs: 95, batch: 32 loss: 0.21604375541210175\n",
            "Epochs: 95, batch: 33 loss: 0.07293856143951416\n",
            "Epochs: 95, batch: 34 loss: 0.06624387204647064\n",
            "Epochs: 95, batch: 35 loss: 0.19121651351451874\n",
            "Epochs: 95, batch: 36 loss: 0.0679067075252533\n",
            "Epochs: 95, batch: 37 loss: 0.19079580903053284\n",
            "Epochs: 95, batch: 38 loss: 0.08083169907331467\n",
            "Epochs: 95, batch: 39 loss: 0.12651026248931885\n",
            "Epochs: 95, batch: 40 loss: 0.128505676984787\n",
            "Epochs: 95, batch: 41 loss: 0.040288496762514114\n",
            "Epochs: 95, batch: 42 loss: 0.13376860320568085\n",
            "Epochs: 95, batch: 43 loss: 0.1780356913805008\n",
            "Epochs: 95, batch: 44 loss: 0.11625209450721741\n",
            "Epochs: 95, batch: 45 loss: 0.03415244072675705\n",
            "Epochs: 95, batch: 46 loss: 0.1126975566148758\n",
            "Epochs: 95, batch: 47 loss: 0.10353820770978928\n",
            "Epochs: 95, batch: 48 loss: 0.14632652699947357\n",
            "Epochs: 95, batch: 49 loss: 0.1060231477022171\n",
            "Epochs: 95, batch: 50 loss: 0.07049167901277542\n",
            "Epochs: 95, batch: 51 loss: 0.055376846343278885\n",
            "Epochs: 95, batch: 52 loss: 0.24521614611148834\n",
            "Epochs: 95, batch: 53 loss: 0.14757958054542542\n",
            "Epochs: 95, batch: 54 loss: 0.15560805797576904\n",
            "Epochs: 95, batch: 55 loss: 0.09464146941900253\n",
            "Epochs: 95, batch: 56 loss: 0.14244601130485535\n",
            "Epochs: 95, batch: 57 loss: 0.16164718568325043\n",
            "Epochs: 95, batch: 58 loss: 0.13956880569458008\n",
            "Epochs: 95, batch: 59 loss: 0.16358131170272827\n",
            "Epochs: 95, batch: 60 loss: 0.18751800060272217\n",
            "Epochs: 95, batch: 61 loss: 0.12789681553840637\n",
            "Epochs: 95, batch: 62 loss: 0.04221615567803383\n",
            "Epochs: 95, batch: 63 loss: 0.18548008799552917\n",
            "Epochs: 95, batch: 64 loss: 0.1059298887848854\n",
            "Epochs: 95, batch: 65 loss: 0.18104258179664612\n",
            "Epochs: 95, batch: 66 loss: 0.07992124557495117\n",
            "Epochs: 95, batch: 67 loss: 0.11262392997741699\n",
            "Epochs: 95, batch: 68 loss: 0.21983332931995392\n",
            "Epochs: 95, batch: 69 loss: 0.050631362944841385\n",
            "Epochs: 95, batch: 70 loss: 0.12172112613916397\n",
            "Epochs: 95, batch: 71 loss: 0.13507650792598724\n",
            "Epochs: 95, batch: 72 loss: 0.32214459776878357\n",
            "Epochs: 95, batch: 73 loss: 0.03149464353919029\n",
            "Epochs: 95, batch: 74 loss: 0.12064863741397858\n",
            "Epochs: 95, batch: 75 loss: 0.0921625867486\n",
            "Epochs: 95, batch: 76 loss: 0.12466892600059509\n",
            "Epochs: 95, batch: 77 loss: 0.1339322328567505\n",
            "Epochs: 95, batch: 78 loss: 0.23309795558452606\n",
            "Epochs: 95, batch: 79 loss: 0.06989728659391403\n",
            "Epochs: 95, batch: 80 loss: 0.17471788823604584\n",
            "Epochs: 95, batch: 81 loss: 0.13640540838241577\n",
            "Epochs: 95, batch: 82 loss: 0.10216508060693741\n",
            "Epochs: 95, batch: 83 loss: 0.16747528314590454\n",
            "Epochs: 95, batch: 84 loss: 0.06920487433671951\n",
            "Epochs: 95, batch: 85 loss: 0.1425902545452118\n",
            "Epochs: 95, batch: 86 loss: 0.19271034002304077\n",
            "Epochs: 95, batch: 87 loss: 0.076017826795578\n",
            "Epochs: 95, batch: 88 loss: 0.08565044403076172\n",
            "Epochs: 95, batch: 89 loss: 0.1469379961490631\n",
            "Epochs: 95, batch: 90 loss: 0.14026644825935364\n",
            "Epochs: 95, batch: 91 loss: 0.03805381432175636\n",
            "Epochs: 95, batch: 92 loss: 0.2337174117565155\n",
            "Epochs: 95, batch: 93 loss: 0.09664023667573929\n",
            "Epochs: 95, batch: 94 loss: 0.15185308456420898\n",
            "Epochs: 95, batch: 95 loss: 0.13253253698349\n",
            "Epochs: 95, batch: 96 loss: 0.026133734732866287\n",
            "Epochs: 95, batch: 97 loss: 0.09910920262336731\n",
            "Epochs: 95, batch: 98 loss: 0.1128583773970604\n",
            "Epochs: 95, batch: 99 loss: 0.11484386771917343\n",
            "Epochs: 95, batch: 101 loss: 0.03714073449373245\n",
            "Epochs: 95, batch: 102 loss: 0.10351954400539398\n",
            "Epochs: 95, batch: 103 loss: 0.12042681872844696\n",
            "Epochs: 95, batch: 104 loss: 0.11865244805812836\n",
            "Epochs: 95, batch: 105 loss: 0.20349565148353577\n",
            "Epochs: 95, batch: 106 loss: 0.1854693740606308\n",
            "Epochs: 95, batch: 107 loss: 0.11853538453578949\n",
            "Epochs: 95, batch: 108 loss: 0.07351338118314743\n",
            "Epochs: 95, batch: 109 loss: 0.07712800800800323\n",
            "Epochs: 95, batch: 110 loss: 0.029452772811055183\n",
            "Epochs: 95, batch: 111 loss: 0.06648654490709305\n",
            "Epochs: 95, batch: 112 loss: 0.3088033199310303\n",
            "Epochs: 95, batch: 113 loss: 0.04475073516368866\n",
            "Epochs: 95, batch: 114 loss: 0.17380839586257935\n",
            "Epochs: 95, batch: 115 loss: 0.14127229154109955\n",
            "Epochs: 95, batch: 116 loss: 0.22001054883003235\n",
            "Epochs: 95, batch: 117 loss: 0.09956932812929153\n",
            "Epochs: 95, batch: 118 loss: 0.028995007276535034\n",
            "Epochs: 95, batch: 119 loss: 0.09840123355388641\n",
            "Epochs: 95, batch: 120 loss: 0.026126723736524582\n",
            "Epochs: 95, batch: 121 loss: 0.2607937157154083\n",
            "Epochs: 95, batch: 122 loss: 0.08048073202371597\n",
            "Epochs: 95, batch: 123 loss: 0.20193983614444733\n",
            "Epochs: 95, batch: 124 loss: 0.04269258677959442\n",
            "Epochs: 95, batch: 125 loss: 0.11014010012149811\n",
            "Epochs: 95, batch: 126 loss: 0.09699399769306183\n",
            "Epochs: 95, batch: 127 loss: 0.16540926694869995\n",
            "Epochs: 95, batch: 128 loss: 0.0721159353852272\n",
            "Epochs: 95, batch: 129 loss: 0.10387331992387772\n",
            "Epochs: 95, batch: 130 loss: 0.0971677228808403\n",
            "Epochs: 95, batch: 131 loss: 0.17700490355491638\n",
            "Epochs: 95, batch: 132 loss: 0.11600770056247711\n",
            "Epochs: 95, batch: 133 loss: 0.2175460308790207\n",
            "Epochs: 95, batch: 134 loss: 0.2036568969488144\n",
            "Epochs: 95, batch: 135 loss: 0.19224247336387634\n",
            "Epochs: 95, batch: 136 loss: 0.10822427272796631\n",
            "Epochs: 95, batch: 137 loss: 0.13044920563697815\n",
            "Epochs: 95, batch: 138 loss: 0.17237022519111633\n",
            "Epochs: 95, batch: 139 loss: 0.10857769101858139\n",
            "Epochs: 95, batch: 140 loss: 0.06734239310026169\n",
            "Epochs: 95, batch: 141 loss: 0.10238923132419586\n",
            "Epochs: 95, batch: 142 loss: 0.06432843208312988\n",
            "Epochs: 95, batch: 143 loss: 0.13337931036949158\n",
            "Epochs: 95, batch: 144 loss: 0.15388213098049164\n",
            "Epochs: 95, batch: 145 loss: 0.06558311730623245\n",
            "Epochs: 95, batch: 146 loss: 0.1957934945821762\n",
            "Epochs: 95, batch: 147 loss: 0.12218283116817474\n",
            "Epochs: 95, batch: 148 loss: 0.2974620461463928\n",
            "Epochs: 95, batch: 149 loss: 0.05436769500374794\n",
            "Epochs: 95, batch: 150 loss: 0.14565949141979218\n",
            "Epochs: 95, batch: 151 loss: 0.08962678909301758\n",
            "Epochs: 95, batch: 152 loss: 0.13814452290534973\n",
            "Epochs: 95, batch: 153 loss: 0.12286911904811859\n",
            "Epochs: 95, batch: 154 loss: 0.2504952847957611\n",
            "Epochs: 95, batch: 155 loss: 0.12591324746608734\n",
            "Epochs: 95, batch: 156 loss: 0.052461378276348114\n",
            "Epochs: 95, batch: 157 loss: 0.17542670667171478\n",
            "Epochs: 95, batch: 158 loss: 0.11416714638471603\n",
            "Epochs: 95, batch: 159 loss: 0.10654472559690475\n",
            "Epochs: 95, batch: 160 loss: 0.16004589200019836\n",
            "Epochs: 95, batch: 161 loss: 0.22051818668842316\n",
            "Epochs: 95, batch: 162 loss: 0.07463062554597855\n",
            "Epochs: 95, batch: 163 loss: 0.13302919268608093\n",
            "Epochs: 95, batch: 164 loss: 0.08923457562923431\n",
            "Epochs: 95, batch: 165 loss: 0.14536882936954498\n",
            "Epochs: 95, batch: 166 loss: 0.11274514347314835\n",
            "Epochs: 95, batch: 167 loss: 0.27561116218566895\n",
            "Epochs: 95, batch: 168 loss: 0.07065260410308838\n",
            "Epochs: 95, batch: 169 loss: 0.04560065269470215\n",
            "Epochs: 95, batch: 170 loss: 0.06210611015558243\n",
            "Epochs: 95, batch: 171 loss: 0.1023659035563469\n",
            "Epochs: 95, batch: 172 loss: 0.042692653834819794\n",
            "Epochs: 95, batch: 173 loss: 0.10219307243824005\n",
            "Epochs: 95, batch: 174 loss: 0.1954481303691864\n",
            "Epochs: 95, batch: 175 loss: 0.0868411734700203\n",
            "Epochs: 95, batch: 176 loss: 0.10395804047584534\n",
            "Epochs: 95, batch: 177 loss: 0.07433730363845825\n",
            "Epochs: 95, batch: 178 loss: 0.09559664130210876\n",
            "Epochs: 95, batch: 179 loss: 0.04137169197201729\n",
            "Epochs: 95, batch: 180 loss: 0.1418716311454773\n",
            "Epochs: 95, batch: 181 loss: 0.06984876841306686\n",
            "Epochs: 95, batch: 182 loss: 0.22796697914600372\n",
            "Epochs: 95, batch: 183 loss: 0.07080656290054321\n",
            "Epochs: 95, batch: 184 loss: 0.06565713882446289\n",
            "Epochs: 95, batch: 185 loss: 0.07550869882106781\n",
            "Epochs: 95, batch: 186 loss: 0.14380791783332825\n",
            "Epochs: 95, batch: 187 loss: 0.11547645926475525\n",
            "Epochs: 95, batch: 188 loss: 0.07049098610877991\n",
            "Epochs: 95, batch: 189 loss: 0.21375426650047302\n",
            "Epochs: 95, batch: 190 loss: 0.11279217898845673\n",
            "Epochs: 95, batch: 191 loss: 0.04349621757864952\n",
            "Epochs: 95, batch: 192 loss: 0.16175131499767303\n",
            "Epochs: 95, batch: 193 loss: 0.0695359855890274\n",
            "Epochs: 95, batch: 194 loss: 0.18775209784507751\n",
            "Epochs: 95, batch: 195 loss: 0.11270589381456375\n",
            "Epochs: 95, batch: 196 loss: 0.1823054999113083\n",
            "Epochs: 95, batch: 197 loss: 0.07401316612958908\n",
            "Epochs: 95, batch: 198 loss: 0.07275278866291046\n",
            "Epochs: 95, batch: 199 loss: 0.1220809817314148\n",
            "Epochs: 95, batch: 201 loss: 0.11295389384031296\n",
            "Epochs: 95, batch: 202 loss: 0.2228110432624817\n",
            "Epochs: 95, batch: 203 loss: 0.07494498044252396\n",
            "Epochs: 95, batch: 204 loss: 0.17329467833042145\n",
            "Epochs: 95, batch: 205 loss: 0.09008786827325821\n",
            "Epochs: 95, batch: 206 loss: 0.09959415346384048\n",
            "Epochs: 95, batch: 207 loss: 0.09818535298109055\n",
            "Epochs: 95, batch: 208 loss: 0.06256557255983353\n",
            "Epochs: 95, batch: 209 loss: 0.08887160569429398\n",
            "Epochs: 95, batch: 210 loss: 0.10207617282867432\n",
            "Epochs: 95, batch: 211 loss: 0.06880118697881699\n",
            "Epochs: 95, batch: 212 loss: 0.16960273683071136\n",
            "Epochs: 95, batch: 213 loss: 0.2500338554382324\n",
            "Epochs: 95, batch: 214 loss: 0.15513837337493896\n",
            "Epochs: 95, batch: 215 loss: 0.1291140913963318\n",
            "Epochs: 95, batch: 216 loss: 0.1293570101261139\n",
            "Epochs: 95, batch: 217 loss: 0.10260145366191864\n",
            "Epochs: 95, batch: 218 loss: 0.058433741331100464\n",
            "Epochs: 95, batch: 219 loss: 0.20299378037452698\n",
            "Epochs: 95, batch: 220 loss: 0.12767882645130157\n",
            "Epochs: 95, batch: 221 loss: 0.04045780748128891\n",
            "Epochs: 95, batch: 222 loss: 0.14573904871940613\n",
            "Epochs: 95, batch: 223 loss: 0.11895251274108887\n",
            "Epochs: 95, batch: 224 loss: 0.17816920578479767\n",
            "Epochs: 95, batch: 225 loss: 0.10681487619876862\n",
            "Epochs: 95, batch: 226 loss: 0.13969764113426208\n",
            "Epochs: 95, batch: 227 loss: 0.15167289972305298\n",
            "Epochs: 95, batch: 228 loss: 0.14235976338386536\n",
            "Epochs: 95, batch: 229 loss: 0.1004209890961647\n",
            "Epochs: 95, batch: 230 loss: 0.1619725078344345\n",
            "Epochs: 95, batch: 231 loss: 0.08284369856119156\n",
            "Epochs: 95, batch: 232 loss: 0.1230848878622055\n",
            "Epochs: 95, batch: 233 loss: 0.0525863841176033\n",
            "Epochs: 95, batch: 234 loss: 0.15864235162734985\n",
            "Epochs: 95, batch: 235 loss: 0.1083783432841301\n",
            "Epochs: 95, batch: 236 loss: 0.17058789730072021\n",
            "Epochs: 95, batch: 237 loss: 0.0680733174085617\n",
            "Epochs: 95, batch: 238 loss: 0.10089302808046341\n",
            "Epochs: 95, batch: 239 loss: 0.10924317687749863\n",
            "Epochs: 95, batch: 240 loss: 0.07307370007038116\n",
            "Epochs: 95, batch: 241 loss: 0.11676986515522003\n",
            "Epochs: 95, batch: 242 loss: 0.11517247557640076\n",
            "Epochs: 95, batch: 243 loss: 0.0500430203974247\n",
            "Epochs: 95, batch: 244 loss: 0.17237623035907745\n",
            "Epochs: 95, batch: 245 loss: 0.18875916302204132\n",
            "Epochs: 95, batch: 246 loss: 0.17112085223197937\n",
            "Epochs: 95, batch: 247 loss: 0.09773856401443481\n",
            "Epochs: 95, batch: 248 loss: 0.13430556654930115\n",
            "Epochs: 95, batch: 249 loss: 0.07150868326425552\n",
            "Epochs: 95, batch: 250 loss: 0.21063998341560364\n",
            "Epochs: 95, batch: 251 loss: 0.3737744092941284\n",
            "Epochs: 95, batch: 252 loss: 0.09969907999038696\n",
            "Epochs: 95, batch: 253 loss: 0.11033686250448227\n",
            "Epochs: 95, batch: 254 loss: 0.1627756655216217\n",
            "Epochs: 95, batch: 255 loss: 0.10212014615535736\n",
            "Epochs: 95, batch: 256 loss: 0.1040034368634224\n",
            "Epochs: 95, batch: 257 loss: 0.15366974472999573\n",
            "Epochs: 95, batch: 258 loss: 0.14526233077049255\n",
            "Epochs: 95, batch: 259 loss: 0.13442416489124298\n",
            "Epochs: 95, batch: 260 loss: 0.07327626645565033\n",
            "Epochs: 95, batch: 261 loss: 0.07433079183101654\n",
            "Epochs: 95, batch: 262 loss: 0.19175103306770325\n",
            "Epochs: 95, batch: 263 loss: 0.06971960514783859\n",
            "Epochs: 95, batch: 264 loss: 0.11449597030878067\n",
            "Epochs: 95, batch: 265 loss: 0.12911924719810486\n",
            "Epochs: 95, batch: 266 loss: 0.14580018818378448\n",
            "Epochs: 95, batch: 267 loss: 0.17057013511657715\n",
            "Epochs: 95, batch: 268 loss: 0.036310311406850815\n",
            "Epochs: 95, batch: 269 loss: 0.2348739057779312\n",
            "Epochs: 95, batch: 270 loss: 0.02646605297923088\n",
            "Epochs: 95, batch: 271 loss: 0.14144542813301086\n",
            "Epochs: 95, batch: 272 loss: 0.11101469397544861\n",
            "Epochs: 95, batch: 273 loss: 0.08239008486270905\n",
            "Epochs: 95, batch: 274 loss: 0.05729974806308746\n",
            "Epochs: 95, batch: 275 loss: 0.13012270629405975\n",
            "Epochs: 95, batch: 276 loss: 0.07421933114528656\n",
            "Epochs: 95, batch: 277 loss: 0.17548823356628418\n",
            "Epochs: 95, batch: 278 loss: 0.05939193814992905\n",
            "Epochs: 95, batch: 279 loss: 0.027805451303720474\n",
            "Epochs: 95, batch: 280 loss: 0.06571599096059799\n",
            "Epochs: 95, batch: 281 loss: 0.2063482105731964\n",
            "Epochs: 95, batch: 282 loss: 0.1468159407377243\n",
            "Epochs: 95, batch: 283 loss: 0.07047794759273529\n",
            "Epochs: 95, batch: 284 loss: 0.06748121231794357\n",
            "Epochs: 95, batch: 285 loss: 0.0982593521475792\n",
            "Epochs: 95, batch: 286 loss: 0.15414293110370636\n",
            "Epochs: 95, batch: 287 loss: 0.056546054780483246\n",
            "Epochs: 95, batch: 288 loss: 0.03588574752211571\n",
            "Epochs: 95, batch: 289 loss: 0.12958811223506927\n",
            "Epochs: 95, batch: 290 loss: 0.10249427706003189\n",
            "Epochs: 95, batch: 291 loss: 0.10581372678279877\n",
            "Epochs: 95, batch: 292 loss: 0.1791859269142151\n",
            "Epochs: 95, batch: 293 loss: 0.1833326667547226\n",
            "Epochs: 95, batch: 294 loss: 0.13495613634586334\n",
            "Epochs: 95, batch: 295 loss: 0.17959406971931458\n",
            "Epochs: 95, batch: 296 loss: 0.12884825468063354\n",
            "Epochs: 95, batch: 297 loss: 0.07974961400032043\n",
            "Epochs: 95, batch: 298 loss: 0.08624695241451263\n",
            "Epochs: 95, batch: 299 loss: 0.11714126169681549\n",
            "Epochs: 95, batch: 301 loss: 0.07352368533611298\n",
            "Epochs: 95, batch: 302 loss: 0.10631034523248672\n",
            "Epochs: 95, batch: 303 loss: 0.2016793191432953\n",
            "Epochs: 95, batch: 304 loss: 0.23342135548591614\n",
            "Epochs: 95, batch: 305 loss: 0.16543543338775635\n",
            "Epochs: 95, batch: 306 loss: 0.13558298349380493\n",
            "Epochs: 95, batch: 307 loss: 0.03403162211179733\n",
            "Epochs: 95, batch: 308 loss: 0.09152857959270477\n",
            "Epochs: 95, batch: 309 loss: 0.10092756897211075\n",
            "Epochs: 95, batch: 310 loss: 0.13917064666748047\n",
            "Epochs: 95, batch: 311 loss: 0.16636580228805542\n",
            "Epochs: 95, batch: 312 loss: 0.03922625631093979\n",
            "Epochs: 95, batch: 313 loss: 0.1003875732421875\n",
            "Epochs: 95, batch: 314 loss: 0.044156093150377274\n",
            "Epochs: 95, batch: 315 loss: 0.10700279474258423\n",
            "Epochs: 95, batch: 316 loss: 0.09133690595626831\n",
            "Epochs: 95, batch: 317 loss: 0.13774672150611877\n",
            "Epochs: 95, batch: 318 loss: 0.11606393754482269\n",
            "Epochs: 95, batch: 319 loss: 0.07426878064870834\n",
            "Epochs: 95, batch: 320 loss: 0.1619681417942047\n",
            "Epochs: 95, batch: 321 loss: 0.1523125320672989\n",
            "Epochs: 95, batch: 322 loss: 0.1646994948387146\n",
            "Epochs: 95, batch: 323 loss: 0.1645544469356537\n",
            "Epochs: 95, batch: 324 loss: 0.07707720994949341\n",
            "Epochs: 95, batch: 325 loss: 0.06433485448360443\n",
            "Epochs: 95, batch: 326 loss: 0.1497218757867813\n",
            "Epochs: 95, batch: 327 loss: 0.1526913046836853\n",
            "Epochs: 95, batch: 328 loss: 0.09550163149833679\n",
            "Epochs: 95, batch: 329 loss: 0.08473554253578186\n",
            "Epochs: 95, batch: 330 loss: 0.11891867220401764\n",
            "Epochs: 95, batch: 331 loss: 0.2368953377008438\n",
            "Epochs: 95, batch: 332 loss: 0.1350821703672409\n",
            "Epochs: 95, batch: 333 loss: 0.1666824072599411\n",
            "Epochs: 95, batch: 334 loss: 0.26119232177734375\n",
            "Epochs: 95, batch: 335 loss: 0.1663527488708496\n",
            "Epochs: 95, batch: 336 loss: 0.09333119541406631\n",
            "Epochs: 95, batch: 337 loss: 0.06182737275958061\n",
            "Epochs: 95, batch: 338 loss: 0.09983213245868683\n",
            "Epochs: 95, batch: 339 loss: 0.08408422023057938\n",
            "Epochs: 95, batch: 340 loss: 0.13077673316001892\n",
            "Epochs: 95, batch: 341 loss: 0.20826110243797302\n",
            "Epochs: 95, batch: 342 loss: 0.24159513413906097\n",
            "Epochs: 95, batch: 343 loss: 0.1786620318889618\n",
            "Epochs: 95, batch: 344 loss: 0.1310887336730957\n",
            "Epochs: 95, batch: 345 loss: 0.24535220861434937\n",
            "Epochs: 95, batch: 346 loss: 0.1572597175836563\n",
            "Epochs: 95, batch: 347 loss: 0.09550613164901733\n",
            "Epochs: 95, batch: 348 loss: 0.13233378529548645\n",
            "Epochs: 95, batch: 349 loss: 0.14318548142910004\n",
            "Epochs: 95, batch: 350 loss: 0.2518121600151062\n",
            "Epochs: 95, batch: 351 loss: 0.117349773645401\n",
            "Epochs: 95, batch: 352 loss: 0.16258493065834045\n",
            "Epochs: 95, batch: 353 loss: 0.1625262200832367\n",
            "Epochs: 95, batch: 354 loss: 0.049501873552799225\n",
            "Epochs: 95, batch: 355 loss: 0.12907052040100098\n",
            "Epochs: 95, batch: 356 loss: 0.19993683695793152\n",
            "Epochs: 95, batch: 357 loss: 0.16817660629749298\n",
            "Epochs: 95, batch: 358 loss: 0.24826589226722717\n",
            "Epochs: 95, batch: 1 loss: 0.1771368384361267\n",
            "Epochs: 95, batch: 2 loss: 0.09202279150485992\n",
            "Epochs: 95, batch: 3 loss: 0.1293887197971344\n",
            "Epochs: 95, batch: 4 loss: 0.10153001546859741\n",
            "Epochs: 95, batch: 5 loss: 0.08922821283340454\n",
            "Epochs: 95, batch: 6 loss: 0.1125897616147995\n",
            "Epochs: 95, batch: 7 loss: 0.12567487359046936\n",
            "Epochs: 95, batch: 8 loss: 0.060678012669086456\n",
            "Epochs: 95, batch: 9 loss: 0.15149077773094177\n",
            "Epochs: 95, batch: 10 loss: 0.13598954677581787\n",
            "Epochs: 95, batch: 11 loss: 0.09939523786306381\n",
            "Epochs: 95, batch: 12 loss: 0.16199570894241333\n",
            "Epochs: 95, batch: 13 loss: 0.07099538296461105\n",
            "Epochs: 95, batch: 14 loss: 0.20830264687538147\n",
            "Epochs: 95, batch: 15 loss: 0.1305016577243805\n",
            "Epochs: 95, batch: 16 loss: 0.27115094661712646\n",
            "Epochs: 95, batch: 17 loss: 0.06009967625141144\n",
            "Epochs: 95, batch: 18 loss: 0.10156377404928207\n",
            "Epochs: 95, batch: 19 loss: 0.1230255663394928\n",
            "Epochs: 95, batch: 20 loss: 0.11879868060350418\n",
            "Epochs: 95, batch: 21 loss: 0.11838284134864807\n",
            "Epochs: 95, batch: 22 loss: 0.07501554489135742\n",
            "Epochs: 95, batch: 23 loss: 0.16418401896953583\n",
            "Epochs: 95, batch: 24 loss: 0.14389735460281372\n",
            "Epochs: 95, batch: 25 loss: 0.09442795813083649\n",
            "Epochs: 95, batch: 26 loss: 0.04821700602769852\n",
            "Epochs: 95, batch: 27 loss: 0.10137340426445007\n",
            "Epochs: 95, batch: 28 loss: 0.2601063549518585\n",
            "Epochs: 95, batch: 29 loss: 0.08537495881319046\n",
            "Epochs: 95, batch: 30 loss: 0.19221335649490356\n",
            "Epochs: 95, batch: 31 loss: 0.18464460968971252\n",
            "Epochs: 95, batch: 32 loss: 0.09594081342220306\n",
            "Epochs: 95, batch: 33 loss: 0.12366897612810135\n",
            "Epochs: 95, batch: 34 loss: 0.19822706282138824\n",
            "Epochs: 95, batch: 35 loss: 0.10816115140914917\n",
            "Epochs: 95, batch: 36 loss: 0.07346953451633453\n",
            "Epochs: 95, batch: 37 loss: 0.12968160212039948\n",
            "Epochs: 95, batch: 38 loss: 0.23504404723644257\n",
            "Epochs: 95, batch: 39 loss: 0.1126800924539566\n",
            "Epochs: 95, batch: 40 loss: 0.09894712269306183\n",
            "Epochs: 95, batch: 41 loss: 0.12080744653940201\n",
            "Epochs: 95, batch: 42 loss: 0.14264357089996338\n",
            "Epochs: 95, batch: 43 loss: 0.11860023438930511\n",
            "Epochs: 95, batch: 44 loss: 0.08197251707315445\n",
            "Epochs: 95, batch: 45 loss: 0.027568666264414787\n",
            "Epochs: 95, batch: 46 loss: 0.06600865721702576\n",
            "Epochs: 95, batch: 47 loss: 0.10182079672813416\n",
            "Epochs: 95, batch: 48 loss: 0.057299304753541946\n",
            "Epochs: 95, batch: 49 loss: 0.048505768179893494\n",
            "Epochs: 95, batch: 50 loss: 0.1957855373620987\n",
            "Epochs: 95, batch: 51 loss: 0.21632841229438782\n",
            "Epochs: 95, batch: 52 loss: 0.04127984121441841\n",
            "Epochs: 95, batch: 53 loss: 0.10322848707437515\n",
            "Epochs: 95, batch: 54 loss: 0.11535119265317917\n",
            "Epochs: 95, batch: 55 loss: 0.0687805712223053\n",
            "Epochs: 95, batch: 56 loss: 0.15428882837295532\n",
            "Epochs: 95, batch: 57 loss: 0.1259397268295288\n",
            "Epochs: 95, batch: 58 loss: 0.09144990891218185\n",
            "Epochs: 95, batch: 59 loss: 0.2616376578807831\n",
            "Epochs: 95, batch: 60 loss: 0.0937243402004242\n",
            "Epochs: 95, batch: 61 loss: 0.11592578887939453\n",
            "Epochs: 95, batch: 62 loss: 0.03304541856050491\n",
            "Epochs: 95, batch: 63 loss: 0.113490030169487\n",
            "Epochs: 95, batch: 64 loss: 0.1451503336429596\n",
            "Epochs: 95, batch: 65 loss: 0.13358068466186523\n",
            "Epochs: 95, batch: 66 loss: 0.06657315045595169\n",
            "Epochs: 95, batch: 67 loss: 0.053970325738191605\n",
            "Epochs: 95, batch: 68 loss: 0.12313002347946167\n",
            "Epochs: 95, batch: 69 loss: 0.11188635975122452\n",
            "Epochs: 95, batch: 70 loss: 0.14472100138664246\n",
            "Epochs: 95, batch: 71 loss: 0.13193383812904358\n",
            "Epochs: 95, batch: 72 loss: 0.13353368639945984\n",
            "Epochs: 95, batch: 73 loss: 0.24735626578330994\n",
            "Epochs: 95, batch: 74 loss: 0.1358780562877655\n",
            "Epochs: 95, batch: 75 loss: 0.04101508483290672\n",
            "Epochs: 95, batch: 76 loss: 0.03683806210756302\n",
            "Epochs: 95, batch: 77 loss: 0.09145642817020416\n",
            "Epochs: 95, batch: 78 loss: 0.14437691867351532\n",
            "Epochs: 95, batch: 79 loss: 0.05259856954216957\n",
            "Epochs: 95, batch: 80 loss: 0.07604420185089111\n",
            "Epochs: 95, batch: 81 loss: 0.18339189887046814\n",
            "Epochs: 95, batch: 82 loss: 0.15061445534229279\n",
            "Epochs: 95, batch: 83 loss: 0.05247388780117035\n",
            "Epochs: 95, batch: 84 loss: 0.0827159583568573\n",
            "Epochs: 95, batch: 85 loss: 0.1601203978061676\n",
            "Epochs: 95, batch: 86 loss: 0.16888421773910522\n",
            "Epochs: 95, batch: 87 loss: 0.09018394351005554\n",
            "Epochs: 95, batch: 88 loss: 0.11951284855604172\n",
            "Epochs: 95, batch: 89 loss: 0.04346039146184921\n",
            "Epochs: 95, batch: 90 loss: 0.10028165578842163\n",
            "Epochs: 95, batch: 91 loss: 0.021760601550340652\n",
            "Epochs: 95, batch: 92 loss: 0.08933967351913452\n",
            "Epochs: 95, batch: 93 loss: 0.16531825065612793\n",
            "Epochs: 95, batch: 94 loss: 0.1416647732257843\n",
            "Epochs: 95, batch: 95 loss: 0.06632576137781143\n",
            "Epochs: 95, batch: 96 loss: 0.06294138729572296\n",
            "Epochs: 95, batch: 97 loss: 0.1450125128030777\n",
            "Epochs: 95, batch: 98 loss: 0.18775023519992828\n",
            "Epochs: 95, batch: 99 loss: 0.18655773997306824\n",
            "Epochs: 95, batch: 101 loss: 0.21207082271575928\n",
            "Epochs: 95, batch: 102 loss: 0.11316033452749252\n",
            "Epochs: 95, batch: 103 loss: 0.18126057088375092\n",
            "Epochs: 95, batch: 104 loss: 0.03537392243742943\n",
            "Epochs: 95, batch: 105 loss: 0.15083575248718262\n",
            "Epochs: 95, batch: 106 loss: 0.04969275742769241\n",
            "Epochs: 95, batch: 107 loss: 0.04442901536822319\n",
            "Epochs: 95, batch: 108 loss: 0.1668899655342102\n",
            "Epochs: 95, batch: 109 loss: 0.11817159503698349\n",
            "Epochs: 95, batch: 110 loss: 0.11582952737808228\n",
            "Epochs: 95, batch: 111 loss: 0.13626137375831604\n",
            "Epochs: 95, batch: 112 loss: 0.14299091696739197\n",
            "Epochs: 95, batch: 113 loss: 0.15771900117397308\n",
            "Epochs: 95, batch: 114 loss: 0.1077662855386734\n",
            "Epochs: 95, batch: 115 loss: 0.08300984650850296\n",
            "Epochs: 95, batch: 116 loss: 0.15224793553352356\n",
            "Epochs: 95, batch: 117 loss: 0.06117067486047745\n",
            "Epochs: 95, batch: 118 loss: 0.060078926384449005\n",
            "Epochs: 95, batch: 119 loss: 0.15218916535377502\n",
            "Epochs: 95, batch: 120 loss: 0.0673762708902359\n",
            "Epochs: 95, batch: 121 loss: 0.1164633259177208\n",
            "Epochs: 95, batch: 122 loss: 0.12794184684753418\n",
            "Epochs: 95, batch: 123 loss: 0.12962058186531067\n",
            "Epochs: 95, batch: 124 loss: 0.06959635019302368\n",
            "Epochs: 95, batch: 125 loss: 0.08077786862850189\n",
            "Epochs: 95, batch: 126 loss: 0.15064111351966858\n",
            "Epochs: 95, batch: 127 loss: 0.10094548761844635\n",
            "Epochs: 95, batch: 128 loss: 0.15794967114925385\n",
            "Epochs: 95, batch: 129 loss: 0.2011001855134964\n",
            "Epochs: 95, batch: 130 loss: 0.06861989200115204\n",
            "Epochs: 95, batch: 131 loss: 0.21301467716693878\n",
            "Epochs: 95, batch: 132 loss: 0.18014149367809296\n",
            "Epochs: 95, batch: 133 loss: 0.08235476911067963\n",
            "Epochs: 95, batch: 134 loss: 0.25422418117523193\n",
            "Epochs: 95, batch: 135 loss: 0.13008169829845428\n",
            "Epochs: 95, batch: 136 loss: 0.17002853751182556\n",
            "Epochs: 95, batch: 137 loss: 0.2876293659210205\n",
            "Epochs: 95, batch: 138 loss: 0.11802703142166138\n",
            "Epochs: 95, batch: 139 loss: 0.15518763661384583\n",
            "Epochs: 95, batch: 140 loss: 0.030430350452661514\n",
            "Epochs: 95, batch: 141 loss: 0.15080860257148743\n",
            "Epochs: 95, batch: 142 loss: 0.14216744899749756\n",
            "Epochs: 95, batch: 143 loss: 0.11462622135877609\n",
            "Epochs: 95, batch: 144 loss: 0.04962979257106781\n",
            "Epochs: 95, batch: 145 loss: 0.09679887443780899\n",
            "Epochs: 95, batch: 146 loss: 0.1994308978319168\n",
            "Epochs: 95, batch: 147 loss: 0.14239004254341125\n",
            "Epochs: 95, batch: 148 loss: 0.07825139164924622\n",
            "Epochs: 95, batch: 149 loss: 0.11536849290132523\n",
            "Epochs: 95, batch: 150 loss: 0.042737990617752075\n",
            "Epochs: 95, batch: 151 loss: 0.0722208172082901\n",
            "Epochs: 95, batch: 152 loss: 0.13557063043117523\n",
            "Epochs: 95, batch: 153 loss: 0.11921091377735138\n",
            "Epochs: 95, batch: 154 loss: 0.1921873688697815\n",
            "Epochs: 95, batch: 155 loss: 0.21093644201755524\n",
            "Epochs: 95, batch: 156 loss: 0.12867556512355804\n",
            "Epochs: 95, batch: 157 loss: 0.0308213010430336\n",
            "Epochs: 95, batch: 158 loss: 0.10608606785535812\n",
            "Epochs: 95, batch: 159 loss: 0.10925076901912689\n",
            "Epochs: 95, batch: 160 loss: 0.1238604411482811\n",
            "Epochs: 95, batch: 161 loss: 0.07060860842466354\n",
            "Epochs: 95, batch: 162 loss: 0.06866896152496338\n",
            "Epochs: 95, batch: 163 loss: 0.168984055519104\n",
            "Epochs: 95, batch: 164 loss: 0.07969199866056442\n",
            "Epochs: 95, batch: 165 loss: 0.06929232180118561\n",
            "Epochs: 95, batch: 166 loss: 0.1714594066143036\n",
            "Epochs: 95, batch: 167 loss: 0.19460642337799072\n",
            "Epochs: 95, batch: 168 loss: 0.06017934903502464\n",
            "Epochs: 95, batch: 169 loss: 0.056240200996398926\n",
            "Epochs: 95, batch: 170 loss: 0.2236010879278183\n",
            "Epochs: 95, batch: 171 loss: 0.08942292630672455\n",
            "Epochs: 95, batch: 172 loss: 0.0899532288312912\n",
            "Epochs: 95, batch: 173 loss: 0.08801700174808502\n",
            "Epochs: 95, batch: 174 loss: 0.1152024194598198\n",
            "Epochs: 95, batch: 175 loss: 0.019891411066055298\n",
            "Epochs: 95, batch: 176 loss: 0.10755495727062225\n",
            "Epochs: 95, batch: 177 loss: 0.08082674443721771\n",
            "Epochs: 95, batch: 178 loss: 0.12157325446605682\n",
            "Epochs: 95, batch: 179 loss: 0.08947032690048218\n",
            "Epochs: 95, batch: 180 loss: 0.14169010519981384\n",
            "Epochs: 95, batch: 181 loss: 0.14555257558822632\n",
            "Epochs: 95, batch: 182 loss: 0.129850834608078\n",
            "Epochs: 95, batch: 183 loss: 0.10510970652103424\n",
            "Epochs: 95, batch: 184 loss: 0.04501461982727051\n",
            "Epochs: 95, batch: 185 loss: 0.045514702796936035\n",
            "Epochs: 95, batch: 186 loss: 0.16178125143051147\n",
            "Epochs: 95, batch: 187 loss: 0.2647761106491089\n",
            "Epochs: 95, batch: 188 loss: 0.11051285266876221\n",
            "Epochs: 95, batch: 189 loss: 0.09159816801548004\n",
            "Epochs: 95, batch: 190 loss: 0.06602314114570618\n",
            "Epochs: 95, batch: 191 loss: 0.06656989455223083\n",
            "Epochs: 95, batch: 192 loss: 0.19074960052967072\n",
            "Epochs: 95, batch: 193 loss: 0.10012829303741455\n",
            "Epochs: 95, batch: 194 loss: 0.20278441905975342\n",
            "Epochs: 95, batch: 195 loss: 0.05796287953853607\n",
            "Epochs: 95, batch: 196 loss: 0.14850759506225586\n",
            "Epochs: 95, batch: 197 loss: 0.10402655601501465\n",
            "Epochs: 95, batch: 198 loss: 0.12444683164358139\n",
            "Epochs: 95, batch: 199 loss: 0.1815536916255951\n",
            "Epochs: 95, batch: 201 loss: 0.1396915465593338\n",
            "Epochs: 95, batch: 202 loss: 0.09829647839069366\n",
            "Epochs: 95, batch: 203 loss: 0.11257462203502655\n",
            "Epochs: 95, batch: 204 loss: 0.0922245904803276\n",
            "Epochs: 95, batch: 205 loss: 0.04591132327914238\n",
            "Epochs: 95, batch: 206 loss: 0.12397773563861847\n",
            "Epochs: 95, batch: 207 loss: 0.2752333879470825\n",
            "Epochs: 95, batch: 208 loss: 0.176511749625206\n",
            "Epochs: 95, batch: 209 loss: 0.1787235140800476\n",
            "Epochs: 95, batch: 210 loss: 0.12468674778938293\n",
            "Epochs: 95, batch: 211 loss: 0.20019569993019104\n",
            "Epochs: 95, batch: 212 loss: 0.14481312036514282\n",
            "Epochs: 95, batch: 213 loss: 0.05859314277768135\n",
            "Epochs: 95, batch: 214 loss: 0.1723763346672058\n",
            "Epochs: 95, batch: 215 loss: 0.26857858896255493\n",
            "Epochs: 95, batch: 216 loss: 0.09069547802209854\n",
            "Epochs: 95, batch: 217 loss: 0.12234241515398026\n",
            "Epochs: 95, batch: 218 loss: 0.06802139431238174\n",
            "Epochs: 95, batch: 219 loss: 0.06525103747844696\n",
            "Epochs: 95, batch: 220 loss: 0.24708250164985657\n",
            "Epochs: 95, batch: 221 loss: 0.14464397728443146\n",
            "Epochs: 95, batch: 222 loss: 0.08382756263017654\n",
            "Epochs: 95, batch: 223 loss: 0.0730631873011589\n",
            "Epochs: 95, batch: 224 loss: 0.09673138707876205\n",
            "Epochs: 95, batch: 225 loss: 0.11821286380290985\n",
            "Epochs: 95, batch: 226 loss: 0.054842568933963776\n",
            "Epochs: 95, batch: 227 loss: 0.048599205911159515\n",
            "Epochs: 95, batch: 228 loss: 0.04650704935193062\n",
            "Epochs: 95, batch: 229 loss: 0.11849243938922882\n",
            "Epochs: 95, batch: 230 loss: 0.09630370140075684\n",
            "Epochs: 95, batch: 231 loss: 0.04090306907892227\n",
            "Epochs: 95, batch: 232 loss: 0.11580464243888855\n",
            "Epochs: 95, batch: 233 loss: 0.147751584649086\n",
            "Epochs: 95, batch: 234 loss: 0.10742415487766266\n",
            "Epochs: 95, batch: 235 loss: 0.15247312188148499\n",
            "Epochs: 95, batch: 236 loss: 0.1799640953540802\n",
            "Epochs: 95, batch: 237 loss: 0.1705285608768463\n",
            "Epochs: 95, batch: 238 loss: 0.15731696784496307\n",
            "Epochs: 95, batch: 239 loss: 0.0969383716583252\n",
            "Epochs: 95, batch: 240 loss: 0.11547324806451797\n",
            "Epochs: 95, batch: 241 loss: 0.06227423623204231\n",
            "Epochs: 95, batch: 242 loss: 0.1366971731185913\n",
            "Epochs: 95, batch: 243 loss: 0.11377091705799103\n",
            "Epochs: 95, batch: 244 loss: 0.05582783743739128\n",
            "Epochs: 95, batch: 245 loss: 0.12411586940288544\n",
            "Epochs: 95, batch: 246 loss: 0.20725587010383606\n",
            "Epochs: 95, batch: 247 loss: 0.12576213479042053\n",
            "Epochs: 95, batch: 248 loss: 0.140831857919693\n",
            "Epochs: 95, batch: 249 loss: 0.05504411831498146\n",
            "Epochs: 95, batch: 250 loss: 0.10960319638252258\n",
            "Epochs: 95, batch: 251 loss: 0.06056493893265724\n",
            "Epochs: 95, batch: 252 loss: 0.18661829829216003\n",
            "Epochs: 95, batch: 253 loss: 0.15087956190109253\n",
            "Epochs: 95, batch: 254 loss: 0.1442868411540985\n",
            "Epochs: 95, batch: 255 loss: 0.23527801036834717\n",
            "Epochs: 95, batch: 256 loss: 0.11830739676952362\n",
            "Epochs: 95, batch: 257 loss: 0.0427718386054039\n",
            "Epochs: 95, batch: 258 loss: 0.1983869969844818\n",
            "Epochs: 95, batch: 259 loss: 0.11154897511005402\n",
            "Epochs: 95, batch: 260 loss: 0.13642600178718567\n",
            "Epochs: 95, batch: 261 loss: 0.06306447833776474\n",
            "Epochs: 95, batch: 262 loss: 0.10195280611515045\n",
            "Epochs: 95, batch: 263 loss: 0.10650902986526489\n",
            "Epochs: 95, batch: 264 loss: 0.10337012261152267\n",
            "Epochs: 95, batch: 265 loss: 0.25917619466781616\n",
            "Epochs: 95, batch: 266 loss: 0.09120163321495056\n",
            "Epochs: 95, batch: 267 loss: 0.18929067254066467\n",
            "Epochs: 95, batch: 268 loss: 0.05361009016633034\n",
            "Epochs: 95, batch: 269 loss: 0.07413133233785629\n",
            "Epochs: 95, batch: 270 loss: 0.10414308309555054\n",
            "Epochs: 95, batch: 271 loss: 0.16644081473350525\n",
            "Epochs: 95, batch: 272 loss: 0.11534518748521805\n",
            "Epochs: 95, batch: 273 loss: 0.12787765264511108\n",
            "Epochs: 95, batch: 274 loss: 0.1737755537033081\n",
            "Epochs: 95, batch: 275 loss: 0.1448102444410324\n",
            "Epochs: 95, batch: 276 loss: 0.07131084054708481\n",
            "Epochs: 95, batch: 277 loss: 0.14010030031204224\n",
            "Epochs: 95, batch: 278 loss: 0.0484188012778759\n",
            "Epochs: 95, batch: 279 loss: 0.13850750029087067\n",
            "Epochs: 95, batch: 280 loss: 0.037933822721242905\n",
            "Epochs: 95, batch: 281 loss: 0.1012246161699295\n",
            "Epochs: 95, batch: 282 loss: 0.12132342904806137\n",
            "Epochs: 95, batch: 283 loss: 0.10036730766296387\n",
            "Epochs: 95, batch: 284 loss: 0.16049273312091827\n",
            "Epochs: 95, batch: 285 loss: 0.12485744059085846\n",
            "Epochs: 95, batch: 286 loss: 0.06592222303152084\n",
            "Epochs: 95, batch: 287 loss: 0.11549632251262665\n",
            "Epochs: 95, batch: 288 loss: 0.05078672617673874\n",
            "Epochs: 95, batch: 289 loss: 0.07420851290225983\n",
            "Epochs: 95, batch: 290 loss: 0.06432401388883591\n",
            "Epochs: 95, batch: 291 loss: 0.06800433993339539\n",
            "Epochs: 95, batch: 292 loss: 0.08533161878585815\n",
            "Epochs: 95, batch: 293 loss: 0.06918279081583023\n",
            "Epochs: 95, batch: 294 loss: 0.0912446677684784\n",
            "Epochs: 95, batch: 295 loss: 0.08899974822998047\n",
            "Epochs: 95, batch: 296 loss: 0.04394625127315521\n",
            "Epochs: 95, batch: 297 loss: 0.15899720788002014\n",
            "Epochs: 95, batch: 298 loss: 0.11836160719394684\n",
            "Epochs: 95, batch: 299 loss: 0.13276158273220062\n",
            "Epochs: 95, batch: 301 loss: 0.05521649122238159\n",
            "Epochs: 95, batch: 302 loss: 0.14530232548713684\n",
            "Epochs: 95, batch: 303 loss: 0.16648542881011963\n",
            "Epochs: 95, batch: 304 loss: 0.09618373215198517\n",
            "Epochs: 95, batch: 305 loss: 0.05410657078027725\n",
            "Epochs: 95, batch: 306 loss: 0.07267898321151733\n",
            "Epochs: 95, batch: 307 loss: 0.1569969207048416\n",
            "Epochs: 95, batch: 308 loss: 0.09070076048374176\n",
            "Epochs: 95, batch: 309 loss: 0.16604629158973694\n",
            "Epochs: 95, batch: 310 loss: 0.08186102658510208\n",
            "Epochs: 95, batch: 311 loss: 0.08337192237377167\n",
            "Epochs: 95, batch: 312 loss: 0.05273554474115372\n",
            "Epochs: 95, batch: 313 loss: 0.1710086464881897\n",
            "Epochs: 95, batch: 314 loss: 0.14609375596046448\n",
            "Epochs: 95, batch: 315 loss: 0.152726411819458\n",
            "Epochs: 95, batch: 316 loss: 0.08498062193393707\n",
            "Epochs: 95, batch: 317 loss: 0.12954966723918915\n",
            "Epochs: 95, batch: 318 loss: 0.07471367716789246\n",
            "Epochs: 95, batch: 319 loss: 0.1522858738899231\n",
            "Epochs: 95, batch: 320 loss: 0.1511932611465454\n",
            "Epochs: 95, batch: 321 loss: 0.21005511283874512\n",
            "Epochs: 95, batch: 322 loss: 0.17340150475502014\n",
            "Epochs: 95, batch: 323 loss: 0.25631797313690186\n",
            "Epochs: 95, batch: 324 loss: 0.19121529161930084\n",
            "Epochs: 95, batch: 325 loss: 0.08136274665594101\n",
            "Epochs: 95, batch: 326 loss: 0.10733667016029358\n",
            "Epochs: 95, batch: 327 loss: 0.23645669221878052\n",
            "Epochs: 95, batch: 328 loss: 0.10318872332572937\n",
            "Epochs: 95, batch: 329 loss: 0.14646373689174652\n",
            "Epochs: 95, batch: 330 loss: 0.15940068662166595\n",
            "Epochs: 95, batch: 331 loss: 0.07253745198249817\n",
            "Epochs: 95, batch: 332 loss: 0.09892834722995758\n",
            "Epochs: 95, batch: 333 loss: 0.17184868454933167\n",
            "Epochs: 95, batch: 334 loss: 0.09390991926193237\n",
            "Epochs: 95, batch: 335 loss: 0.17504572868347168\n",
            "Epochs: 95, batch: 336 loss: 0.10237453877925873\n",
            "Epochs: 95, batch: 337 loss: 0.1020713746547699\n",
            "Epochs: 95, batch: 338 loss: 0.1591271162033081\n",
            "Epochs: 95, batch: 339 loss: 0.06742352992296219\n",
            "Epochs: 95, batch: 340 loss: 0.11756659299135208\n",
            "Epochs: 95, batch: 341 loss: 0.07249386608600616\n",
            "Epochs: 95, batch: 342 loss: 0.10205206274986267\n",
            "Epochs: 95, batch: 343 loss: 0.12225096672773361\n",
            "Epochs: 95, batch: 344 loss: 0.09865957498550415\n",
            "Epochs: 95, batch: 345 loss: 0.1155242919921875\n",
            "Epochs: 95, batch: 346 loss: 0.17011766135692596\n",
            "Epochs: 95, batch: 347 loss: 0.21837109327316284\n",
            "Epochs: 95, batch: 348 loss: 0.07376401126384735\n",
            "Epochs: 95, batch: 349 loss: 0.15281757712364197\n",
            "Epochs: 95, batch: 350 loss: 0.14573505520820618\n",
            "Epochs: 95, batch: 351 loss: 0.1140105128288269\n",
            "Epochs: 95, batch: 352 loss: 0.08257456868886948\n",
            "Epochs: 95, batch: 353 loss: 0.07786168158054352\n",
            "Epochs: 95, batch: 354 loss: 0.19854265451431274\n",
            "Epochs: 95, batch: 355 loss: 0.11317239701747894\n",
            "Epochs: 95, batch: 356 loss: 0.13638213276863098\n",
            "Epochs: 95, batch: 357 loss: 0.08585721999406815\n",
            "Epochs: 95, batch: 358 loss: 0.046852316707372665\n",
            "Epochs: 96, batch: 1 loss: 0.0798521563410759\n",
            "Epochs: 96, batch: 2 loss: 0.16735905408859253\n",
            "Epochs: 96, batch: 3 loss: 0.13165727257728577\n",
            "Epochs: 96, batch: 4 loss: 0.19394539296627045\n",
            "Epochs: 96, batch: 5 loss: 0.16548317670822144\n",
            "Epochs: 96, batch: 6 loss: 0.0701218992471695\n",
            "Epochs: 96, batch: 7 loss: 0.10184462368488312\n",
            "Epochs: 96, batch: 8 loss: 0.07163757085800171\n",
            "Epochs: 96, batch: 9 loss: 0.3618689775466919\n",
            "Epochs: 96, batch: 10 loss: 0.11036792397499084\n",
            "Epochs: 96, batch: 11 loss: 0.0904388278722763\n",
            "Epochs: 96, batch: 12 loss: 0.04177981987595558\n",
            "Epochs: 96, batch: 13 loss: 0.029396140947937965\n",
            "Epochs: 96, batch: 14 loss: 0.1887579709291458\n",
            "Epochs: 96, batch: 15 loss: 0.07494045048952103\n",
            "Epochs: 96, batch: 16 loss: 0.16965118050575256\n",
            "Epochs: 96, batch: 17 loss: 0.09579335898160934\n",
            "Epochs: 96, batch: 18 loss: 0.060916606336832047\n",
            "Epochs: 96, batch: 19 loss: 0.13107524812221527\n",
            "Epochs: 96, batch: 20 loss: 0.12118034064769745\n",
            "Epochs: 96, batch: 21 loss: 0.18412351608276367\n",
            "Epochs: 96, batch: 22 loss: 0.15839910507202148\n",
            "Epochs: 96, batch: 23 loss: 0.06955134868621826\n",
            "Epochs: 96, batch: 24 loss: 0.12430278956890106\n",
            "Epochs: 96, batch: 25 loss: 0.28834933042526245\n",
            "Epochs: 96, batch: 26 loss: 0.10467962920665741\n",
            "Epochs: 96, batch: 27 loss: 0.13714472949504852\n",
            "Epochs: 96, batch: 28 loss: 0.07614407688379288\n",
            "Epochs: 96, batch: 29 loss: 0.0883258581161499\n",
            "Epochs: 96, batch: 30 loss: 0.10018771886825562\n",
            "Epochs: 96, batch: 31 loss: 0.1185537576675415\n",
            "Epochs: 96, batch: 32 loss: 0.06587329506874084\n",
            "Epochs: 96, batch: 33 loss: 0.16824841499328613\n",
            "Epochs: 96, batch: 34 loss: 0.1735662817955017\n",
            "Epochs: 96, batch: 35 loss: 0.1462721973657608\n",
            "Epochs: 96, batch: 36 loss: 0.047017429023981094\n",
            "Epochs: 96, batch: 37 loss: 0.2756537199020386\n",
            "Epochs: 96, batch: 38 loss: 0.10197126120328903\n",
            "Epochs: 96, batch: 39 loss: 0.10635942220687866\n",
            "Epochs: 96, batch: 40 loss: 0.033886753022670746\n",
            "Epochs: 96, batch: 41 loss: 0.18025921285152435\n",
            "Epochs: 96, batch: 42 loss: 0.10479124635457993\n",
            "Epochs: 96, batch: 43 loss: 0.20975816249847412\n",
            "Epochs: 96, batch: 44 loss: 0.14248493313789368\n",
            "Epochs: 96, batch: 45 loss: 0.04059922695159912\n",
            "Epochs: 96, batch: 46 loss: 0.0673065260052681\n",
            "Epochs: 96, batch: 47 loss: 0.05468396097421646\n",
            "Epochs: 96, batch: 48 loss: 0.1035136803984642\n",
            "Epochs: 96, batch: 49 loss: 0.0488329753279686\n",
            "Epochs: 96, batch: 50 loss: 0.19639098644256592\n",
            "Epochs: 96, batch: 51 loss: 0.1703065186738968\n",
            "Epochs: 96, batch: 52 loss: 0.1926523894071579\n",
            "Epochs: 96, batch: 53 loss: 0.07880958169698715\n",
            "Epochs: 96, batch: 54 loss: 0.09456130862236023\n",
            "Epochs: 96, batch: 55 loss: 0.2070280909538269\n",
            "Epochs: 96, batch: 56 loss: 0.18122413754463196\n",
            "Epochs: 96, batch: 57 loss: 0.12255170941352844\n",
            "Epochs: 96, batch: 58 loss: 0.2711026668548584\n",
            "Epochs: 96, batch: 59 loss: 0.05532466620206833\n",
            "Epochs: 96, batch: 60 loss: 0.21506384015083313\n",
            "Epochs: 96, batch: 61 loss: 0.12175793945789337\n",
            "Epochs: 96, batch: 62 loss: 0.10198768228292465\n",
            "Epochs: 96, batch: 63 loss: 0.047552675008773804\n",
            "Epochs: 96, batch: 64 loss: 0.09296906739473343\n",
            "Epochs: 96, batch: 65 loss: 0.12587003409862518\n",
            "Epochs: 96, batch: 66 loss: 0.0765046775341034\n",
            "Epochs: 96, batch: 67 loss: 0.19311730563640594\n",
            "Epochs: 96, batch: 68 loss: 0.1868666410446167\n",
            "Epochs: 96, batch: 69 loss: 0.11521542072296143\n",
            "Epochs: 96, batch: 70 loss: 0.18327942490577698\n",
            "Epochs: 96, batch: 71 loss: 0.2671118974685669\n",
            "Epochs: 96, batch: 72 loss: 0.12142374366521835\n",
            "Epochs: 96, batch: 73 loss: 0.1576116681098938\n",
            "Epochs: 96, batch: 74 loss: 0.039038561284542084\n",
            "Epochs: 96, batch: 75 loss: 0.04682055860757828\n",
            "Epochs: 96, batch: 76 loss: 0.10298820585012436\n",
            "Epochs: 96, batch: 77 loss: 0.12951388955116272\n",
            "Epochs: 96, batch: 78 loss: 0.09844313561916351\n",
            "Epochs: 96, batch: 79 loss: 0.07913032174110413\n",
            "Epochs: 96, batch: 80 loss: 0.07144606113433838\n",
            "Epochs: 96, batch: 81 loss: 0.07548009604215622\n",
            "Epochs: 96, batch: 82 loss: 0.05632324516773224\n",
            "Epochs: 96, batch: 83 loss: 0.15300121903419495\n",
            "Epochs: 96, batch: 84 loss: 0.11753252893686295\n",
            "Epochs: 96, batch: 85 loss: 0.09452594816684723\n",
            "Epochs: 96, batch: 86 loss: 0.22675512731075287\n",
            "Epochs: 96, batch: 87 loss: 0.12830351293087006\n",
            "Epochs: 96, batch: 88 loss: 0.23310774564743042\n",
            "Epochs: 96, batch: 89 loss: 0.22224172949790955\n",
            "Epochs: 96, batch: 90 loss: 0.07044844329357147\n",
            "Epochs: 96, batch: 91 loss: 0.06289945542812347\n",
            "Epochs: 96, batch: 92 loss: 0.16658642888069153\n",
            "Epochs: 96, batch: 93 loss: 0.06746508181095123\n",
            "Epochs: 96, batch: 94 loss: 0.21047371625900269\n",
            "Epochs: 96, batch: 95 loss: 0.0464729443192482\n",
            "Epochs: 96, batch: 96 loss: 0.1530001312494278\n",
            "Epochs: 96, batch: 97 loss: 0.1417388617992401\n",
            "Epochs: 96, batch: 98 loss: 0.045462675392627716\n",
            "Epochs: 96, batch: 99 loss: 0.0584101527929306\n",
            "Epochs: 96, batch: 101 loss: 0.11044932156801224\n",
            "Epochs: 96, batch: 102 loss: 0.1778743416070938\n",
            "Epochs: 96, batch: 103 loss: 0.12686659395694733\n",
            "Epochs: 96, batch: 104 loss: 0.05308122932910919\n",
            "Epochs: 96, batch: 105 loss: 0.11591728031635284\n",
            "Epochs: 96, batch: 106 loss: 0.1830502152442932\n",
            "Epochs: 96, batch: 107 loss: 0.13353662192821503\n",
            "Epochs: 96, batch: 108 loss: 0.15092284977436066\n",
            "Epochs: 96, batch: 109 loss: 0.09490978717803955\n",
            "Epochs: 96, batch: 110 loss: 0.19933176040649414\n",
            "Epochs: 96, batch: 111 loss: 0.21917316317558289\n",
            "Epochs: 96, batch: 112 loss: 0.140067920088768\n",
            "Epochs: 96, batch: 113 loss: 0.0869985967874527\n",
            "Epochs: 96, batch: 114 loss: 0.10489591956138611\n",
            "Epochs: 96, batch: 115 loss: 0.13134312629699707\n",
            "Epochs: 96, batch: 116 loss: 0.13120435178279877\n",
            "Epochs: 96, batch: 117 loss: 0.1726282685995102\n",
            "Epochs: 96, batch: 118 loss: 0.22357432544231415\n",
            "Epochs: 96, batch: 119 loss: 0.15519191324710846\n",
            "Epochs: 96, batch: 120 loss: 0.11316484212875366\n",
            "Epochs: 96, batch: 121 loss: 0.2810255289077759\n",
            "Epochs: 96, batch: 122 loss: 0.0969143807888031\n",
            "Epochs: 96, batch: 123 loss: 0.10335824638605118\n",
            "Epochs: 96, batch: 124 loss: 0.19401216506958008\n",
            "Epochs: 96, batch: 125 loss: 0.19286589324474335\n",
            "Epochs: 96, batch: 126 loss: 0.11503860354423523\n",
            "Epochs: 96, batch: 127 loss: 0.11576245725154877\n",
            "Epochs: 96, batch: 128 loss: 0.12777963280677795\n",
            "Epochs: 96, batch: 129 loss: 0.05509398505091667\n",
            "Epochs: 96, batch: 130 loss: 0.09313654899597168\n",
            "Epochs: 96, batch: 131 loss: 0.23112519085407257\n",
            "Epochs: 96, batch: 132 loss: 0.05055427551269531\n",
            "Epochs: 96, batch: 133 loss: 0.13306443393230438\n",
            "Epochs: 96, batch: 134 loss: 0.12096934020519257\n",
            "Epochs: 96, batch: 135 loss: 0.1417195051908493\n",
            "Epochs: 96, batch: 136 loss: 0.21223533153533936\n",
            "Epochs: 96, batch: 137 loss: 0.15734681487083435\n",
            "Epochs: 96, batch: 138 loss: 0.12436488270759583\n",
            "Epochs: 96, batch: 139 loss: 0.14202910661697388\n",
            "Epochs: 96, batch: 140 loss: 0.1283978521823883\n",
            "Epochs: 96, batch: 141 loss: 0.12398596107959747\n",
            "Epochs: 96, batch: 142 loss: 0.04617523029446602\n",
            "Epochs: 96, batch: 143 loss: 0.04464329779148102\n",
            "Epochs: 96, batch: 144 loss: 0.136885866522789\n",
            "Epochs: 96, batch: 145 loss: 0.14506679773330688\n",
            "Epochs: 96, batch: 146 loss: 0.10798750817775726\n",
            "Epochs: 96, batch: 147 loss: 0.09327911585569382\n",
            "Epochs: 96, batch: 148 loss: 0.19972969591617584\n",
            "Epochs: 96, batch: 149 loss: 0.07958472520112991\n",
            "Epochs: 96, batch: 150 loss: 0.25627976655960083\n",
            "Epochs: 96, batch: 151 loss: 0.14301708340644836\n",
            "Epochs: 96, batch: 152 loss: 0.07636517286300659\n",
            "Epochs: 96, batch: 153 loss: 0.03252770006656647\n",
            "Epochs: 96, batch: 154 loss: 0.16888242959976196\n",
            "Epochs: 96, batch: 155 loss: 0.29812532663345337\n",
            "Epochs: 96, batch: 156 loss: 0.07350053638219833\n",
            "Epochs: 96, batch: 157 loss: 0.17412123084068298\n",
            "Epochs: 96, batch: 158 loss: 0.14527319371700287\n",
            "Epochs: 96, batch: 159 loss: 0.11277059465646744\n",
            "Epochs: 96, batch: 160 loss: 0.13560092449188232\n",
            "Epochs: 96, batch: 161 loss: 0.044025540351867676\n",
            "Epochs: 96, batch: 162 loss: 0.08750753849744797\n",
            "Epochs: 96, batch: 163 loss: 0.13905252516269684\n",
            "Epochs: 96, batch: 164 loss: 0.20293764770030975\n",
            "Epochs: 96, batch: 165 loss: 0.09177212417125702\n",
            "Epochs: 96, batch: 166 loss: 0.12178540229797363\n",
            "Epochs: 96, batch: 167 loss: 0.13565410673618317\n",
            "Epochs: 96, batch: 168 loss: 0.0925101563334465\n",
            "Epochs: 96, batch: 169 loss: 0.11811039596796036\n",
            "Epochs: 96, batch: 170 loss: 0.10176447778940201\n",
            "Epochs: 96, batch: 171 loss: 0.09436246752738953\n",
            "Epochs: 96, batch: 172 loss: 0.09011726081371307\n",
            "Epochs: 96, batch: 173 loss: 0.3402973413467407\n",
            "Epochs: 96, batch: 174 loss: 0.09175028651952744\n",
            "Epochs: 96, batch: 175 loss: 0.14552468061447144\n",
            "Epochs: 96, batch: 176 loss: 0.13563331961631775\n",
            "Epochs: 96, batch: 177 loss: 0.058853425085544586\n",
            "Epochs: 96, batch: 178 loss: 0.24172523617744446\n",
            "Epochs: 96, batch: 179 loss: 0.11417493224143982\n",
            "Epochs: 96, batch: 180 loss: 0.2017860859632492\n",
            "Epochs: 96, batch: 181 loss: 0.09208536148071289\n",
            "Epochs: 96, batch: 182 loss: 0.20481553673744202\n",
            "Epochs: 96, batch: 183 loss: 0.10486699640750885\n",
            "Epochs: 96, batch: 184 loss: 0.0839429646730423\n",
            "Epochs: 96, batch: 185 loss: 0.18735374510288239\n",
            "Epochs: 96, batch: 186 loss: 0.10390010476112366\n",
            "Epochs: 96, batch: 187 loss: 0.07915031909942627\n",
            "Epochs: 96, batch: 188 loss: 0.12081405520439148\n",
            "Epochs: 96, batch: 189 loss: 0.18785345554351807\n",
            "Epochs: 96, batch: 190 loss: 0.11847181618213654\n",
            "Epochs: 96, batch: 191 loss: 0.08785310387611389\n",
            "Epochs: 96, batch: 192 loss: 0.12759746611118317\n",
            "Epochs: 96, batch: 193 loss: 0.18631915748119354\n",
            "Epochs: 96, batch: 194 loss: 0.10986083000898361\n",
            "Epochs: 96, batch: 195 loss: 0.09071406722068787\n",
            "Epochs: 96, batch: 196 loss: 0.0394999161362648\n",
            "Epochs: 96, batch: 197 loss: 0.1255502700805664\n",
            "Epochs: 96, batch: 198 loss: 0.11432772129774094\n",
            "Epochs: 96, batch: 199 loss: 0.06127886101603508\n",
            "Epochs: 96, batch: 201 loss: 0.0926225483417511\n",
            "Epochs: 96, batch: 202 loss: 0.035736020654439926\n",
            "Epochs: 96, batch: 203 loss: 0.06104551628232002\n",
            "Epochs: 96, batch: 204 loss: 0.17901493608951569\n",
            "Epochs: 96, batch: 205 loss: 0.06016521900892258\n",
            "Epochs: 96, batch: 206 loss: 0.10546684265136719\n",
            "Epochs: 96, batch: 207 loss: 0.09972155839204788\n",
            "Epochs: 96, batch: 208 loss: 0.07565297186374664\n",
            "Epochs: 96, batch: 209 loss: 0.09471248090267181\n",
            "Epochs: 96, batch: 210 loss: 0.07621922343969345\n",
            "Epochs: 96, batch: 211 loss: 0.0359027162194252\n",
            "Epochs: 96, batch: 212 loss: 0.06061252951622009\n",
            "Epochs: 96, batch: 213 loss: 0.07807381451129913\n",
            "Epochs: 96, batch: 214 loss: 0.0688241496682167\n",
            "Epochs: 96, batch: 215 loss: 0.15461285412311554\n",
            "Epochs: 96, batch: 216 loss: 0.10162429511547089\n",
            "Epochs: 96, batch: 217 loss: 0.0839078426361084\n",
            "Epochs: 96, batch: 218 loss: 0.13064280152320862\n",
            "Epochs: 96, batch: 219 loss: 0.2906925082206726\n",
            "Epochs: 96, batch: 220 loss: 0.07726150006055832\n",
            "Epochs: 96, batch: 221 loss: 0.2686466872692108\n",
            "Epochs: 96, batch: 222 loss: 0.09312363713979721\n",
            "Epochs: 96, batch: 223 loss: 0.08764898777008057\n",
            "Epochs: 96, batch: 224 loss: 0.1421521157026291\n",
            "Epochs: 96, batch: 225 loss: 0.08549423515796661\n",
            "Epochs: 96, batch: 226 loss: 0.23086421191692352\n",
            "Epochs: 96, batch: 227 loss: 0.10862892866134644\n",
            "Epochs: 96, batch: 228 loss: 0.15881052613258362\n",
            "Epochs: 96, batch: 229 loss: 0.06857408583164215\n",
            "Epochs: 96, batch: 230 loss: 0.23200514912605286\n",
            "Epochs: 96, batch: 231 loss: 0.027989933267235756\n",
            "Epochs: 96, batch: 232 loss: 0.06370751559734344\n",
            "Epochs: 96, batch: 233 loss: 0.08009684830904007\n",
            "Epochs: 96, batch: 234 loss: 0.1328195333480835\n",
            "Epochs: 96, batch: 235 loss: 0.11437663435935974\n",
            "Epochs: 96, batch: 236 loss: 0.13722112774848938\n",
            "Epochs: 96, batch: 237 loss: 0.06722106039524078\n",
            "Epochs: 96, batch: 238 loss: 0.1416350156068802\n",
            "Epochs: 96, batch: 239 loss: 0.06664816290140152\n",
            "Epochs: 96, batch: 240 loss: 0.09711557626724243\n",
            "Epochs: 96, batch: 241 loss: 0.2550993263721466\n",
            "Epochs: 96, batch: 242 loss: 0.06506545841693878\n",
            "Epochs: 96, batch: 243 loss: 0.0356566458940506\n",
            "Epochs: 96, batch: 244 loss: 0.06523255258798599\n",
            "Epochs: 96, batch: 245 loss: 0.03934139758348465\n",
            "Epochs: 96, batch: 246 loss: 0.11107651889324188\n",
            "Epochs: 96, batch: 247 loss: 0.030970461666584015\n",
            "Epochs: 96, batch: 248 loss: 0.08873480558395386\n",
            "Epochs: 96, batch: 249 loss: 0.1685643196105957\n",
            "Epochs: 96, batch: 250 loss: 0.10871738940477371\n",
            "Epochs: 96, batch: 251 loss: 0.07201582193374634\n",
            "Epochs: 96, batch: 252 loss: 0.1614425778388977\n",
            "Epochs: 96, batch: 253 loss: 0.0638803169131279\n",
            "Epochs: 96, batch: 254 loss: 0.1259879618883133\n",
            "Epochs: 96, batch: 255 loss: 0.1500113159418106\n",
            "Epochs: 96, batch: 256 loss: 0.11614257097244263\n",
            "Epochs: 96, batch: 257 loss: 0.06608140468597412\n",
            "Epochs: 96, batch: 258 loss: 0.16449956595897675\n",
            "Epochs: 96, batch: 259 loss: 0.04130265861749649\n",
            "Epochs: 96, batch: 260 loss: 0.0747133195400238\n",
            "Epochs: 96, batch: 261 loss: 0.16391819715499878\n",
            "Epochs: 96, batch: 262 loss: 0.06553289294242859\n",
            "Epochs: 96, batch: 263 loss: 0.15699277818202972\n",
            "Epochs: 96, batch: 264 loss: 0.14191634953022003\n",
            "Epochs: 96, batch: 265 loss: 0.16343636810779572\n",
            "Epochs: 96, batch: 266 loss: 0.1845240741968155\n",
            "Epochs: 96, batch: 267 loss: 0.24525892734527588\n",
            "Epochs: 96, batch: 268 loss: 0.08217864483594894\n",
            "Epochs: 96, batch: 269 loss: 0.08640766888856888\n",
            "Epochs: 96, batch: 270 loss: 0.04987487569451332\n",
            "Epochs: 96, batch: 271 loss: 0.08567196130752563\n",
            "Epochs: 96, batch: 272 loss: 0.20159615576267242\n",
            "Epochs: 96, batch: 273 loss: 0.21750207245349884\n",
            "Epochs: 96, batch: 274 loss: 0.33043426275253296\n",
            "Epochs: 96, batch: 275 loss: 0.08463723957538605\n",
            "Epochs: 96, batch: 276 loss: 0.03616327792406082\n",
            "Epochs: 96, batch: 277 loss: 0.12718109786510468\n",
            "Epochs: 96, batch: 278 loss: 0.15638189017772675\n",
            "Epochs: 96, batch: 279 loss: 0.08568474650382996\n",
            "Epochs: 96, batch: 280 loss: 0.0677531510591507\n",
            "Epochs: 96, batch: 281 loss: 0.2584421634674072\n",
            "Epochs: 96, batch: 282 loss: 0.04227748140692711\n",
            "Epochs: 96, batch: 283 loss: 0.12331530451774597\n",
            "Epochs: 96, batch: 284 loss: 0.17331354320049286\n",
            "Epochs: 96, batch: 285 loss: 0.14146758615970612\n",
            "Epochs: 96, batch: 286 loss: 0.061491575092077255\n",
            "Epochs: 96, batch: 287 loss: 0.15371713042259216\n",
            "Epochs: 96, batch: 288 loss: 0.040092386305332184\n",
            "Epochs: 96, batch: 289 loss: 0.0795874074101448\n",
            "Epochs: 96, batch: 290 loss: 0.11999651789665222\n",
            "Epochs: 96, batch: 291 loss: 0.13317565619945526\n",
            "Epochs: 96, batch: 292 loss: 0.0911986380815506\n",
            "Epochs: 96, batch: 293 loss: 0.15282022953033447\n",
            "Epochs: 96, batch: 294 loss: 0.040471259504556656\n",
            "Epochs: 96, batch: 295 loss: 0.07661345601081848\n",
            "Epochs: 96, batch: 296 loss: 0.0842590481042862\n",
            "Epochs: 96, batch: 297 loss: 0.07557936757802963\n",
            "Epochs: 96, batch: 298 loss: 0.07500344514846802\n",
            "Epochs: 96, batch: 299 loss: 0.08452999591827393\n",
            "Epochs: 96, batch: 301 loss: 0.23889920115470886\n",
            "Epochs: 96, batch: 302 loss: 0.1731962263584137\n",
            "Epochs: 96, batch: 303 loss: 0.09237301349639893\n",
            "Epochs: 96, batch: 304 loss: 0.15847566723823547\n",
            "Epochs: 96, batch: 305 loss: 0.060013603419065475\n",
            "Epochs: 96, batch: 306 loss: 0.0350247398018837\n",
            "Epochs: 96, batch: 307 loss: 0.09647183120250702\n",
            "Epochs: 96, batch: 308 loss: 0.14792579412460327\n",
            "Epochs: 96, batch: 309 loss: 0.04003385826945305\n",
            "Epochs: 96, batch: 310 loss: 0.0425262376666069\n",
            "Epochs: 96, batch: 311 loss: 0.0853179544210434\n",
            "Epochs: 96, batch: 312 loss: 0.15253856778144836\n",
            "Epochs: 96, batch: 313 loss: 0.07784941792488098\n",
            "Epochs: 96, batch: 314 loss: 0.0318022146821022\n",
            "Epochs: 96, batch: 315 loss: 0.262614369392395\n",
            "Epochs: 96, batch: 316 loss: 0.04661468416452408\n",
            "Epochs: 96, batch: 317 loss: 0.05163116380572319\n",
            "Epochs: 96, batch: 318 loss: 0.14820723235607147\n",
            "Epochs: 96, batch: 319 loss: 0.0509183406829834\n",
            "Epochs: 96, batch: 320 loss: 0.0779745951294899\n",
            "Epochs: 96, batch: 321 loss: 0.15396800637245178\n",
            "Epochs: 96, batch: 322 loss: 0.08944329619407654\n",
            "Epochs: 96, batch: 323 loss: 0.1523924171924591\n",
            "Epochs: 96, batch: 324 loss: 0.1328113079071045\n",
            "Epochs: 96, batch: 325 loss: 0.08335522562265396\n",
            "Epochs: 96, batch: 326 loss: 0.440496563911438\n",
            "Epochs: 96, batch: 327 loss: 0.0851408839225769\n",
            "Epochs: 96, batch: 328 loss: 0.4522353410720825\n",
            "Epochs: 96, batch: 329 loss: 0.15336455404758453\n",
            "Epochs: 96, batch: 330 loss: 0.25462478399276733\n",
            "Epochs: 96, batch: 331 loss: 0.06768415868282318\n",
            "Epochs: 96, batch: 332 loss: 0.133675679564476\n",
            "Epochs: 96, batch: 333 loss: 0.10110485553741455\n",
            "Epochs: 96, batch: 334 loss: 0.05699934810400009\n",
            "Epochs: 96, batch: 335 loss: 0.26552844047546387\n",
            "Epochs: 96, batch: 336 loss: 0.07825765013694763\n",
            "Epochs: 96, batch: 337 loss: 0.16008256375789642\n",
            "Epochs: 96, batch: 338 loss: 0.12629161775112152\n",
            "Epochs: 96, batch: 339 loss: 0.13335256278514862\n",
            "Epochs: 96, batch: 340 loss: 0.08344799280166626\n",
            "Epochs: 96, batch: 341 loss: 0.11144352704286575\n",
            "Epochs: 96, batch: 342 loss: 0.062354981899261475\n",
            "Epochs: 96, batch: 343 loss: 0.13010594248771667\n",
            "Epochs: 96, batch: 344 loss: 0.15050560235977173\n",
            "Epochs: 96, batch: 345 loss: 0.05336333066225052\n",
            "Epochs: 96, batch: 346 loss: 0.09912724792957306\n",
            "Epochs: 96, batch: 347 loss: 0.12841251492500305\n",
            "Epochs: 96, batch: 348 loss: 0.030725890770554543\n",
            "Epochs: 96, batch: 349 loss: 0.1966220587491989\n",
            "Epochs: 96, batch: 350 loss: 0.13909125328063965\n",
            "Epochs: 96, batch: 351 loss: 0.19994571805000305\n",
            "Epochs: 96, batch: 352 loss: 0.0940299928188324\n",
            "Epochs: 96, batch: 353 loss: 0.14767013490200043\n",
            "Epochs: 96, batch: 354 loss: 0.04715803638100624\n",
            "Epochs: 96, batch: 355 loss: 0.03563681244850159\n",
            "Epochs: 96, batch: 356 loss: 0.1676895171403885\n",
            "Epochs: 96, batch: 357 loss: 0.1717248558998108\n",
            "Epochs: 96, batch: 358 loss: 0.06276344507932663\n",
            "Epochs: 96, batch: 1 loss: 0.04733425751328468\n",
            "Epochs: 96, batch: 2 loss: 0.18595853447914124\n",
            "Epochs: 96, batch: 3 loss: 0.16571997106075287\n",
            "Epochs: 96, batch: 4 loss: 0.11321249604225159\n",
            "Epochs: 96, batch: 5 loss: 0.11760525405406952\n",
            "Epochs: 96, batch: 6 loss: 0.19186627864837646\n",
            "Epochs: 96, batch: 7 loss: 0.06051427870988846\n",
            "Epochs: 96, batch: 8 loss: 0.08630801737308502\n",
            "Epochs: 96, batch: 9 loss: 0.025351326912641525\n",
            "Epochs: 96, batch: 10 loss: 0.12278635799884796\n",
            "Epochs: 96, batch: 11 loss: 0.15654098987579346\n",
            "Epochs: 96, batch: 12 loss: 0.0283979419618845\n",
            "Epochs: 96, batch: 13 loss: 0.08239148557186127\n",
            "Epochs: 96, batch: 14 loss: 0.08541195094585419\n",
            "Epochs: 96, batch: 15 loss: 0.14341650903224945\n",
            "Epochs: 96, batch: 16 loss: 0.10669330507516861\n",
            "Epochs: 96, batch: 17 loss: 0.06354156881570816\n",
            "Epochs: 96, batch: 18 loss: 0.1110147088766098\n",
            "Epochs: 96, batch: 19 loss: 0.12828905880451202\n",
            "Epochs: 96, batch: 20 loss: 0.08608101308345795\n",
            "Epochs: 96, batch: 21 loss: 0.13097119331359863\n",
            "Epochs: 96, batch: 22 loss: 0.22178411483764648\n",
            "Epochs: 96, batch: 23 loss: 0.041628770530223846\n",
            "Epochs: 96, batch: 24 loss: 0.13930653035640717\n",
            "Epochs: 96, batch: 25 loss: 0.10009162127971649\n",
            "Epochs: 96, batch: 26 loss: 0.09744340181350708\n",
            "Epochs: 96, batch: 27 loss: 0.06510275602340698\n",
            "Epochs: 96, batch: 28 loss: 0.1294947862625122\n",
            "Epochs: 96, batch: 29 loss: 0.03097553551197052\n",
            "Epochs: 96, batch: 30 loss: 0.13194116950035095\n",
            "Epochs: 96, batch: 31 loss: 0.08389822393655777\n",
            "Epochs: 96, batch: 32 loss: 0.17284008860588074\n",
            "Epochs: 96, batch: 33 loss: 0.09263892471790314\n",
            "Epochs: 96, batch: 34 loss: 0.08381739258766174\n",
            "Epochs: 96, batch: 35 loss: 0.11685709655284882\n",
            "Epochs: 96, batch: 36 loss: 0.12546131014823914\n",
            "Epochs: 96, batch: 37 loss: 0.15494617819786072\n",
            "Epochs: 96, batch: 38 loss: 0.07018917798995972\n",
            "Epochs: 96, batch: 39 loss: 0.05919940769672394\n",
            "Epochs: 96, batch: 40 loss: 0.039238184690475464\n",
            "Epochs: 96, batch: 41 loss: 0.12466499209403992\n",
            "Epochs: 96, batch: 42 loss: 0.06016465649008751\n",
            "Epochs: 96, batch: 43 loss: 0.11482014507055283\n",
            "Epochs: 96, batch: 44 loss: 0.032111577689647675\n",
            "Epochs: 96, batch: 45 loss: 0.06306947767734528\n",
            "Epochs: 96, batch: 46 loss: 0.08840131014585495\n",
            "Epochs: 96, batch: 47 loss: 0.13739247620105743\n",
            "Epochs: 96, batch: 48 loss: 0.05749833956360817\n",
            "Epochs: 96, batch: 49 loss: 0.10458195209503174\n",
            "Epochs: 96, batch: 50 loss: 0.08293814957141876\n",
            "Epochs: 96, batch: 51 loss: 0.08022567629814148\n",
            "Epochs: 96, batch: 52 loss: 0.10189962387084961\n",
            "Epochs: 96, batch: 53 loss: 0.11015638709068298\n",
            "Epochs: 96, batch: 54 loss: 0.04512196406722069\n",
            "Epochs: 96, batch: 55 loss: 0.10348937660455704\n",
            "Epochs: 96, batch: 56 loss: 0.160286545753479\n",
            "Epochs: 96, batch: 57 loss: 0.07146415114402771\n",
            "Epochs: 96, batch: 58 loss: 0.10142410546541214\n",
            "Epochs: 96, batch: 59 loss: 0.07248617708683014\n",
            "Epochs: 96, batch: 60 loss: 0.053497105836868286\n",
            "Epochs: 96, batch: 61 loss: 0.09852812439203262\n",
            "Epochs: 96, batch: 62 loss: 0.19914667308330536\n",
            "Epochs: 96, batch: 63 loss: 0.054795943200588226\n",
            "Epochs: 96, batch: 64 loss: 0.10097905993461609\n",
            "Epochs: 96, batch: 65 loss: 0.0487896092236042\n",
            "Epochs: 96, batch: 66 loss: 0.07307977229356766\n",
            "Epochs: 96, batch: 67 loss: 0.05037451535463333\n",
            "Epochs: 96, batch: 68 loss: 0.15104985237121582\n",
            "Epochs: 96, batch: 69 loss: 0.07457248866558075\n",
            "Epochs: 96, batch: 70 loss: 0.21836704015731812\n",
            "Epochs: 96, batch: 71 loss: 0.10961949825286865\n",
            "Epochs: 96, batch: 72 loss: 0.021168045699596405\n",
            "Epochs: 96, batch: 73 loss: 0.10457722842693329\n",
            "Epochs: 96, batch: 74 loss: 0.11080284416675568\n",
            "Epochs: 96, batch: 75 loss: 0.07048479467630386\n",
            "Epochs: 96, batch: 76 loss: 0.11620955914258957\n",
            "Epochs: 96, batch: 77 loss: 0.1993083655834198\n",
            "Epochs: 96, batch: 78 loss: 0.1491166055202484\n",
            "Epochs: 96, batch: 79 loss: 0.12067729979753494\n",
            "Epochs: 96, batch: 80 loss: 0.060222141444683075\n",
            "Epochs: 96, batch: 81 loss: 0.1296638548374176\n",
            "Epochs: 96, batch: 82 loss: 0.10524873435497284\n",
            "Epochs: 96, batch: 83 loss: 0.09652967005968094\n",
            "Epochs: 96, batch: 84 loss: 0.2676249146461487\n",
            "Epochs: 96, batch: 85 loss: 0.07806160300970078\n",
            "Epochs: 96, batch: 86 loss: 0.05215500295162201\n",
            "Epochs: 96, batch: 87 loss: 0.16107383370399475\n",
            "Epochs: 96, batch: 88 loss: 0.09830817580223083\n",
            "Epochs: 96, batch: 89 loss: 0.0920538380742073\n",
            "Epochs: 96, batch: 90 loss: 0.09870533645153046\n",
            "Epochs: 96, batch: 91 loss: 0.07425899803638458\n",
            "Epochs: 96, batch: 92 loss: 0.09541922807693481\n",
            "Epochs: 96, batch: 93 loss: 0.1642611175775528\n",
            "Epochs: 96, batch: 94 loss: 0.04433374106884003\n",
            "Epochs: 96, batch: 95 loss: 0.10556763410568237\n",
            "Epochs: 96, batch: 96 loss: 0.1307677924633026\n",
            "Epochs: 96, batch: 97 loss: 0.1816878318786621\n",
            "Epochs: 96, batch: 98 loss: 0.1506013125181198\n",
            "Epochs: 96, batch: 99 loss: 0.17693260312080383\n",
            "Epochs: 96, batch: 101 loss: 0.1267486810684204\n",
            "Epochs: 96, batch: 102 loss: 0.06747917830944061\n",
            "Epochs: 96, batch: 103 loss: 0.1958865523338318\n",
            "Epochs: 96, batch: 104 loss: 0.0689443051815033\n",
            "Epochs: 96, batch: 105 loss: 0.06438513100147247\n",
            "Epochs: 96, batch: 106 loss: 0.10837949812412262\n",
            "Epochs: 96, batch: 107 loss: 0.10861456394195557\n",
            "Epochs: 96, batch: 108 loss: 0.12270817160606384\n",
            "Epochs: 96, batch: 109 loss: 0.1888047754764557\n",
            "Epochs: 96, batch: 110 loss: 0.1003485918045044\n",
            "Epochs: 96, batch: 111 loss: 0.12975050508975983\n",
            "Epochs: 96, batch: 112 loss: 0.05434272438287735\n",
            "Epochs: 96, batch: 113 loss: 0.17628872394561768\n",
            "Epochs: 96, batch: 114 loss: 0.09280478209257126\n",
            "Epochs: 96, batch: 115 loss: 0.07314412295818329\n",
            "Epochs: 96, batch: 116 loss: 0.1028677374124527\n",
            "Epochs: 96, batch: 117 loss: 0.09238265454769135\n",
            "Epochs: 96, batch: 118 loss: 0.2827560603618622\n",
            "Epochs: 96, batch: 119 loss: 0.33184564113616943\n",
            "Epochs: 96, batch: 120 loss: 0.08497747778892517\n",
            "Epochs: 96, batch: 121 loss: 0.11109369993209839\n",
            "Epochs: 96, batch: 122 loss: 0.11567471921443939\n",
            "Epochs: 96, batch: 123 loss: 0.11111743003129959\n",
            "Epochs: 96, batch: 124 loss: 0.12148892879486084\n",
            "Epochs: 96, batch: 125 loss: 0.041767023503780365\n",
            "Epochs: 96, batch: 126 loss: 0.17626579105854034\n",
            "Epochs: 96, batch: 127 loss: 0.09857968240976334\n",
            "Epochs: 96, batch: 128 loss: 0.09057130664587021\n",
            "Epochs: 96, batch: 129 loss: 0.018725577741861343\n",
            "Epochs: 96, batch: 130 loss: 0.08749087154865265\n",
            "Epochs: 96, batch: 131 loss: 0.09212826192378998\n",
            "Epochs: 96, batch: 132 loss: 0.029240354895591736\n",
            "Epochs: 96, batch: 133 loss: 0.29107704758644104\n",
            "Epochs: 96, batch: 134 loss: 0.04803532734513283\n",
            "Epochs: 96, batch: 135 loss: 0.15292689204216003\n",
            "Epochs: 96, batch: 136 loss: 0.09098169207572937\n",
            "Epochs: 96, batch: 137 loss: 0.11907164007425308\n",
            "Epochs: 96, batch: 138 loss: 0.18331825733184814\n",
            "Epochs: 96, batch: 139 loss: 0.0744754895567894\n",
            "Epochs: 96, batch: 140 loss: 0.029851337894797325\n",
            "Epochs: 96, batch: 141 loss: 0.1051110252737999\n",
            "Epochs: 96, batch: 142 loss: 0.03391801938414574\n",
            "Epochs: 96, batch: 143 loss: 0.20371976494789124\n",
            "Epochs: 96, batch: 144 loss: 0.06973111629486084\n",
            "Epochs: 96, batch: 145 loss: 0.08309232443571091\n",
            "Epochs: 96, batch: 146 loss: 0.12018999457359314\n",
            "Epochs: 96, batch: 147 loss: 0.2273193597793579\n",
            "Epochs: 96, batch: 148 loss: 0.16216427087783813\n",
            "Epochs: 96, batch: 149 loss: 0.18752193450927734\n",
            "Epochs: 96, batch: 150 loss: 0.09902887046337128\n",
            "Epochs: 96, batch: 151 loss: 0.07528294622898102\n",
            "Epochs: 96, batch: 152 loss: 0.23536556959152222\n",
            "Epochs: 96, batch: 153 loss: 0.08760173618793488\n",
            "Epochs: 96, batch: 154 loss: 0.09428821504116058\n",
            "Epochs: 96, batch: 155 loss: 0.14055897295475006\n",
            "Epochs: 96, batch: 156 loss: 0.2297017127275467\n",
            "Epochs: 96, batch: 157 loss: 0.0747167244553566\n",
            "Epochs: 96, batch: 158 loss: 0.05620011314749718\n",
            "Epochs: 96, batch: 159 loss: 0.04569768160581589\n",
            "Epochs: 96, batch: 160 loss: 0.19984374940395355\n",
            "Epochs: 96, batch: 161 loss: 0.050695113837718964\n",
            "Epochs: 96, batch: 162 loss: 0.06599936634302139\n",
            "Epochs: 96, batch: 163 loss: 0.19979830086231232\n",
            "Epochs: 96, batch: 164 loss: 0.10180576145648956\n",
            "Epochs: 96, batch: 165 loss: 0.08877904713153839\n",
            "Epochs: 96, batch: 166 loss: 0.1983758509159088\n",
            "Epochs: 96, batch: 167 loss: 0.12994861602783203\n",
            "Epochs: 96, batch: 168 loss: 0.023766299709677696\n",
            "Epochs: 96, batch: 169 loss: 0.052796173840761185\n",
            "Epochs: 96, batch: 170 loss: 0.05816182494163513\n",
            "Epochs: 96, batch: 171 loss: 0.19434967637062073\n",
            "Epochs: 96, batch: 172 loss: 0.082545205950737\n",
            "Epochs: 96, batch: 173 loss: 0.15311646461486816\n",
            "Epochs: 96, batch: 174 loss: 0.10963402688503265\n",
            "Epochs: 96, batch: 175 loss: 0.11969684809446335\n",
            "Epochs: 96, batch: 176 loss: 0.17775972187519073\n",
            "Epochs: 96, batch: 177 loss: 0.09337760508060455\n",
            "Epochs: 96, batch: 178 loss: 0.14708304405212402\n",
            "Epochs: 96, batch: 179 loss: 0.18788914382457733\n",
            "Epochs: 96, batch: 180 loss: 0.06645767390727997\n",
            "Epochs: 96, batch: 181 loss: 0.10926427692174911\n",
            "Epochs: 96, batch: 182 loss: 0.17335017025470734\n",
            "Epochs: 96, batch: 183 loss: 0.11845093220472336\n",
            "Epochs: 96, batch: 184 loss: 0.10317292809486389\n",
            "Epochs: 96, batch: 185 loss: 0.1819104254245758\n",
            "Epochs: 96, batch: 186 loss: 0.09915083646774292\n",
            "Epochs: 96, batch: 187 loss: 0.09980399906635284\n",
            "Epochs: 96, batch: 188 loss: 0.14474967122077942\n",
            "Epochs: 96, batch: 189 loss: 0.13272538781166077\n",
            "Epochs: 96, batch: 190 loss: 0.1001322939991951\n",
            "Epochs: 96, batch: 191 loss: 0.06885842978954315\n",
            "Epochs: 96, batch: 192 loss: 0.0699840560555458\n",
            "Epochs: 96, batch: 193 loss: 0.13506051898002625\n",
            "Epochs: 96, batch: 194 loss: 0.053180623799562454\n",
            "Epochs: 96, batch: 195 loss: 0.06933236122131348\n",
            "Epochs: 96, batch: 196 loss: 0.15710072219371796\n",
            "Epochs: 96, batch: 197 loss: 0.0624028742313385\n",
            "Epochs: 96, batch: 198 loss: 0.01780678704380989\n",
            "Epochs: 96, batch: 199 loss: 0.11236564815044403\n",
            "Epochs: 96, batch: 201 loss: 0.17483067512512207\n",
            "Epochs: 96, batch: 202 loss: 0.246758833527565\n",
            "Epochs: 96, batch: 203 loss: 0.08004079014062881\n",
            "Epochs: 96, batch: 204 loss: 0.2611856162548065\n",
            "Epochs: 96, batch: 205 loss: 0.14533980190753937\n",
            "Epochs: 96, batch: 206 loss: 0.16208776831626892\n",
            "Epochs: 96, batch: 207 loss: 0.22618985176086426\n",
            "Epochs: 96, batch: 208 loss: 0.06477504223585129\n",
            "Epochs: 96, batch: 209 loss: 0.22126157581806183\n",
            "Epochs: 96, batch: 210 loss: 0.2532399892807007\n",
            "Epochs: 96, batch: 211 loss: 0.07860034704208374\n",
            "Epochs: 96, batch: 212 loss: 0.030435575172305107\n",
            "Epochs: 96, batch: 213 loss: 0.09085895121097565\n",
            "Epochs: 96, batch: 214 loss: 0.12455237656831741\n",
            "Epochs: 96, batch: 215 loss: 0.1233157068490982\n",
            "Epochs: 96, batch: 216 loss: 0.13788630068302155\n",
            "Epochs: 96, batch: 217 loss: 0.12373063713312149\n",
            "Epochs: 96, batch: 218 loss: 0.29390716552734375\n",
            "Epochs: 96, batch: 219 loss: 0.13630157709121704\n",
            "Epochs: 96, batch: 220 loss: 0.10986217856407166\n",
            "Epochs: 96, batch: 221 loss: 0.10987609624862671\n",
            "Epochs: 96, batch: 222 loss: 0.03107961267232895\n",
            "Epochs: 96, batch: 223 loss: 0.08946961164474487\n",
            "Epochs: 96, batch: 224 loss: 0.10595424473285675\n",
            "Epochs: 96, batch: 225 loss: 0.03429717943072319\n",
            "Epochs: 96, batch: 226 loss: 0.05535709112882614\n",
            "Epochs: 96, batch: 227 loss: 0.08096644282341003\n",
            "Epochs: 96, batch: 228 loss: 0.11713024228811264\n",
            "Epochs: 96, batch: 229 loss: 0.17107120156288147\n",
            "Epochs: 96, batch: 230 loss: 0.05272848159074783\n",
            "Epochs: 96, batch: 231 loss: 0.09999711066484451\n",
            "Epochs: 96, batch: 232 loss: 0.05298725515604019\n",
            "Epochs: 96, batch: 233 loss: 0.1510629504919052\n",
            "Epochs: 96, batch: 234 loss: 0.10259763896465302\n",
            "Epochs: 96, batch: 235 loss: 0.041381098330020905\n",
            "Epochs: 96, batch: 236 loss: 0.09875671565532684\n",
            "Epochs: 96, batch: 237 loss: 0.06342724710702896\n",
            "Epochs: 96, batch: 238 loss: 0.20144668221473694\n",
            "Epochs: 96, batch: 239 loss: 0.07220012694597244\n",
            "Epochs: 96, batch: 240 loss: 0.110223188996315\n",
            "Epochs: 96, batch: 241 loss: 0.20733347535133362\n",
            "Epochs: 96, batch: 242 loss: 0.259034126996994\n",
            "Epochs: 96, batch: 243 loss: 0.07515105605125427\n",
            "Epochs: 96, batch: 244 loss: 0.06853105127811432\n",
            "Epochs: 96, batch: 245 loss: 0.122491255402565\n",
            "Epochs: 96, batch: 246 loss: 0.0681779533624649\n",
            "Epochs: 96, batch: 247 loss: 0.047745153307914734\n",
            "Epochs: 96, batch: 248 loss: 0.15514881908893585\n",
            "Epochs: 96, batch: 249 loss: 0.06625290960073471\n",
            "Epochs: 96, batch: 250 loss: 0.10657355189323425\n",
            "Epochs: 96, batch: 251 loss: 0.06628260761499405\n",
            "Epochs: 96, batch: 252 loss: 0.15326830744743347\n",
            "Epochs: 96, batch: 253 loss: 0.16006404161453247\n",
            "Epochs: 96, batch: 254 loss: 0.0728406012058258\n",
            "Epochs: 96, batch: 255 loss: 0.19075502455234528\n",
            "Epochs: 96, batch: 256 loss: 0.11982931196689606\n",
            "Epochs: 96, batch: 257 loss: 0.07492506504058838\n",
            "Epochs: 96, batch: 258 loss: 0.07400701195001602\n",
            "Epochs: 96, batch: 259 loss: 0.1117914468050003\n",
            "Epochs: 96, batch: 260 loss: 0.10947387665510178\n",
            "Epochs: 96, batch: 261 loss: 0.17655245959758759\n",
            "Epochs: 96, batch: 262 loss: 0.07657338678836823\n",
            "Epochs: 96, batch: 263 loss: 0.02332792803645134\n",
            "Epochs: 96, batch: 264 loss: 0.23426540195941925\n",
            "Epochs: 96, batch: 265 loss: 0.024400100111961365\n",
            "Epochs: 96, batch: 266 loss: 0.12862657010555267\n",
            "Epochs: 96, batch: 267 loss: 0.10106663405895233\n",
            "Epochs: 96, batch: 268 loss: 0.1130179911851883\n",
            "Epochs: 96, batch: 269 loss: 0.07821513712406158\n",
            "Epochs: 96, batch: 270 loss: 0.19604076445102692\n",
            "Epochs: 96, batch: 271 loss: 0.11669039726257324\n",
            "Epochs: 96, batch: 272 loss: 0.20983734726905823\n",
            "Epochs: 96, batch: 273 loss: 0.09142141789197922\n",
            "Epochs: 96, batch: 274 loss: 0.11787132918834686\n",
            "Epochs: 96, batch: 275 loss: 0.19806447625160217\n",
            "Epochs: 96, batch: 276 loss: 0.08841429650783539\n",
            "Epochs: 96, batch: 277 loss: 0.048632025718688965\n",
            "Epochs: 96, batch: 278 loss: 0.05303715169429779\n",
            "Epochs: 96, batch: 279 loss: 0.13654154539108276\n",
            "Epochs: 96, batch: 280 loss: 0.08654578030109406\n",
            "Epochs: 96, batch: 281 loss: 0.14825905859470367\n",
            "Epochs: 96, batch: 282 loss: 0.06830138713121414\n",
            "Epochs: 96, batch: 283 loss: 0.11475929617881775\n",
            "Epochs: 96, batch: 284 loss: 0.09019540250301361\n",
            "Epochs: 96, batch: 285 loss: 0.11947276443243027\n",
            "Epochs: 96, batch: 286 loss: 0.19237197935581207\n",
            "Epochs: 96, batch: 287 loss: 0.28682374954223633\n",
            "Epochs: 96, batch: 288 loss: 0.19373299181461334\n",
            "Epochs: 96, batch: 289 loss: 0.08722462505102158\n",
            "Epochs: 96, batch: 290 loss: 0.0707084983587265\n",
            "Epochs: 96, batch: 291 loss: 0.10999223589897156\n",
            "Epochs: 96, batch: 292 loss: 0.09850629419088364\n",
            "Epochs: 96, batch: 293 loss: 0.1178874671459198\n",
            "Epochs: 96, batch: 294 loss: 0.14382250607013702\n",
            "Epochs: 96, batch: 295 loss: 0.07406537234783173\n",
            "Epochs: 96, batch: 296 loss: 0.10534118860960007\n",
            "Epochs: 96, batch: 297 loss: 0.16441985964775085\n",
            "Epochs: 96, batch: 298 loss: 0.14278994500637054\n",
            "Epochs: 96, batch: 299 loss: 0.04263179004192352\n",
            "Epochs: 96, batch: 301 loss: 0.07786418497562408\n",
            "Epochs: 96, batch: 302 loss: 0.0711483508348465\n",
            "Epochs: 96, batch: 303 loss: 0.17478418350219727\n",
            "Epochs: 96, batch: 304 loss: 0.20318379998207092\n",
            "Epochs: 96, batch: 305 loss: 0.16495464742183685\n",
            "Epochs: 96, batch: 306 loss: 0.12425148487091064\n",
            "Epochs: 96, batch: 307 loss: 0.12730059027671814\n",
            "Epochs: 96, batch: 308 loss: 0.034381698817014694\n",
            "Epochs: 96, batch: 309 loss: 0.13856787979602814\n",
            "Epochs: 96, batch: 310 loss: 0.09769733250141144\n",
            "Epochs: 96, batch: 311 loss: 0.11953894048929214\n",
            "Epochs: 96, batch: 312 loss: 0.1734364777803421\n",
            "Epochs: 96, batch: 313 loss: 0.09897938370704651\n",
            "Epochs: 96, batch: 314 loss: 0.19074448943138123\n",
            "Epochs: 96, batch: 315 loss: 0.198512002825737\n",
            "Epochs: 96, batch: 316 loss: 0.138933926820755\n",
            "Epochs: 96, batch: 317 loss: 0.06960167735815048\n",
            "Epochs: 96, batch: 318 loss: 0.1360778510570526\n",
            "Epochs: 96, batch: 319 loss: 0.054737575352191925\n",
            "Epochs: 96, batch: 320 loss: 0.16654953360557556\n",
            "Epochs: 96, batch: 321 loss: 0.13863670825958252\n",
            "Epochs: 96, batch: 322 loss: 0.19926176965236664\n",
            "Epochs: 96, batch: 323 loss: 0.058063529431819916\n",
            "Epochs: 96, batch: 324 loss: 0.024814847856760025\n",
            "Epochs: 96, batch: 325 loss: 0.03198649361729622\n",
            "Epochs: 96, batch: 326 loss: 0.05835873633623123\n",
            "Epochs: 96, batch: 327 loss: 0.03479761257767677\n",
            "Epochs: 96, batch: 328 loss: 0.1415020227432251\n",
            "Epochs: 96, batch: 329 loss: 0.07481423765420914\n",
            "Epochs: 96, batch: 330 loss: 0.10477585345506668\n",
            "Epochs: 96, batch: 331 loss: 0.12731194496154785\n",
            "Epochs: 96, batch: 332 loss: 0.22581183910369873\n",
            "Epochs: 96, batch: 333 loss: 0.0703917071223259\n",
            "Epochs: 96, batch: 334 loss: 0.1191568374633789\n",
            "Epochs: 96, batch: 335 loss: 0.21458446979522705\n",
            "Epochs: 96, batch: 336 loss: 0.12651702761650085\n",
            "Epochs: 96, batch: 337 loss: 0.04995793104171753\n",
            "Epochs: 96, batch: 338 loss: 0.24757468700408936\n",
            "Epochs: 96, batch: 339 loss: 0.11288803815841675\n",
            "Epochs: 96, batch: 340 loss: 0.12362028658390045\n",
            "Epochs: 96, batch: 341 loss: 0.07435755431652069\n",
            "Epochs: 96, batch: 342 loss: 0.1903689205646515\n",
            "Epochs: 96, batch: 343 loss: 0.04889059066772461\n",
            "Epochs: 96, batch: 344 loss: 0.12551537156105042\n",
            "Epochs: 96, batch: 345 loss: 0.04735514149069786\n",
            "Epochs: 96, batch: 346 loss: 0.1569339483976364\n",
            "Epochs: 96, batch: 347 loss: 0.04673729091882706\n",
            "Epochs: 96, batch: 348 loss: 0.14162588119506836\n",
            "Epochs: 96, batch: 349 loss: 0.061542294919490814\n",
            "Epochs: 96, batch: 350 loss: 0.06508223712444305\n",
            "Epochs: 96, batch: 351 loss: 0.030427685007452965\n",
            "Epochs: 96, batch: 352 loss: 0.09293195605278015\n",
            "Epochs: 96, batch: 353 loss: 0.09493697434663773\n",
            "Epochs: 96, batch: 354 loss: 0.19925473630428314\n",
            "Epochs: 96, batch: 355 loss: 0.19009290635585785\n",
            "Epochs: 96, batch: 356 loss: 0.06947270780801773\n",
            "Epochs: 96, batch: 357 loss: 0.09342461824417114\n",
            "Epochs: 96, batch: 358 loss: 0.33921143412590027\n",
            "Epochs: 97, batch: 1 loss: 0.172095388174057\n",
            "Epochs: 97, batch: 2 loss: 0.10942988842725754\n",
            "Epochs: 97, batch: 3 loss: 0.07322297990322113\n",
            "Epochs: 97, batch: 4 loss: 0.16900229454040527\n",
            "Epochs: 97, batch: 5 loss: 0.04231654852628708\n",
            "Epochs: 97, batch: 6 loss: 0.06243281811475754\n",
            "Epochs: 97, batch: 7 loss: 0.07113540917634964\n",
            "Epochs: 97, batch: 8 loss: 0.25161558389663696\n",
            "Epochs: 97, batch: 9 loss: 0.14221632480621338\n",
            "Epochs: 97, batch: 10 loss: 0.1355784833431244\n",
            "Epochs: 97, batch: 11 loss: 0.0751752108335495\n",
            "Epochs: 97, batch: 12 loss: 0.17216742038726807\n",
            "Epochs: 97, batch: 13 loss: 0.05208045616745949\n",
            "Epochs: 97, batch: 14 loss: 0.2840079069137573\n",
            "Epochs: 97, batch: 15 loss: 0.0600011944770813\n",
            "Epochs: 97, batch: 16 loss: 0.21499013900756836\n",
            "Epochs: 97, batch: 17 loss: 0.13794079422950745\n",
            "Epochs: 97, batch: 18 loss: 0.029984714463353157\n",
            "Epochs: 97, batch: 19 loss: 0.16247877478599548\n",
            "Epochs: 97, batch: 20 loss: 0.10172980278730392\n",
            "Epochs: 97, batch: 21 loss: 0.1034892350435257\n",
            "Epochs: 97, batch: 22 loss: 0.11893599480390549\n",
            "Epochs: 97, batch: 23 loss: 0.137742817401886\n",
            "Epochs: 97, batch: 24 loss: 0.07580302655696869\n",
            "Epochs: 97, batch: 25 loss: 0.13836491107940674\n",
            "Epochs: 97, batch: 26 loss: 0.15616722404956818\n",
            "Epochs: 97, batch: 27 loss: 0.11370117962360382\n",
            "Epochs: 97, batch: 28 loss: 0.07466156780719757\n",
            "Epochs: 97, batch: 29 loss: 0.14755739271640778\n",
            "Epochs: 97, batch: 30 loss: 0.11471664905548096\n",
            "Epochs: 97, batch: 31 loss: 0.0948992371559143\n",
            "Epochs: 97, batch: 32 loss: 0.09806099534034729\n",
            "Epochs: 97, batch: 33 loss: 0.11580265313386917\n",
            "Epochs: 97, batch: 34 loss: 0.13181881606578827\n",
            "Epochs: 97, batch: 35 loss: 0.027598757296800613\n",
            "Epochs: 97, batch: 36 loss: 0.058381788432598114\n",
            "Epochs: 97, batch: 37 loss: 0.136277973651886\n",
            "Epochs: 97, batch: 38 loss: 0.031368352472782135\n",
            "Epochs: 97, batch: 39 loss: 0.09334281086921692\n",
            "Epochs: 97, batch: 40 loss: 0.09198258072137833\n",
            "Epochs: 97, batch: 41 loss: 0.13369296491146088\n",
            "Epochs: 97, batch: 42 loss: 0.20693175494670868\n",
            "Epochs: 97, batch: 43 loss: 0.1583721935749054\n",
            "Epochs: 97, batch: 44 loss: 0.11416599899530411\n",
            "Epochs: 97, batch: 45 loss: 0.12032867968082428\n",
            "Epochs: 97, batch: 46 loss: 0.11413659900426865\n",
            "Epochs: 97, batch: 47 loss: 0.0677972212433815\n",
            "Epochs: 97, batch: 48 loss: 0.25017720460891724\n",
            "Epochs: 97, batch: 49 loss: 0.08110368996858597\n",
            "Epochs: 97, batch: 50 loss: 0.13725614547729492\n",
            "Epochs: 97, batch: 51 loss: 0.09389140456914902\n",
            "Epochs: 97, batch: 52 loss: 0.1812102496623993\n",
            "Epochs: 97, batch: 53 loss: 0.06317982822656631\n",
            "Epochs: 97, batch: 54 loss: 0.06377919018268585\n",
            "Epochs: 97, batch: 55 loss: 0.13812480866909027\n",
            "Epochs: 97, batch: 56 loss: 0.06704545021057129\n",
            "Epochs: 97, batch: 57 loss: 0.19860702753067017\n",
            "Epochs: 97, batch: 58 loss: 0.1267295926809311\n",
            "Epochs: 97, batch: 59 loss: 0.12654908001422882\n",
            "Epochs: 97, batch: 60 loss: 0.15030652284622192\n",
            "Epochs: 97, batch: 61 loss: 0.14209099113941193\n",
            "Epochs: 97, batch: 62 loss: 0.08425969630479813\n",
            "Epochs: 97, batch: 63 loss: 0.028964314609766006\n",
            "Epochs: 97, batch: 64 loss: 0.272982656955719\n",
            "Epochs: 97, batch: 65 loss: 0.017217544838786125\n",
            "Epochs: 97, batch: 66 loss: 0.1833890676498413\n",
            "Epochs: 97, batch: 67 loss: 0.13217447698116302\n",
            "Epochs: 97, batch: 68 loss: 0.14413273334503174\n",
            "Epochs: 97, batch: 69 loss: 0.027328643947839737\n",
            "Epochs: 97, batch: 70 loss: 0.08793061971664429\n",
            "Epochs: 97, batch: 71 loss: 0.06011773645877838\n",
            "Epochs: 97, batch: 72 loss: 0.09231779724359512\n",
            "Epochs: 97, batch: 73 loss: 0.19420157372951508\n",
            "Epochs: 97, batch: 74 loss: 0.08417807519435883\n",
            "Epochs: 97, batch: 75 loss: 0.15142741799354553\n",
            "Epochs: 97, batch: 76 loss: 0.15083946287631989\n",
            "Epochs: 97, batch: 77 loss: 0.03351575508713722\n",
            "Epochs: 97, batch: 78 loss: 0.19786491990089417\n",
            "Epochs: 97, batch: 79 loss: 0.31038913130760193\n",
            "Epochs: 97, batch: 80 loss: 0.10697661340236664\n",
            "Epochs: 97, batch: 81 loss: 0.0757315456867218\n",
            "Epochs: 97, batch: 82 loss: 0.08941999077796936\n",
            "Epochs: 97, batch: 83 loss: 0.04667693004012108\n",
            "Epochs: 97, batch: 84 loss: 0.055166758596897125\n",
            "Epochs: 97, batch: 85 loss: 0.11560391634702682\n",
            "Epochs: 97, batch: 86 loss: 0.14683464169502258\n",
            "Epochs: 97, batch: 87 loss: 0.12236098945140839\n",
            "Epochs: 97, batch: 88 loss: 0.15566599369049072\n",
            "Epochs: 97, batch: 89 loss: 0.11409832537174225\n",
            "Epochs: 97, batch: 90 loss: 0.1688002347946167\n",
            "Epochs: 97, batch: 91 loss: 0.10809951275587082\n",
            "Epochs: 97, batch: 92 loss: 0.1841614544391632\n",
            "Epochs: 97, batch: 93 loss: 0.16735956072807312\n",
            "Epochs: 97, batch: 94 loss: 0.03213348239660263\n",
            "Epochs: 97, batch: 95 loss: 0.12949196994304657\n",
            "Epochs: 97, batch: 96 loss: 0.11857093870639801\n",
            "Epochs: 97, batch: 97 loss: 0.08489824831485748\n",
            "Epochs: 97, batch: 98 loss: 0.06124000623822212\n",
            "Epochs: 97, batch: 99 loss: 0.22291618585586548\n",
            "Epochs: 97, batch: 101 loss: 0.07896173000335693\n",
            "Epochs: 97, batch: 102 loss: 0.04928645119071007\n",
            "Epochs: 97, batch: 103 loss: 0.031421951949596405\n",
            "Epochs: 97, batch: 104 loss: 0.21366283297538757\n",
            "Epochs: 97, batch: 105 loss: 0.3396497070789337\n",
            "Epochs: 97, batch: 106 loss: 0.026556815952062607\n",
            "Epochs: 97, batch: 107 loss: 0.08342361450195312\n",
            "Epochs: 97, batch: 108 loss: 0.06822235882282257\n",
            "Epochs: 97, batch: 109 loss: 0.0161050483584404\n",
            "Epochs: 97, batch: 110 loss: 0.03431091830134392\n",
            "Epochs: 97, batch: 111 loss: 0.05640791729092598\n",
            "Epochs: 97, batch: 112 loss: 0.0621720552444458\n",
            "Epochs: 97, batch: 113 loss: 0.157265767455101\n",
            "Epochs: 97, batch: 114 loss: 0.07542307674884796\n",
            "Epochs: 97, batch: 115 loss: 0.1787651777267456\n",
            "Epochs: 97, batch: 116 loss: 0.07995643466711044\n",
            "Epochs: 97, batch: 117 loss: 0.07138599455356598\n",
            "Epochs: 97, batch: 118 loss: 0.08600421249866486\n",
            "Epochs: 97, batch: 119 loss: 0.12275733053684235\n",
            "Epochs: 97, batch: 120 loss: 0.08008614927530289\n",
            "Epochs: 97, batch: 121 loss: 0.22659166157245636\n",
            "Epochs: 97, batch: 122 loss: 0.11723271012306213\n",
            "Epochs: 97, batch: 123 loss: 0.17705371975898743\n",
            "Epochs: 97, batch: 124 loss: 0.14299559593200684\n",
            "Epochs: 97, batch: 125 loss: 0.1532965749502182\n",
            "Epochs: 97, batch: 126 loss: 0.09532108902931213\n",
            "Epochs: 97, batch: 127 loss: 0.07287430018186569\n",
            "Epochs: 97, batch: 128 loss: 0.17022782564163208\n",
            "Epochs: 97, batch: 129 loss: 0.2017139494419098\n",
            "Epochs: 97, batch: 130 loss: 0.13911253213882446\n",
            "Epochs: 97, batch: 131 loss: 0.06209534406661987\n",
            "Epochs: 97, batch: 132 loss: 0.12942180037498474\n",
            "Epochs: 97, batch: 133 loss: 0.09414675831794739\n",
            "Epochs: 97, batch: 134 loss: 0.05183975398540497\n",
            "Epochs: 97, batch: 135 loss: 0.09035539627075195\n",
            "Epochs: 97, batch: 136 loss: 0.07485229521989822\n",
            "Epochs: 97, batch: 137 loss: 0.16399170458316803\n",
            "Epochs: 97, batch: 138 loss: 0.05653423070907593\n",
            "Epochs: 97, batch: 139 loss: 0.2394944280385971\n",
            "Epochs: 97, batch: 140 loss: 0.1554480642080307\n",
            "Epochs: 97, batch: 141 loss: 0.08274339884519577\n",
            "Epochs: 97, batch: 142 loss: 0.07618430256843567\n",
            "Epochs: 97, batch: 143 loss: 0.2824753522872925\n",
            "Epochs: 97, batch: 144 loss: 0.1772901564836502\n",
            "Epochs: 97, batch: 145 loss: 0.08203452080488205\n",
            "Epochs: 97, batch: 146 loss: 0.045591648668050766\n",
            "Epochs: 97, batch: 147 loss: 0.0878528282046318\n",
            "Epochs: 97, batch: 148 loss: 0.19740734994411469\n",
            "Epochs: 97, batch: 149 loss: 0.09457553923130035\n",
            "Epochs: 97, batch: 150 loss: 0.108489491045475\n",
            "Epochs: 97, batch: 151 loss: 0.11964374780654907\n",
            "Epochs: 97, batch: 152 loss: 0.08278332650661469\n",
            "Epochs: 97, batch: 153 loss: 0.1234976053237915\n",
            "Epochs: 97, batch: 154 loss: 0.1386222392320633\n",
            "Epochs: 97, batch: 155 loss: 0.0621347539126873\n",
            "Epochs: 97, batch: 156 loss: 0.08105560392141342\n",
            "Epochs: 97, batch: 157 loss: 0.11483223736286163\n",
            "Epochs: 97, batch: 158 loss: 0.17871063947677612\n",
            "Epochs: 97, batch: 159 loss: 0.07482415437698364\n",
            "Epochs: 97, batch: 160 loss: 0.05449521541595459\n",
            "Epochs: 97, batch: 161 loss: 0.07418876886367798\n",
            "Epochs: 97, batch: 162 loss: 0.2789158523082733\n",
            "Epochs: 97, batch: 163 loss: 0.24037328362464905\n",
            "Epochs: 97, batch: 164 loss: 0.1927010416984558\n",
            "Epochs: 97, batch: 165 loss: 0.1457749456167221\n",
            "Epochs: 97, batch: 166 loss: 0.14363078773021698\n",
            "Epochs: 97, batch: 167 loss: 0.07252712547779083\n",
            "Epochs: 97, batch: 168 loss: 0.12001283466815948\n",
            "Epochs: 97, batch: 169 loss: 0.1749189794063568\n",
            "Epochs: 97, batch: 170 loss: 0.252031534910202\n",
            "Epochs: 97, batch: 171 loss: 0.08905702829360962\n",
            "Epochs: 97, batch: 172 loss: 0.17427699267864227\n",
            "Epochs: 97, batch: 173 loss: 0.20237457752227783\n",
            "Epochs: 97, batch: 174 loss: 0.2199847400188446\n",
            "Epochs: 97, batch: 175 loss: 0.2627665400505066\n",
            "Epochs: 97, batch: 176 loss: 0.13601692020893097\n",
            "Epochs: 97, batch: 177 loss: 0.11130867898464203\n",
            "Epochs: 97, batch: 178 loss: 0.035255007445812225\n",
            "Epochs: 97, batch: 179 loss: 0.08870179951190948\n",
            "Epochs: 97, batch: 180 loss: 0.09047620743513107\n",
            "Epochs: 97, batch: 181 loss: 0.03639376908540726\n",
            "Epochs: 97, batch: 182 loss: 0.1710350215435028\n",
            "Epochs: 97, batch: 183 loss: 0.18046844005584717\n",
            "Epochs: 97, batch: 184 loss: 0.040892891585826874\n",
            "Epochs: 97, batch: 185 loss: 0.1117120161652565\n",
            "Epochs: 97, batch: 186 loss: 0.07285074144601822\n",
            "Epochs: 97, batch: 187 loss: 0.2725691795349121\n",
            "Epochs: 97, batch: 188 loss: 0.04840671271085739\n",
            "Epochs: 97, batch: 189 loss: 0.1374063789844513\n",
            "Epochs: 97, batch: 190 loss: 0.1189645379781723\n",
            "Epochs: 97, batch: 191 loss: 0.18171405792236328\n",
            "Epochs: 97, batch: 192 loss: 0.09676048159599304\n",
            "Epochs: 97, batch: 193 loss: 0.04695659875869751\n",
            "Epochs: 97, batch: 194 loss: 0.17676430940628052\n",
            "Epochs: 97, batch: 195 loss: 0.06367115676403046\n",
            "Epochs: 97, batch: 196 loss: 0.0805106908082962\n",
            "Epochs: 97, batch: 197 loss: 0.09198211133480072\n",
            "Epochs: 97, batch: 198 loss: 0.06178245320916176\n",
            "Epochs: 97, batch: 199 loss: 0.37718522548675537\n",
            "Epochs: 97, batch: 201 loss: 0.06136242300271988\n",
            "Epochs: 97, batch: 202 loss: 0.28428763151168823\n",
            "Epochs: 97, batch: 203 loss: 0.09071818739175797\n",
            "Epochs: 97, batch: 204 loss: 0.038631539791822433\n",
            "Epochs: 97, batch: 205 loss: 0.06095787137746811\n",
            "Epochs: 97, batch: 206 loss: 0.06452950090169907\n",
            "Epochs: 97, batch: 207 loss: 0.19592556357383728\n",
            "Epochs: 97, batch: 208 loss: 0.06943270564079285\n",
            "Epochs: 97, batch: 209 loss: 0.10666603595018387\n",
            "Epochs: 97, batch: 210 loss: 0.1529533863067627\n",
            "Epochs: 97, batch: 211 loss: 0.10676156729459763\n",
            "Epochs: 97, batch: 212 loss: 0.1981380432844162\n",
            "Epochs: 97, batch: 213 loss: 0.12033776193857193\n",
            "Epochs: 97, batch: 214 loss: 0.14955955743789673\n",
            "Epochs: 97, batch: 215 loss: 0.06228375434875488\n",
            "Epochs: 97, batch: 216 loss: 0.12362781167030334\n",
            "Epochs: 97, batch: 217 loss: 0.1276383101940155\n",
            "Epochs: 97, batch: 218 loss: 0.20672333240509033\n",
            "Epochs: 97, batch: 219 loss: 0.08839583396911621\n",
            "Epochs: 97, batch: 220 loss: 0.16760677099227905\n",
            "Epochs: 97, batch: 221 loss: 0.18245208263397217\n",
            "Epochs: 97, batch: 222 loss: 0.07261333614587784\n",
            "Epochs: 97, batch: 223 loss: 0.0626690536737442\n",
            "Epochs: 97, batch: 224 loss: 0.1375773549079895\n",
            "Epochs: 97, batch: 225 loss: 0.12632453441619873\n",
            "Epochs: 97, batch: 226 loss: 0.1286660134792328\n",
            "Epochs: 97, batch: 227 loss: 0.36182132363319397\n",
            "Epochs: 97, batch: 228 loss: 0.12198299169540405\n",
            "Epochs: 97, batch: 229 loss: 0.1263924539089203\n",
            "Epochs: 97, batch: 230 loss: 0.14231401681900024\n",
            "Epochs: 97, batch: 231 loss: 0.09127621352672577\n",
            "Epochs: 97, batch: 232 loss: 0.1712769865989685\n",
            "Epochs: 97, batch: 233 loss: 0.13060049712657928\n",
            "Epochs: 97, batch: 234 loss: 0.15572869777679443\n",
            "Epochs: 97, batch: 235 loss: 0.17089435458183289\n",
            "Epochs: 97, batch: 236 loss: 0.14439497888088226\n",
            "Epochs: 97, batch: 237 loss: 0.13064861297607422\n",
            "Epochs: 97, batch: 238 loss: 0.11167675256729126\n",
            "Epochs: 97, batch: 239 loss: 0.18391019105911255\n",
            "Epochs: 97, batch: 240 loss: 0.1363329440355301\n",
            "Epochs: 97, batch: 241 loss: 0.0558619387447834\n",
            "Epochs: 97, batch: 242 loss: 0.1431821882724762\n",
            "Epochs: 97, batch: 243 loss: 0.1681639552116394\n",
            "Epochs: 97, batch: 244 loss: 0.1768285036087036\n",
            "Epochs: 97, batch: 245 loss: 0.17086932063102722\n",
            "Epochs: 97, batch: 246 loss: 0.30515891313552856\n",
            "Epochs: 97, batch: 247 loss: 0.08768291771411896\n",
            "Epochs: 97, batch: 248 loss: 0.05619380623102188\n",
            "Epochs: 97, batch: 249 loss: 0.19203469157218933\n",
            "Epochs: 97, batch: 250 loss: 0.1092580109834671\n",
            "Epochs: 97, batch: 251 loss: 0.2235902100801468\n",
            "Epochs: 97, batch: 252 loss: 0.10049499571323395\n",
            "Epochs: 97, batch: 253 loss: 0.08020856976509094\n",
            "Epochs: 97, batch: 254 loss: 0.1719127595424652\n",
            "Epochs: 97, batch: 255 loss: 0.08322017639875412\n",
            "Epochs: 97, batch: 256 loss: 0.044620342552661896\n",
            "Epochs: 97, batch: 257 loss: 0.04308929666876793\n",
            "Epochs: 97, batch: 258 loss: 0.2181428074836731\n",
            "Epochs: 97, batch: 259 loss: 0.1327081322669983\n",
            "Epochs: 97, batch: 260 loss: 0.12448613345623016\n",
            "Epochs: 97, batch: 261 loss: 0.19896182417869568\n",
            "Epochs: 97, batch: 262 loss: 0.12057860195636749\n",
            "Epochs: 97, batch: 263 loss: 0.2185036540031433\n",
            "Epochs: 97, batch: 264 loss: 0.09903638064861298\n",
            "Epochs: 97, batch: 265 loss: 0.08321966230869293\n",
            "Epochs: 97, batch: 266 loss: 0.14381638169288635\n",
            "Epochs: 97, batch: 267 loss: 0.1278037428855896\n",
            "Epochs: 97, batch: 268 loss: 0.06344462931156158\n",
            "Epochs: 97, batch: 269 loss: 0.07602283358573914\n",
            "Epochs: 97, batch: 270 loss: 0.04533863812685013\n",
            "Epochs: 97, batch: 271 loss: 0.11110527813434601\n",
            "Epochs: 97, batch: 272 loss: 0.19448119401931763\n",
            "Epochs: 97, batch: 273 loss: 0.12740865349769592\n",
            "Epochs: 97, batch: 274 loss: 0.10431376844644547\n",
            "Epochs: 97, batch: 275 loss: 0.12644095718860626\n",
            "Epochs: 97, batch: 276 loss: 0.22067973017692566\n",
            "Epochs: 97, batch: 277 loss: 0.0626596063375473\n",
            "Epochs: 97, batch: 278 loss: 0.047499388456344604\n",
            "Epochs: 97, batch: 279 loss: 0.09397944062948227\n",
            "Epochs: 97, batch: 280 loss: 0.09017559885978699\n",
            "Epochs: 97, batch: 281 loss: 0.06426871567964554\n",
            "Epochs: 97, batch: 282 loss: 0.161798357963562\n",
            "Epochs: 97, batch: 283 loss: 0.1019856408238411\n",
            "Epochs: 97, batch: 284 loss: 0.08889299631118774\n",
            "Epochs: 97, batch: 285 loss: 0.08734022825956345\n",
            "Epochs: 97, batch: 286 loss: 0.23227235674858093\n",
            "Epochs: 97, batch: 287 loss: 0.06661580502986908\n",
            "Epochs: 97, batch: 288 loss: 0.0903652012348175\n",
            "Epochs: 97, batch: 289 loss: 0.183933287858963\n",
            "Epochs: 97, batch: 290 loss: 0.1436004638671875\n",
            "Epochs: 97, batch: 291 loss: 0.018913233652710915\n",
            "Epochs: 97, batch: 292 loss: 0.11905262619256973\n",
            "Epochs: 97, batch: 293 loss: 0.10790526866912842\n",
            "Epochs: 97, batch: 294 loss: 0.09582111239433289\n",
            "Epochs: 97, batch: 295 loss: 0.204708993434906\n",
            "Epochs: 97, batch: 296 loss: 0.09119515866041183\n",
            "Epochs: 97, batch: 297 loss: 0.08568749576807022\n",
            "Epochs: 97, batch: 298 loss: 0.1900935024023056\n",
            "Epochs: 97, batch: 299 loss: 0.12242972105741501\n",
            "Epochs: 97, batch: 301 loss: 0.12618108093738556\n",
            "Epochs: 97, batch: 302 loss: 0.20354759693145752\n",
            "Epochs: 97, batch: 303 loss: 0.0765518918633461\n",
            "Epochs: 97, batch: 304 loss: 0.10994957387447357\n",
            "Epochs: 97, batch: 305 loss: 0.08119277656078339\n",
            "Epochs: 97, batch: 306 loss: 0.05085797980427742\n",
            "Epochs: 97, batch: 307 loss: 0.07939314097166061\n",
            "Epochs: 97, batch: 308 loss: 0.05725362151861191\n",
            "Epochs: 97, batch: 309 loss: 0.11978434026241302\n",
            "Epochs: 97, batch: 310 loss: 0.18033339083194733\n",
            "Epochs: 97, batch: 311 loss: 0.061115559190511703\n",
            "Epochs: 97, batch: 312 loss: 0.03260859474539757\n",
            "Epochs: 97, batch: 313 loss: 0.1459926962852478\n",
            "Epochs: 97, batch: 314 loss: 0.0801563411951065\n",
            "Epochs: 97, batch: 315 loss: 0.06440819799900055\n",
            "Epochs: 97, batch: 316 loss: 0.15642964839935303\n",
            "Epochs: 97, batch: 317 loss: 0.09674564749002457\n",
            "Epochs: 97, batch: 318 loss: 0.10495054721832275\n",
            "Epochs: 97, batch: 319 loss: 0.17474651336669922\n",
            "Epochs: 97, batch: 320 loss: 0.15146589279174805\n",
            "Epochs: 97, batch: 321 loss: 0.09849715232849121\n",
            "Epochs: 97, batch: 322 loss: 0.07135423272848129\n",
            "Epochs: 97, batch: 323 loss: 0.1325634866952896\n",
            "Epochs: 97, batch: 324 loss: 0.11533814668655396\n",
            "Epochs: 97, batch: 325 loss: 0.09136336296796799\n",
            "Epochs: 97, batch: 326 loss: 0.08941686153411865\n",
            "Epochs: 97, batch: 327 loss: 0.17135095596313477\n",
            "Epochs: 97, batch: 328 loss: 0.25176364183425903\n",
            "Epochs: 97, batch: 329 loss: 0.0782766342163086\n",
            "Epochs: 97, batch: 330 loss: 0.14932763576507568\n",
            "Epochs: 97, batch: 331 loss: 0.17159581184387207\n",
            "Epochs: 97, batch: 332 loss: 0.15732529759407043\n",
            "Epochs: 97, batch: 333 loss: 0.12026739865541458\n",
            "Epochs: 97, batch: 334 loss: 0.13062730431556702\n",
            "Epochs: 97, batch: 335 loss: 0.14681215584278107\n",
            "Epochs: 97, batch: 336 loss: 0.19448481500148773\n",
            "Epochs: 97, batch: 337 loss: 0.116582952439785\n",
            "Epochs: 97, batch: 338 loss: 0.22324621677398682\n",
            "Epochs: 97, batch: 339 loss: 0.1345255821943283\n",
            "Epochs: 97, batch: 340 loss: 0.12095079571008682\n",
            "Epochs: 97, batch: 341 loss: 0.13310252130031586\n",
            "Epochs: 97, batch: 342 loss: 0.05867334455251694\n",
            "Epochs: 97, batch: 343 loss: 0.18186309933662415\n",
            "Epochs: 97, batch: 344 loss: 0.07697062194347382\n",
            "Epochs: 97, batch: 345 loss: 0.07217923551797867\n",
            "Epochs: 97, batch: 346 loss: 0.17481139302253723\n",
            "Epochs: 97, batch: 347 loss: 0.28150972723960876\n",
            "Epochs: 97, batch: 348 loss: 0.16994406282901764\n",
            "Epochs: 97, batch: 349 loss: 0.16924874484539032\n",
            "Epochs: 97, batch: 350 loss: 0.29548677802085876\n",
            "Epochs: 97, batch: 351 loss: 0.19010867178440094\n",
            "Epochs: 97, batch: 352 loss: 0.09109393507242203\n",
            "Epochs: 97, batch: 353 loss: 0.06579621136188507\n",
            "Epochs: 97, batch: 354 loss: 0.10701656341552734\n",
            "Epochs: 97, batch: 355 loss: 0.14055776596069336\n",
            "Epochs: 97, batch: 356 loss: 0.2898271679878235\n",
            "Epochs: 97, batch: 357 loss: 0.08741483092308044\n",
            "Epochs: 97, batch: 358 loss: 0.09040841460227966\n",
            "Epochs: 97, batch: 1 loss: 0.10542701184749603\n",
            "Epochs: 97, batch: 2 loss: 0.12291234731674194\n",
            "Epochs: 97, batch: 3 loss: 0.2695198655128479\n",
            "Epochs: 97, batch: 4 loss: 0.08004096150398254\n",
            "Epochs: 97, batch: 5 loss: 0.12582488358020782\n",
            "Epochs: 97, batch: 6 loss: 0.060645993798971176\n",
            "Epochs: 97, batch: 7 loss: 0.059741027653217316\n",
            "Epochs: 97, batch: 8 loss: 0.09053943306207657\n",
            "Epochs: 97, batch: 9 loss: 0.09617315232753754\n",
            "Epochs: 97, batch: 10 loss: 0.11279813200235367\n",
            "Epochs: 97, batch: 11 loss: 0.0686236023902893\n",
            "Epochs: 97, batch: 12 loss: 0.07977194339036942\n",
            "Epochs: 97, batch: 13 loss: 0.10799717903137207\n",
            "Epochs: 97, batch: 14 loss: 0.21758633852005005\n",
            "Epochs: 97, batch: 15 loss: 0.06016088277101517\n",
            "Epochs: 97, batch: 16 loss: 0.04488477110862732\n",
            "Epochs: 97, batch: 17 loss: 0.08154886960983276\n",
            "Epochs: 97, batch: 18 loss: 0.15010692179203033\n",
            "Epochs: 97, batch: 19 loss: 0.09769120812416077\n",
            "Epochs: 97, batch: 20 loss: 0.024792928248643875\n",
            "Epochs: 97, batch: 21 loss: 0.10803015530109406\n",
            "Epochs: 97, batch: 22 loss: 0.02515333518385887\n",
            "Epochs: 97, batch: 23 loss: 0.1136474609375\n",
            "Epochs: 97, batch: 24 loss: 0.08733221143484116\n",
            "Epochs: 97, batch: 25 loss: 0.037270013242959976\n",
            "Epochs: 97, batch: 26 loss: 0.19693222641944885\n",
            "Epochs: 97, batch: 27 loss: 0.1339646279811859\n",
            "Epochs: 97, batch: 28 loss: 0.13545891642570496\n",
            "Epochs: 97, batch: 29 loss: 0.09624700248241425\n",
            "Epochs: 97, batch: 30 loss: 0.05619490519165993\n",
            "Epochs: 97, batch: 31 loss: 0.1617613136768341\n",
            "Epochs: 97, batch: 32 loss: 0.12625116109848022\n",
            "Epochs: 97, batch: 33 loss: 0.049563929438591\n",
            "Epochs: 97, batch: 34 loss: 0.014605773612856865\n",
            "Epochs: 97, batch: 35 loss: 0.09637551009654999\n",
            "Epochs: 97, batch: 36 loss: 0.2600350081920624\n",
            "Epochs: 97, batch: 37 loss: 0.12764158844947815\n",
            "Epochs: 97, batch: 38 loss: 0.07533129304647446\n",
            "Epochs: 97, batch: 39 loss: 0.1547039896249771\n",
            "Epochs: 97, batch: 40 loss: 0.11736848950386047\n",
            "Epochs: 97, batch: 41 loss: 0.04250282794237137\n",
            "Epochs: 97, batch: 42 loss: 0.2033553123474121\n",
            "Epochs: 97, batch: 43 loss: 0.09263810515403748\n",
            "Epochs: 97, batch: 44 loss: 0.09983686357736588\n",
            "Epochs: 97, batch: 45 loss: 0.13051286339759827\n",
            "Epochs: 97, batch: 46 loss: 0.11645299196243286\n",
            "Epochs: 97, batch: 47 loss: 0.09151197969913483\n",
            "Epochs: 97, batch: 48 loss: 0.09838419407606125\n",
            "Epochs: 97, batch: 49 loss: 0.06110314279794693\n",
            "Epochs: 97, batch: 50 loss: 0.11184639483690262\n",
            "Epochs: 97, batch: 51 loss: 0.11066564917564392\n",
            "Epochs: 97, batch: 52 loss: 0.10141701996326447\n",
            "Epochs: 97, batch: 53 loss: 0.1749461591243744\n",
            "Epochs: 97, batch: 54 loss: 0.08954204618930817\n",
            "Epochs: 97, batch: 55 loss: 0.06192486733198166\n",
            "Epochs: 97, batch: 56 loss: 0.08530522882938385\n",
            "Epochs: 97, batch: 57 loss: 0.12563428282737732\n",
            "Epochs: 97, batch: 58 loss: 0.2957293689250946\n",
            "Epochs: 97, batch: 59 loss: 0.16006511449813843\n",
            "Epochs: 97, batch: 60 loss: 0.3397294878959656\n",
            "Epochs: 97, batch: 61 loss: 0.12234579026699066\n",
            "Epochs: 97, batch: 62 loss: 0.08288486301898956\n",
            "Epochs: 97, batch: 63 loss: 0.07595494389533997\n",
            "Epochs: 97, batch: 64 loss: 0.09029766172170639\n",
            "Epochs: 97, batch: 65 loss: 0.1368263065814972\n",
            "Epochs: 97, batch: 66 loss: 0.09962533414363861\n",
            "Epochs: 97, batch: 67 loss: 0.0612398162484169\n",
            "Epochs: 97, batch: 68 loss: 0.14005893468856812\n",
            "Epochs: 97, batch: 69 loss: 0.0573810413479805\n",
            "Epochs: 97, batch: 70 loss: 0.056053366512060165\n",
            "Epochs: 97, batch: 71 loss: 0.1387048214673996\n",
            "Epochs: 97, batch: 72 loss: 0.1517755538225174\n",
            "Epochs: 97, batch: 73 loss: 0.1649942696094513\n",
            "Epochs: 97, batch: 74 loss: 0.2844267785549164\n",
            "Epochs: 97, batch: 75 loss: 0.18880890309810638\n",
            "Epochs: 97, batch: 76 loss: 0.08719970285892487\n",
            "Epochs: 97, batch: 77 loss: 0.08517321944236755\n",
            "Epochs: 97, batch: 78 loss: 0.10327805578708649\n",
            "Epochs: 97, batch: 79 loss: 0.1087341159582138\n",
            "Epochs: 97, batch: 80 loss: 0.11221689730882645\n",
            "Epochs: 97, batch: 81 loss: 0.11552716046571732\n",
            "Epochs: 97, batch: 82 loss: 0.07579140365123749\n",
            "Epochs: 97, batch: 83 loss: 0.07696279138326645\n",
            "Epochs: 97, batch: 84 loss: 0.15307192504405975\n",
            "Epochs: 97, batch: 85 loss: 0.08968615531921387\n",
            "Epochs: 97, batch: 86 loss: 0.08811834454536438\n",
            "Epochs: 97, batch: 87 loss: 0.06711393594741821\n",
            "Epochs: 97, batch: 88 loss: 0.1048823818564415\n",
            "Epochs: 97, batch: 89 loss: 0.0748690664768219\n",
            "Epochs: 97, batch: 90 loss: 0.21396660804748535\n",
            "Epochs: 97, batch: 91 loss: 0.11758633702993393\n",
            "Epochs: 97, batch: 92 loss: 0.1336613893508911\n",
            "Epochs: 97, batch: 93 loss: 0.09708468616008759\n",
            "Epochs: 97, batch: 94 loss: 0.18501543998718262\n",
            "Epochs: 97, batch: 95 loss: 0.19689911603927612\n",
            "Epochs: 97, batch: 96 loss: 0.20677751302719116\n",
            "Epochs: 97, batch: 97 loss: 0.08613233268260956\n",
            "Epochs: 97, batch: 98 loss: 0.17106036841869354\n",
            "Epochs: 97, batch: 99 loss: 0.20571835339069366\n",
            "Epochs: 97, batch: 101 loss: 0.15169192850589752\n",
            "Epochs: 97, batch: 102 loss: 0.06104549393057823\n",
            "Epochs: 97, batch: 103 loss: 0.14122077822685242\n",
            "Epochs: 97, batch: 104 loss: 0.11055292934179306\n",
            "Epochs: 97, batch: 105 loss: 0.1469181329011917\n",
            "Epochs: 97, batch: 106 loss: 0.37205350399017334\n",
            "Epochs: 97, batch: 107 loss: 0.11501944065093994\n",
            "Epochs: 97, batch: 108 loss: 0.12796509265899658\n",
            "Epochs: 97, batch: 109 loss: 0.1920813024044037\n",
            "Epochs: 97, batch: 110 loss: 0.118277907371521\n",
            "Epochs: 97, batch: 111 loss: 0.07718997448682785\n",
            "Epochs: 97, batch: 112 loss: 0.061251599341630936\n",
            "Epochs: 97, batch: 113 loss: 0.11576001346111298\n",
            "Epochs: 97, batch: 114 loss: 0.05312064290046692\n",
            "Epochs: 97, batch: 115 loss: 0.1871059238910675\n",
            "Epochs: 97, batch: 116 loss: 0.07295231521129608\n",
            "Epochs: 97, batch: 117 loss: 0.17077243328094482\n",
            "Epochs: 97, batch: 118 loss: 0.05681678280234337\n",
            "Epochs: 97, batch: 119 loss: 0.14478851854801178\n",
            "Epochs: 97, batch: 120 loss: 0.05838271975517273\n",
            "Epochs: 97, batch: 121 loss: 0.20857974886894226\n",
            "Epochs: 97, batch: 122 loss: 0.10675361752510071\n",
            "Epochs: 97, batch: 123 loss: 0.07648653537034988\n",
            "Epochs: 97, batch: 124 loss: 0.25115668773651123\n",
            "Epochs: 97, batch: 125 loss: 0.16388669610023499\n",
            "Epochs: 97, batch: 126 loss: 0.0912473201751709\n",
            "Epochs: 97, batch: 127 loss: 0.09670855849981308\n",
            "Epochs: 97, batch: 128 loss: 0.12873992323875427\n",
            "Epochs: 97, batch: 129 loss: 0.0884341150522232\n",
            "Epochs: 97, batch: 130 loss: 0.07674308121204376\n",
            "Epochs: 97, batch: 131 loss: 0.02656046487390995\n",
            "Epochs: 97, batch: 132 loss: 0.12231460958719254\n",
            "Epochs: 97, batch: 133 loss: 0.07799011468887329\n",
            "Epochs: 97, batch: 134 loss: 0.1469569057226181\n",
            "Epochs: 97, batch: 135 loss: 0.055441197007894516\n",
            "Epochs: 97, batch: 136 loss: 0.21624308824539185\n",
            "Epochs: 97, batch: 137 loss: 0.0823802798986435\n",
            "Epochs: 97, batch: 138 loss: 0.09198059141635895\n",
            "Epochs: 97, batch: 139 loss: 0.06752368807792664\n",
            "Epochs: 97, batch: 140 loss: 0.07500022649765015\n",
            "Epochs: 97, batch: 141 loss: 0.1615694761276245\n",
            "Epochs: 97, batch: 142 loss: 0.04071022942662239\n",
            "Epochs: 97, batch: 143 loss: 0.09354552626609802\n",
            "Epochs: 97, batch: 144 loss: 0.1346290409564972\n",
            "Epochs: 97, batch: 145 loss: 0.09663847088813782\n",
            "Epochs: 97, batch: 146 loss: 0.12282542139291763\n",
            "Epochs: 97, batch: 147 loss: 0.09112437069416046\n",
            "Epochs: 97, batch: 148 loss: 0.24098920822143555\n",
            "Epochs: 97, batch: 149 loss: 0.3404080271720886\n",
            "Epochs: 97, batch: 150 loss: 0.08776383846998215\n",
            "Epochs: 97, batch: 151 loss: 0.06420951336622238\n",
            "Epochs: 97, batch: 152 loss: 0.028338978067040443\n",
            "Epochs: 97, batch: 153 loss: 0.10942276567220688\n",
            "Epochs: 97, batch: 154 loss: 0.11888360232114792\n",
            "Epochs: 97, batch: 155 loss: 0.09737367928028107\n",
            "Epochs: 97, batch: 156 loss: 0.116322822868824\n",
            "Epochs: 97, batch: 157 loss: 0.1355786919593811\n",
            "Epochs: 97, batch: 158 loss: 0.1369389295578003\n",
            "Epochs: 97, batch: 159 loss: 0.2045559138059616\n",
            "Epochs: 97, batch: 160 loss: 0.08695743978023529\n",
            "Epochs: 97, batch: 161 loss: 0.21308553218841553\n",
            "Epochs: 97, batch: 162 loss: 0.10781758278608322\n",
            "Epochs: 97, batch: 163 loss: 0.05026824399828911\n",
            "Epochs: 97, batch: 164 loss: 0.12352399528026581\n",
            "Epochs: 97, batch: 165 loss: 0.14106819033622742\n",
            "Epochs: 97, batch: 166 loss: 0.13732199370861053\n",
            "Epochs: 97, batch: 167 loss: 0.08642329275608063\n",
            "Epochs: 97, batch: 168 loss: 0.15017981827259064\n",
            "Epochs: 97, batch: 169 loss: 0.051240257918834686\n",
            "Epochs: 97, batch: 170 loss: 0.11505242437124252\n",
            "Epochs: 97, batch: 171 loss: 0.15816248953342438\n",
            "Epochs: 97, batch: 172 loss: 0.1590798795223236\n",
            "Epochs: 97, batch: 173 loss: 0.09570302069187164\n",
            "Epochs: 97, batch: 174 loss: 0.05998478829860687\n",
            "Epochs: 97, batch: 175 loss: 0.0382804349064827\n",
            "Epochs: 97, batch: 176 loss: 0.0809890627861023\n",
            "Epochs: 97, batch: 177 loss: 0.0710831731557846\n",
            "Epochs: 97, batch: 178 loss: 0.09293154627084732\n",
            "Epochs: 97, batch: 179 loss: 0.19859622418880463\n",
            "Epochs: 97, batch: 180 loss: 0.09740579128265381\n",
            "Epochs: 97, batch: 181 loss: 0.07921397686004639\n",
            "Epochs: 97, batch: 182 loss: 0.06463716179132462\n",
            "Epochs: 97, batch: 183 loss: 0.055955417454242706\n",
            "Epochs: 97, batch: 184 loss: 0.06995013356208801\n",
            "Epochs: 97, batch: 185 loss: 0.04256296157836914\n",
            "Epochs: 97, batch: 186 loss: 0.06350909173488617\n",
            "Epochs: 97, batch: 187 loss: 0.06968341767787933\n",
            "Epochs: 97, batch: 188 loss: 0.03645564615726471\n",
            "Epochs: 97, batch: 189 loss: 0.07965227216482162\n",
            "Epochs: 97, batch: 190 loss: 0.0395713746547699\n",
            "Epochs: 97, batch: 191 loss: 0.11248432844877243\n",
            "Epochs: 97, batch: 192 loss: 0.17038053274154663\n",
            "Epochs: 97, batch: 193 loss: 0.09574533253908157\n",
            "Epochs: 97, batch: 194 loss: 0.0567118301987648\n",
            "Epochs: 97, batch: 195 loss: 0.11491179466247559\n",
            "Epochs: 97, batch: 196 loss: 0.04610003903508186\n",
            "Epochs: 97, batch: 197 loss: 0.06872803717851639\n",
            "Epochs: 97, batch: 198 loss: 0.07922473549842834\n",
            "Epochs: 97, batch: 199 loss: 0.07593420147895813\n",
            "Epochs: 97, batch: 201 loss: 0.16824641823768616\n",
            "Epochs: 97, batch: 202 loss: 0.13973206281661987\n",
            "Epochs: 97, batch: 203 loss: 0.06295564770698547\n",
            "Epochs: 97, batch: 204 loss: 0.09634971618652344\n",
            "Epochs: 97, batch: 205 loss: 0.12131201475858688\n",
            "Epochs: 97, batch: 206 loss: 0.1837121844291687\n",
            "Epochs: 97, batch: 207 loss: 0.13974609971046448\n",
            "Epochs: 97, batch: 208 loss: 0.20887312293052673\n",
            "Epochs: 97, batch: 209 loss: 0.09409668296575546\n",
            "Epochs: 97, batch: 210 loss: 0.08491561561822891\n",
            "Epochs: 97, batch: 211 loss: 0.05606023967266083\n",
            "Epochs: 97, batch: 212 loss: 0.06859032809734344\n",
            "Epochs: 97, batch: 213 loss: 0.2225719690322876\n",
            "Epochs: 97, batch: 214 loss: 0.1458597034215927\n",
            "Epochs: 97, batch: 215 loss: 0.09118323028087616\n",
            "Epochs: 97, batch: 216 loss: 0.1714964210987091\n",
            "Epochs: 97, batch: 217 loss: 0.10915812849998474\n",
            "Epochs: 97, batch: 218 loss: 0.11780688166618347\n",
            "Epochs: 97, batch: 219 loss: 0.10494519770145416\n",
            "Epochs: 97, batch: 220 loss: 0.11777058243751526\n",
            "Epochs: 97, batch: 221 loss: 0.11341941356658936\n",
            "Epochs: 97, batch: 222 loss: 0.20749977231025696\n",
            "Epochs: 97, batch: 223 loss: 0.023779146373271942\n",
            "Epochs: 97, batch: 224 loss: 0.039884984493255615\n",
            "Epochs: 97, batch: 225 loss: 0.0768715888261795\n",
            "Epochs: 97, batch: 226 loss: 0.07682686299085617\n",
            "Epochs: 97, batch: 227 loss: 0.18479835987091064\n",
            "Epochs: 97, batch: 228 loss: 0.062224164605140686\n",
            "Epochs: 97, batch: 229 loss: 0.12887068092823029\n",
            "Epochs: 97, batch: 230 loss: 0.1339474618434906\n",
            "Epochs: 97, batch: 231 loss: 0.08642750978469849\n",
            "Epochs: 97, batch: 232 loss: 0.10167261958122253\n",
            "Epochs: 97, batch: 233 loss: 0.21332287788391113\n",
            "Epochs: 97, batch: 234 loss: 0.16748106479644775\n",
            "Epochs: 97, batch: 235 loss: 0.1472882777452469\n",
            "Epochs: 97, batch: 236 loss: 0.273396372795105\n",
            "Epochs: 97, batch: 237 loss: 0.0562739372253418\n",
            "Epochs: 97, batch: 238 loss: 0.11607109010219574\n",
            "Epochs: 97, batch: 239 loss: 0.18072643876075745\n",
            "Epochs: 97, batch: 240 loss: 0.041281428188085556\n",
            "Epochs: 97, batch: 241 loss: 0.09835823625326157\n",
            "Epochs: 97, batch: 242 loss: 0.05715453624725342\n",
            "Epochs: 97, batch: 243 loss: 0.0629241019487381\n",
            "Epochs: 97, batch: 244 loss: 0.07429790496826172\n",
            "Epochs: 97, batch: 245 loss: 0.10078687965869904\n",
            "Epochs: 97, batch: 246 loss: 0.09301654994487762\n",
            "Epochs: 97, batch: 247 loss: 0.07853593677282333\n",
            "Epochs: 97, batch: 248 loss: 0.12143518775701523\n",
            "Epochs: 97, batch: 249 loss: 0.15382647514343262\n",
            "Epochs: 97, batch: 250 loss: 0.1070924773812294\n",
            "Epochs: 97, batch: 251 loss: 0.12533819675445557\n",
            "Epochs: 97, batch: 252 loss: 0.11793254315853119\n",
            "Epochs: 97, batch: 253 loss: 0.08024570345878601\n",
            "Epochs: 97, batch: 254 loss: 0.08725299686193466\n",
            "Epochs: 97, batch: 255 loss: 0.15998466312885284\n",
            "Epochs: 97, batch: 256 loss: 0.10928382724523544\n",
            "Epochs: 97, batch: 257 loss: 0.08216702938079834\n",
            "Epochs: 97, batch: 258 loss: 0.16163519024848938\n",
            "Epochs: 97, batch: 259 loss: 0.24166423082351685\n",
            "Epochs: 97, batch: 260 loss: 0.12813858687877655\n",
            "Epochs: 97, batch: 261 loss: 0.10863638669252396\n",
            "Epochs: 97, batch: 262 loss: 0.14455938339233398\n",
            "Epochs: 97, batch: 263 loss: 0.19818168878555298\n",
            "Epochs: 97, batch: 264 loss: 0.10324769467115402\n",
            "Epochs: 97, batch: 265 loss: 0.08365878462791443\n",
            "Epochs: 97, batch: 266 loss: 0.2836741805076599\n",
            "Epochs: 97, batch: 267 loss: 0.04662639647722244\n",
            "Epochs: 97, batch: 268 loss: 0.06053907796740532\n",
            "Epochs: 97, batch: 269 loss: 0.10586626827716827\n",
            "Epochs: 97, batch: 270 loss: 0.0626746341586113\n",
            "Epochs: 97, batch: 271 loss: 0.16253316402435303\n",
            "Epochs: 97, batch: 272 loss: 0.09605221450328827\n",
            "Epochs: 97, batch: 273 loss: 0.10589919984340668\n",
            "Epochs: 97, batch: 274 loss: 0.08344529569149017\n",
            "Epochs: 97, batch: 275 loss: 0.06164182722568512\n",
            "Epochs: 97, batch: 276 loss: 0.16886629164218903\n",
            "Epochs: 97, batch: 277 loss: 0.10196838527917862\n",
            "Epochs: 97, batch: 278 loss: 0.05712248012423515\n",
            "Epochs: 97, batch: 279 loss: 0.05793973058462143\n",
            "Epochs: 97, batch: 280 loss: 0.06334920227527618\n",
            "Epochs: 97, batch: 281 loss: 0.2859102487564087\n",
            "Epochs: 97, batch: 282 loss: 0.0827534943819046\n",
            "Epochs: 97, batch: 283 loss: 0.09950344264507294\n",
            "Epochs: 97, batch: 284 loss: 0.07407522946596146\n",
            "Epochs: 97, batch: 285 loss: 0.09542115032672882\n",
            "Epochs: 97, batch: 286 loss: 0.16938212513923645\n",
            "Epochs: 97, batch: 287 loss: 0.1537964642047882\n",
            "Epochs: 97, batch: 288 loss: 0.16119500994682312\n",
            "Epochs: 97, batch: 289 loss: 0.15634244680404663\n",
            "Epochs: 97, batch: 290 loss: 0.10367175936698914\n",
            "Epochs: 97, batch: 291 loss: 0.2170221507549286\n",
            "Epochs: 97, batch: 292 loss: 0.06677266210317612\n",
            "Epochs: 97, batch: 293 loss: 0.20938891172409058\n",
            "Epochs: 97, batch: 294 loss: 0.14461377263069153\n",
            "Epochs: 97, batch: 295 loss: 0.06565991044044495\n",
            "Epochs: 97, batch: 296 loss: 0.2884591817855835\n",
            "Epochs: 97, batch: 297 loss: 0.07394785434007645\n",
            "Epochs: 97, batch: 298 loss: 0.11706757545471191\n",
            "Epochs: 97, batch: 299 loss: 0.06409075111150742\n",
            "Epochs: 97, batch: 301 loss: 0.0994911938905716\n",
            "Epochs: 97, batch: 302 loss: 0.16643525660037994\n",
            "Epochs: 97, batch: 303 loss: 0.12815746665000916\n",
            "Epochs: 97, batch: 304 loss: 0.1313663125038147\n",
            "Epochs: 97, batch: 305 loss: 0.1465880274772644\n",
            "Epochs: 97, batch: 306 loss: 0.1374366283416748\n",
            "Epochs: 97, batch: 307 loss: 0.16388431191444397\n",
            "Epochs: 97, batch: 308 loss: 0.2371019423007965\n",
            "Epochs: 97, batch: 309 loss: 0.1067342683672905\n",
            "Epochs: 97, batch: 310 loss: 0.10052217543125153\n",
            "Epochs: 97, batch: 311 loss: 0.15124374628067017\n",
            "Epochs: 97, batch: 312 loss: 0.04252728819847107\n",
            "Epochs: 97, batch: 313 loss: 0.07874512672424316\n",
            "Epochs: 97, batch: 314 loss: 0.12840327620506287\n",
            "Epochs: 97, batch: 315 loss: 0.22672909498214722\n",
            "Epochs: 97, batch: 316 loss: 0.11862945556640625\n",
            "Epochs: 97, batch: 317 loss: 0.1206316128373146\n",
            "Epochs: 97, batch: 318 loss: 0.04183623194694519\n",
            "Epochs: 97, batch: 319 loss: 0.0466882586479187\n",
            "Epochs: 97, batch: 320 loss: 0.16228324174880981\n",
            "Epochs: 97, batch: 321 loss: 0.10576297342777252\n",
            "Epochs: 97, batch: 322 loss: 0.05023690313100815\n",
            "Epochs: 97, batch: 323 loss: 0.15970931947231293\n",
            "Epochs: 97, batch: 324 loss: 0.0725296288728714\n",
            "Epochs: 97, batch: 325 loss: 0.07720206677913666\n",
            "Epochs: 97, batch: 326 loss: 0.2151864767074585\n",
            "Epochs: 97, batch: 327 loss: 0.041072577238082886\n",
            "Epochs: 97, batch: 328 loss: 0.09330226480960846\n",
            "Epochs: 97, batch: 329 loss: 0.1426696479320526\n",
            "Epochs: 97, batch: 330 loss: 0.10734786093235016\n",
            "Epochs: 97, batch: 331 loss: 0.0690336525440216\n",
            "Epochs: 97, batch: 332 loss: 0.08375540375709534\n",
            "Epochs: 97, batch: 333 loss: 0.06449096649885178\n",
            "Epochs: 97, batch: 334 loss: 0.13156138360500336\n",
            "Epochs: 97, batch: 335 loss: 0.05673354119062424\n",
            "Epochs: 97, batch: 336 loss: 0.07740317285060883\n",
            "Epochs: 97, batch: 337 loss: 0.12114710360765457\n",
            "Epochs: 97, batch: 338 loss: 0.09233607351779938\n",
            "Epochs: 97, batch: 339 loss: 0.06852518767118454\n",
            "Epochs: 97, batch: 340 loss: 0.04035934805870056\n",
            "Epochs: 97, batch: 341 loss: 0.089573934674263\n",
            "Epochs: 97, batch: 342 loss: 0.11595362424850464\n",
            "Epochs: 97, batch: 343 loss: 0.13252218067646027\n",
            "Epochs: 97, batch: 344 loss: 0.09608690440654755\n",
            "Epochs: 97, batch: 345 loss: 0.05065961182117462\n",
            "Epochs: 97, batch: 346 loss: 0.18356242775917053\n",
            "Epochs: 97, batch: 347 loss: 0.16907775402069092\n",
            "Epochs: 97, batch: 348 loss: 0.11201779544353485\n",
            "Epochs: 97, batch: 349 loss: 0.12624657154083252\n",
            "Epochs: 97, batch: 350 loss: 0.24164506793022156\n",
            "Epochs: 97, batch: 351 loss: 0.1536627560853958\n",
            "Epochs: 97, batch: 352 loss: 0.11081544309854507\n",
            "Epochs: 97, batch: 353 loss: 0.05463125556707382\n",
            "Epochs: 97, batch: 354 loss: 0.07254534959793091\n",
            "Epochs: 97, batch: 355 loss: 0.24491164088249207\n",
            "Epochs: 97, batch: 356 loss: 0.049621544778347015\n",
            "Epochs: 97, batch: 357 loss: 0.2300349324941635\n",
            "Epochs: 97, batch: 358 loss: 0.005224992986768484\n",
            "Epochs: 98, batch: 1 loss: 0.09053531289100647\n",
            "Epochs: 98, batch: 2 loss: 0.036939769983291626\n",
            "Epochs: 98, batch: 3 loss: 0.14734871685504913\n",
            "Epochs: 98, batch: 4 loss: 0.25051790475845337\n",
            "Epochs: 98, batch: 5 loss: 0.10910437256097794\n",
            "Epochs: 98, batch: 6 loss: 0.11044647544622421\n",
            "Epochs: 98, batch: 7 loss: 0.0723525807261467\n",
            "Epochs: 98, batch: 8 loss: 0.07376350462436676\n",
            "Epochs: 98, batch: 9 loss: 0.18584081530570984\n",
            "Epochs: 98, batch: 10 loss: 0.11172100901603699\n",
            "Epochs: 98, batch: 11 loss: 0.042196646332740784\n",
            "Epochs: 98, batch: 12 loss: 0.05538921058177948\n",
            "Epochs: 98, batch: 13 loss: 0.050380513072013855\n",
            "Epochs: 98, batch: 14 loss: 0.06398055702447891\n",
            "Epochs: 98, batch: 15 loss: 0.07419969141483307\n",
            "Epochs: 98, batch: 16 loss: 0.14402693510055542\n",
            "Epochs: 98, batch: 17 loss: 0.12295588105916977\n",
            "Epochs: 98, batch: 18 loss: 0.069501593708992\n",
            "Epochs: 98, batch: 19 loss: 0.09206455945968628\n",
            "Epochs: 98, batch: 20 loss: 0.14368876814842224\n",
            "Epochs: 98, batch: 21 loss: 0.18482503294944763\n",
            "Epochs: 98, batch: 22 loss: 0.16701272130012512\n",
            "Epochs: 98, batch: 23 loss: 0.12951445579528809\n",
            "Epochs: 98, batch: 24 loss: 0.024728907272219658\n",
            "Epochs: 98, batch: 25 loss: 0.17176687717437744\n",
            "Epochs: 98, batch: 26 loss: 0.1078292578458786\n",
            "Epochs: 98, batch: 27 loss: 0.23698857426643372\n",
            "Epochs: 98, batch: 28 loss: 0.06016811728477478\n",
            "Epochs: 98, batch: 29 loss: 0.1992720365524292\n",
            "Epochs: 98, batch: 30 loss: 0.1162838339805603\n",
            "Epochs: 98, batch: 31 loss: 0.11445561051368713\n",
            "Epochs: 98, batch: 32 loss: 0.07731372863054276\n",
            "Epochs: 98, batch: 33 loss: 0.10553892701864243\n",
            "Epochs: 98, batch: 34 loss: 0.10460115969181061\n",
            "Epochs: 98, batch: 35 loss: 0.09282928705215454\n",
            "Epochs: 98, batch: 36 loss: 0.09492002427577972\n",
            "Epochs: 98, batch: 37 loss: 0.03082703799009323\n",
            "Epochs: 98, batch: 38 loss: 0.04655073583126068\n",
            "Epochs: 98, batch: 39 loss: 0.07941664755344391\n",
            "Epochs: 98, batch: 40 loss: 0.09778089821338654\n",
            "Epochs: 98, batch: 41 loss: 0.0654740035533905\n",
            "Epochs: 98, batch: 42 loss: 0.17082400619983673\n",
            "Epochs: 98, batch: 43 loss: 0.07205997407436371\n",
            "Epochs: 98, batch: 44 loss: 0.030305232852697372\n",
            "Epochs: 98, batch: 45 loss: 0.18951226770877838\n",
            "Epochs: 98, batch: 46 loss: 0.1042732298374176\n",
            "Epochs: 98, batch: 47 loss: 0.06687012314796448\n",
            "Epochs: 98, batch: 48 loss: 0.1247568279504776\n",
            "Epochs: 98, batch: 49 loss: 0.10820457339286804\n",
            "Epochs: 98, batch: 50 loss: 0.23464816808700562\n",
            "Epochs: 98, batch: 51 loss: 0.049194686114788055\n",
            "Epochs: 98, batch: 52 loss: 0.12686777114868164\n",
            "Epochs: 98, batch: 53 loss: 0.0533672459423542\n",
            "Epochs: 98, batch: 54 loss: 0.23307552933692932\n",
            "Epochs: 98, batch: 55 loss: 0.16160471737384796\n",
            "Epochs: 98, batch: 56 loss: 0.06732294708490372\n",
            "Epochs: 98, batch: 57 loss: 0.03526116535067558\n",
            "Epochs: 98, batch: 58 loss: 0.08085110783576965\n",
            "Epochs: 98, batch: 59 loss: 0.18886637687683105\n",
            "Epochs: 98, batch: 60 loss: 0.2383849173784256\n",
            "Epochs: 98, batch: 61 loss: 0.23366263508796692\n",
            "Epochs: 98, batch: 62 loss: 0.09600977599620819\n",
            "Epochs: 98, batch: 63 loss: 0.0765729695558548\n",
            "Epochs: 98, batch: 64 loss: 0.1064172089099884\n",
            "Epochs: 98, batch: 65 loss: 0.15928004682064056\n",
            "Epochs: 98, batch: 66 loss: 0.10047632455825806\n",
            "Epochs: 98, batch: 67 loss: 0.16260312497615814\n",
            "Epochs: 98, batch: 68 loss: 0.08196675777435303\n",
            "Epochs: 98, batch: 69 loss: 0.04732900857925415\n",
            "Epochs: 98, batch: 70 loss: 0.09656743705272675\n",
            "Epochs: 98, batch: 71 loss: 0.09480691701173782\n",
            "Epochs: 98, batch: 72 loss: 0.2823936939239502\n",
            "Epochs: 98, batch: 73 loss: 0.11651894450187683\n",
            "Epochs: 98, batch: 74 loss: 0.13094331324100494\n",
            "Epochs: 98, batch: 75 loss: 0.12624843418598175\n",
            "Epochs: 98, batch: 76 loss: 0.13845457136631012\n",
            "Epochs: 98, batch: 77 loss: 0.26086103916168213\n",
            "Epochs: 98, batch: 78 loss: 0.1644577831029892\n",
            "Epochs: 98, batch: 79 loss: 0.1105131208896637\n",
            "Epochs: 98, batch: 80 loss: 0.08680468052625656\n",
            "Epochs: 98, batch: 81 loss: 0.18819847702980042\n",
            "Epochs: 98, batch: 82 loss: 0.11736398190259933\n",
            "Epochs: 98, batch: 83 loss: 0.05608615651726723\n",
            "Epochs: 98, batch: 84 loss: 0.05402472987771034\n",
            "Epochs: 98, batch: 85 loss: 0.01571032777428627\n",
            "Epochs: 98, batch: 86 loss: 0.046285487711429596\n",
            "Epochs: 98, batch: 87 loss: 0.15598762035369873\n",
            "Epochs: 98, batch: 88 loss: 0.1773228496313095\n",
            "Epochs: 98, batch: 89 loss: 0.10504819452762604\n",
            "Epochs: 98, batch: 90 loss: 0.09305017441511154\n",
            "Epochs: 98, batch: 91 loss: 0.10739248245954514\n",
            "Epochs: 98, batch: 92 loss: 0.057899635285139084\n",
            "Epochs: 98, batch: 93 loss: 0.10645636916160583\n",
            "Epochs: 98, batch: 94 loss: 0.11995130777359009\n",
            "Epochs: 98, batch: 95 loss: 0.1350090354681015\n",
            "Epochs: 98, batch: 96 loss: 0.23221807181835175\n",
            "Epochs: 98, batch: 97 loss: 0.10566523671150208\n",
            "Epochs: 98, batch: 98 loss: 0.08029645681381226\n",
            "Epochs: 98, batch: 99 loss: 0.10798736661672592\n",
            "Epochs: 98, batch: 101 loss: 0.11141372472047806\n",
            "Epochs: 98, batch: 102 loss: 0.14321686327457428\n",
            "Epochs: 98, batch: 103 loss: 0.07847443222999573\n",
            "Epochs: 98, batch: 104 loss: 0.08866490423679352\n",
            "Epochs: 98, batch: 105 loss: 0.16487938165664673\n",
            "Epochs: 98, batch: 106 loss: 0.058297548443078995\n",
            "Epochs: 98, batch: 107 loss: 0.06702903658151627\n",
            "Epochs: 98, batch: 108 loss: 0.2622797191143036\n",
            "Epochs: 98, batch: 109 loss: 0.08858822286128998\n",
            "Epochs: 98, batch: 110 loss: 0.0642852708697319\n",
            "Epochs: 98, batch: 111 loss: 0.06661312282085419\n",
            "Epochs: 98, batch: 112 loss: 0.08893286436796188\n",
            "Epochs: 98, batch: 113 loss: 0.14379650354385376\n",
            "Epochs: 98, batch: 114 loss: 0.06539163738489151\n",
            "Epochs: 98, batch: 115 loss: 0.04479379951953888\n",
            "Epochs: 98, batch: 116 loss: 0.15692853927612305\n",
            "Epochs: 98, batch: 117 loss: 0.2113831341266632\n",
            "Epochs: 98, batch: 118 loss: 0.252227783203125\n",
            "Epochs: 98, batch: 119 loss: 0.08709222078323364\n",
            "Epochs: 98, batch: 120 loss: 0.11431047320365906\n",
            "Epochs: 98, batch: 121 loss: 0.2611699104309082\n",
            "Epochs: 98, batch: 122 loss: 0.17806795239448547\n",
            "Epochs: 98, batch: 123 loss: 0.04897303879261017\n",
            "Epochs: 98, batch: 124 loss: 0.2150121033191681\n",
            "Epochs: 98, batch: 125 loss: 0.21492871642112732\n",
            "Epochs: 98, batch: 126 loss: 0.12908285856246948\n",
            "Epochs: 98, batch: 127 loss: 0.11207902431488037\n",
            "Epochs: 98, batch: 128 loss: 0.14473941922187805\n",
            "Epochs: 98, batch: 129 loss: 0.15697355568408966\n",
            "Epochs: 98, batch: 130 loss: 0.09025099873542786\n",
            "Epochs: 98, batch: 131 loss: 0.09555234760046005\n",
            "Epochs: 98, batch: 132 loss: 0.0909612625837326\n",
            "Epochs: 98, batch: 133 loss: 0.10022537410259247\n",
            "Epochs: 98, batch: 134 loss: 0.18491633236408234\n",
            "Epochs: 98, batch: 135 loss: 0.08786872029304504\n",
            "Epochs: 98, batch: 136 loss: 0.19586434960365295\n",
            "Epochs: 98, batch: 137 loss: 0.05888795852661133\n",
            "Epochs: 98, batch: 138 loss: 0.06916356086730957\n",
            "Epochs: 98, batch: 139 loss: 0.15004155039787292\n",
            "Epochs: 98, batch: 140 loss: 0.12758220732212067\n",
            "Epochs: 98, batch: 141 loss: 0.1621343195438385\n",
            "Epochs: 98, batch: 142 loss: 0.06671810150146484\n",
            "Epochs: 98, batch: 143 loss: 0.050875719636678696\n",
            "Epochs: 98, batch: 144 loss: 0.07692001014947891\n",
            "Epochs: 98, batch: 145 loss: 0.054410360753536224\n",
            "Epochs: 98, batch: 146 loss: 0.11560025066137314\n",
            "Epochs: 98, batch: 147 loss: 0.16895627975463867\n",
            "Epochs: 98, batch: 148 loss: 0.09865735471248627\n",
            "Epochs: 98, batch: 149 loss: 0.08489740639925003\n",
            "Epochs: 98, batch: 150 loss: 0.1675843894481659\n",
            "Epochs: 98, batch: 151 loss: 0.2766319513320923\n",
            "Epochs: 98, batch: 152 loss: 0.08114665746688843\n",
            "Epochs: 98, batch: 153 loss: 0.15247198939323425\n",
            "Epochs: 98, batch: 154 loss: 0.038858283311128616\n",
            "Epochs: 98, batch: 155 loss: 0.08318431675434113\n",
            "Epochs: 98, batch: 156 loss: 0.04546773061156273\n",
            "Epochs: 98, batch: 157 loss: 0.10496198385953903\n",
            "Epochs: 98, batch: 158 loss: 0.1457570493221283\n",
            "Epochs: 98, batch: 159 loss: 0.15450747311115265\n",
            "Epochs: 98, batch: 160 loss: 0.14560425281524658\n",
            "Epochs: 98, batch: 161 loss: 0.10283856093883514\n",
            "Epochs: 98, batch: 162 loss: 0.08013024181127548\n",
            "Epochs: 98, batch: 163 loss: 0.11009678244590759\n",
            "Epochs: 98, batch: 164 loss: 0.06940315663814545\n",
            "Epochs: 98, batch: 165 loss: 0.11548078060150146\n",
            "Epochs: 98, batch: 166 loss: 0.1027316153049469\n",
            "Epochs: 98, batch: 167 loss: 0.18324735760688782\n",
            "Epochs: 98, batch: 168 loss: 0.197637677192688\n",
            "Epochs: 98, batch: 169 loss: 0.2487027794122696\n",
            "Epochs: 98, batch: 170 loss: 0.046809516847133636\n",
            "Epochs: 98, batch: 171 loss: 0.07046729326248169\n",
            "Epochs: 98, batch: 172 loss: 0.18079686164855957\n",
            "Epochs: 98, batch: 173 loss: 0.06424084305763245\n",
            "Epochs: 98, batch: 174 loss: 0.08651170134544373\n",
            "Epochs: 98, batch: 175 loss: 0.07264917343854904\n",
            "Epochs: 98, batch: 176 loss: 0.07263434678316116\n",
            "Epochs: 98, batch: 177 loss: 0.16452661156654358\n",
            "Epochs: 98, batch: 178 loss: 0.04165160283446312\n",
            "Epochs: 98, batch: 179 loss: 0.09832906723022461\n",
            "Epochs: 98, batch: 180 loss: 0.12739984691143036\n",
            "Epochs: 98, batch: 181 loss: 0.23378720879554749\n",
            "Epochs: 98, batch: 182 loss: 0.05856645479798317\n",
            "Epochs: 98, batch: 183 loss: 0.0874711126089096\n",
            "Epochs: 98, batch: 184 loss: 0.05619439482688904\n",
            "Epochs: 98, batch: 185 loss: 0.07617136836051941\n",
            "Epochs: 98, batch: 186 loss: 0.1485132873058319\n",
            "Epochs: 98, batch: 187 loss: 0.19276940822601318\n",
            "Epochs: 98, batch: 188 loss: 0.2724184989929199\n",
            "Epochs: 98, batch: 189 loss: 0.14903831481933594\n",
            "Epochs: 98, batch: 190 loss: 0.11701696366071701\n",
            "Epochs: 98, batch: 191 loss: 0.13645468652248383\n",
            "Epochs: 98, batch: 192 loss: 0.0550859309732914\n",
            "Epochs: 98, batch: 193 loss: 0.09065937995910645\n",
            "Epochs: 98, batch: 194 loss: 0.1500272899866104\n",
            "Epochs: 98, batch: 195 loss: 0.22459867596626282\n",
            "Epochs: 98, batch: 196 loss: 0.1367444396018982\n",
            "Epochs: 98, batch: 197 loss: 0.21123427152633667\n",
            "Epochs: 98, batch: 198 loss: 0.2471422553062439\n",
            "Epochs: 98, batch: 199 loss: 0.1354692429304123\n",
            "Epochs: 98, batch: 201 loss: 0.03763401508331299\n",
            "Epochs: 98, batch: 202 loss: 0.05885456129908562\n",
            "Epochs: 98, batch: 203 loss: 0.167287677526474\n",
            "Epochs: 98, batch: 204 loss: 0.07684352993965149\n",
            "Epochs: 98, batch: 205 loss: 0.06347362697124481\n",
            "Epochs: 98, batch: 206 loss: 0.15145337581634521\n",
            "Epochs: 98, batch: 207 loss: 0.07288651168346405\n",
            "Epochs: 98, batch: 208 loss: 0.11947324126958847\n",
            "Epochs: 98, batch: 209 loss: 0.033644262701272964\n",
            "Epochs: 98, batch: 210 loss: 0.2466951310634613\n",
            "Epochs: 98, batch: 211 loss: 0.2397211790084839\n",
            "Epochs: 98, batch: 212 loss: 0.1197114884853363\n",
            "Epochs: 98, batch: 213 loss: 0.07784630358219147\n",
            "Epochs: 98, batch: 214 loss: 0.10943938791751862\n",
            "Epochs: 98, batch: 215 loss: 0.1671377420425415\n",
            "Epochs: 98, batch: 216 loss: 0.09694458544254303\n",
            "Epochs: 98, batch: 217 loss: 0.05145611613988876\n",
            "Epochs: 98, batch: 218 loss: 0.038771852850914\n",
            "Epochs: 98, batch: 219 loss: 0.12888506054878235\n",
            "Epochs: 98, batch: 220 loss: 0.08995518088340759\n",
            "Epochs: 98, batch: 221 loss: 0.16939614713191986\n",
            "Epochs: 98, batch: 222 loss: 0.19401328265666962\n",
            "Epochs: 98, batch: 223 loss: 0.07842469215393066\n",
            "Epochs: 98, batch: 224 loss: 0.17478162050247192\n",
            "Epochs: 98, batch: 225 loss: 0.07078393548727036\n",
            "Epochs: 98, batch: 226 loss: 0.3419700860977173\n",
            "Epochs: 98, batch: 227 loss: 0.231001079082489\n",
            "Epochs: 98, batch: 228 loss: 0.16436636447906494\n",
            "Epochs: 98, batch: 229 loss: 0.17928820848464966\n",
            "Epochs: 98, batch: 230 loss: 0.04248347505927086\n",
            "Epochs: 98, batch: 231 loss: 0.04667497053742409\n",
            "Epochs: 98, batch: 232 loss: 0.13441644608974457\n",
            "Epochs: 98, batch: 233 loss: 0.13969376683235168\n",
            "Epochs: 98, batch: 234 loss: 0.1251811385154724\n",
            "Epochs: 98, batch: 235 loss: 0.16180801391601562\n",
            "Epochs: 98, batch: 236 loss: 0.14081573486328125\n",
            "Epochs: 98, batch: 237 loss: 0.11197534203529358\n",
            "Epochs: 98, batch: 238 loss: 0.12177029252052307\n",
            "Epochs: 98, batch: 239 loss: 0.050298623740673065\n",
            "Epochs: 98, batch: 240 loss: 0.10984095931053162\n",
            "Epochs: 98, batch: 241 loss: 0.18325859308242798\n",
            "Epochs: 98, batch: 242 loss: 0.04988079145550728\n",
            "Epochs: 98, batch: 243 loss: 0.1750200241804123\n",
            "Epochs: 98, batch: 244 loss: 0.051604609936475754\n",
            "Epochs: 98, batch: 245 loss: 0.12385871261358261\n",
            "Epochs: 98, batch: 246 loss: 0.14676348865032196\n",
            "Epochs: 98, batch: 247 loss: 0.08737791329622269\n",
            "Epochs: 98, batch: 248 loss: 0.13719037175178528\n",
            "Epochs: 98, batch: 249 loss: 0.15117910504341125\n",
            "Epochs: 98, batch: 250 loss: 0.07437658309936523\n",
            "Epochs: 98, batch: 251 loss: 0.165505051612854\n",
            "Epochs: 98, batch: 252 loss: 0.09208191931247711\n",
            "Epochs: 98, batch: 253 loss: 0.18602535128593445\n",
            "Epochs: 98, batch: 254 loss: 0.2053505778312683\n",
            "Epochs: 98, batch: 255 loss: 0.0951061099767685\n",
            "Epochs: 98, batch: 256 loss: 0.14175920188426971\n",
            "Epochs: 98, batch: 257 loss: 0.09457189589738846\n",
            "Epochs: 98, batch: 258 loss: 0.17921914160251617\n",
            "Epochs: 98, batch: 259 loss: 0.2546807825565338\n",
            "Epochs: 98, batch: 260 loss: 0.12688913941383362\n",
            "Epochs: 98, batch: 261 loss: 0.23676130175590515\n",
            "Epochs: 98, batch: 262 loss: 0.046692438423633575\n",
            "Epochs: 98, batch: 263 loss: 0.0961705893278122\n",
            "Epochs: 98, batch: 264 loss: 0.17023761570453644\n",
            "Epochs: 98, batch: 265 loss: 0.14255757629871368\n",
            "Epochs: 98, batch: 266 loss: 0.14282676577568054\n",
            "Epochs: 98, batch: 267 loss: 0.09344181418418884\n",
            "Epochs: 98, batch: 268 loss: 0.04540206491947174\n",
            "Epochs: 98, batch: 269 loss: 0.0895838737487793\n",
            "Epochs: 98, batch: 270 loss: 0.04202939197421074\n",
            "Epochs: 98, batch: 271 loss: 0.07756374031305313\n",
            "Epochs: 98, batch: 272 loss: 0.1332913339138031\n",
            "Epochs: 98, batch: 273 loss: 0.10347993671894073\n",
            "Epochs: 98, batch: 274 loss: 0.08147405833005905\n",
            "Epochs: 98, batch: 275 loss: 0.03760397061705589\n",
            "Epochs: 98, batch: 276 loss: 0.09205500781536102\n",
            "Epochs: 98, batch: 277 loss: 0.12774881720542908\n",
            "Epochs: 98, batch: 278 loss: 0.16662335395812988\n",
            "Epochs: 98, batch: 279 loss: 0.08902084827423096\n",
            "Epochs: 98, batch: 280 loss: 0.16669484972953796\n",
            "Epochs: 98, batch: 281 loss: 0.09813301265239716\n",
            "Epochs: 98, batch: 282 loss: 0.12073326110839844\n",
            "Epochs: 98, batch: 283 loss: 0.26676514744758606\n",
            "Epochs: 98, batch: 284 loss: 0.18762840330600739\n",
            "Epochs: 98, batch: 285 loss: 0.2405722290277481\n",
            "Epochs: 98, batch: 286 loss: 0.22595460712909698\n",
            "Epochs: 98, batch: 287 loss: 0.218928724527359\n",
            "Epochs: 98, batch: 288 loss: 0.24984925985336304\n",
            "Epochs: 98, batch: 289 loss: 0.22301797568798065\n",
            "Epochs: 98, batch: 290 loss: 0.0911034494638443\n",
            "Epochs: 98, batch: 291 loss: 0.0660531297326088\n",
            "Epochs: 98, batch: 292 loss: 0.21230757236480713\n",
            "Epochs: 98, batch: 293 loss: 0.12283626943826675\n",
            "Epochs: 98, batch: 294 loss: 0.27591511607170105\n",
            "Epochs: 98, batch: 295 loss: 0.0708635076880455\n",
            "Epochs: 98, batch: 296 loss: 0.089107945561409\n",
            "Epochs: 98, batch: 297 loss: 0.14019495248794556\n",
            "Epochs: 98, batch: 298 loss: 0.1600361168384552\n",
            "Epochs: 98, batch: 299 loss: 0.05646241083741188\n",
            "Epochs: 98, batch: 301 loss: 0.07966335862874985\n",
            "Epochs: 98, batch: 302 loss: 0.14400723576545715\n",
            "Epochs: 98, batch: 303 loss: 0.09027398377656937\n",
            "Epochs: 98, batch: 304 loss: 0.06185102090239525\n",
            "Epochs: 98, batch: 305 loss: 0.09075945615768433\n",
            "Epochs: 98, batch: 306 loss: 0.06426674872636795\n",
            "Epochs: 98, batch: 307 loss: 0.1809164583683014\n",
            "Epochs: 98, batch: 308 loss: 0.21864695847034454\n",
            "Epochs: 98, batch: 309 loss: 0.08291245996952057\n",
            "Epochs: 98, batch: 310 loss: 0.25289371609687805\n",
            "Epochs: 98, batch: 311 loss: 0.14412391185760498\n",
            "Epochs: 98, batch: 312 loss: 0.06258971244096756\n",
            "Epochs: 98, batch: 313 loss: 0.05119619518518448\n",
            "Epochs: 98, batch: 314 loss: 0.21966034173965454\n",
            "Epochs: 98, batch: 315 loss: 0.18627554178237915\n",
            "Epochs: 98, batch: 316 loss: 0.09790468215942383\n",
            "Epochs: 98, batch: 317 loss: 0.07327134907245636\n",
            "Epochs: 98, batch: 318 loss: 0.034381549805402756\n",
            "Epochs: 98, batch: 319 loss: 0.0733250230550766\n",
            "Epochs: 98, batch: 320 loss: 0.05328570678830147\n",
            "Epochs: 98, batch: 321 loss: 0.16092276573181152\n",
            "Epochs: 98, batch: 322 loss: 0.059959083795547485\n",
            "Epochs: 98, batch: 323 loss: 0.3831930160522461\n",
            "Epochs: 98, batch: 324 loss: 0.06260164082050323\n",
            "Epochs: 98, batch: 325 loss: 0.1293492317199707\n",
            "Epochs: 98, batch: 326 loss: 0.10514581203460693\n",
            "Epochs: 98, batch: 327 loss: 0.13517487049102783\n",
            "Epochs: 98, batch: 328 loss: 0.03164344280958176\n",
            "Epochs: 98, batch: 329 loss: 0.122548907995224\n",
            "Epochs: 98, batch: 330 loss: 0.13035163283348083\n",
            "Epochs: 98, batch: 331 loss: 0.12172166258096695\n",
            "Epochs: 98, batch: 332 loss: 0.22090265154838562\n",
            "Epochs: 98, batch: 333 loss: 0.11893096566200256\n",
            "Epochs: 98, batch: 334 loss: 0.07954677939414978\n",
            "Epochs: 98, batch: 335 loss: 0.04277414083480835\n",
            "Epochs: 98, batch: 336 loss: 0.14383208751678467\n",
            "Epochs: 98, batch: 337 loss: 0.12785804271697998\n",
            "Epochs: 98, batch: 338 loss: 0.14133870601654053\n",
            "Epochs: 98, batch: 339 loss: 0.14767244458198547\n",
            "Epochs: 98, batch: 340 loss: 0.05518024042248726\n",
            "Epochs: 98, batch: 341 loss: 0.1941242814064026\n",
            "Epochs: 98, batch: 342 loss: 0.16985143721103668\n",
            "Epochs: 98, batch: 343 loss: 0.1362735480070114\n",
            "Epochs: 98, batch: 344 loss: 0.11724403500556946\n",
            "Epochs: 98, batch: 345 loss: 0.08266185224056244\n",
            "Epochs: 98, batch: 346 loss: 0.10306413471698761\n",
            "Epochs: 98, batch: 347 loss: 0.14016565680503845\n",
            "Epochs: 98, batch: 348 loss: 0.060512468218803406\n",
            "Epochs: 98, batch: 349 loss: 0.1731671690940857\n",
            "Epochs: 98, batch: 350 loss: 0.18059542775154114\n",
            "Epochs: 98, batch: 351 loss: 0.16134202480316162\n",
            "Epochs: 98, batch: 352 loss: 0.02179659716784954\n",
            "Epochs: 98, batch: 353 loss: 0.1103934794664383\n",
            "Epochs: 98, batch: 354 loss: 0.09318684786558151\n",
            "Epochs: 98, batch: 355 loss: 0.25492215156555176\n",
            "Epochs: 98, batch: 356 loss: 0.13772794604301453\n",
            "Epochs: 98, batch: 357 loss: 0.22191360592842102\n",
            "Epochs: 98, batch: 358 loss: 0.5239174365997314\n",
            "Epochs: 98, batch: 1 loss: 0.22512224316596985\n",
            "Epochs: 98, batch: 2 loss: 0.09534960985183716\n",
            "Epochs: 98, batch: 3 loss: 0.0704440176486969\n",
            "Epochs: 98, batch: 4 loss: 0.18898342549800873\n",
            "Epochs: 98, batch: 5 loss: 0.26214516162872314\n",
            "Epochs: 98, batch: 6 loss: 0.2482376992702484\n",
            "Epochs: 98, batch: 7 loss: 0.041329383850097656\n",
            "Epochs: 98, batch: 8 loss: 0.20118941366672516\n",
            "Epochs: 98, batch: 9 loss: 0.21167080104351044\n",
            "Epochs: 98, batch: 10 loss: 0.1363980919122696\n",
            "Epochs: 98, batch: 11 loss: 0.12917058169841766\n",
            "Epochs: 98, batch: 12 loss: 0.1524590700864792\n",
            "Epochs: 98, batch: 13 loss: 0.0870317742228508\n",
            "Epochs: 98, batch: 14 loss: 0.15142619609832764\n",
            "Epochs: 98, batch: 15 loss: 0.2674173414707184\n",
            "Epochs: 98, batch: 16 loss: 0.10492929816246033\n",
            "Epochs: 98, batch: 17 loss: 0.16293936967849731\n",
            "Epochs: 98, batch: 18 loss: 0.11924650520086288\n",
            "Epochs: 98, batch: 19 loss: 0.12582968175411224\n",
            "Epochs: 98, batch: 20 loss: 0.09018496423959732\n",
            "Epochs: 98, batch: 21 loss: 0.16438980400562286\n",
            "Epochs: 98, batch: 22 loss: 0.12483350932598114\n",
            "Epochs: 98, batch: 23 loss: 0.14698295295238495\n",
            "Epochs: 98, batch: 24 loss: 0.05285891145467758\n",
            "Epochs: 98, batch: 25 loss: 0.1212535873055458\n",
            "Epochs: 98, batch: 26 loss: 0.16790851950645447\n",
            "Epochs: 98, batch: 27 loss: 0.06879054009914398\n",
            "Epochs: 98, batch: 28 loss: 0.050903044641017914\n",
            "Epochs: 98, batch: 29 loss: 0.047422077506780624\n",
            "Epochs: 98, batch: 30 loss: 0.09849793463945389\n",
            "Epochs: 98, batch: 31 loss: 0.10118704289197922\n",
            "Epochs: 98, batch: 32 loss: 0.06769682466983795\n",
            "Epochs: 98, batch: 33 loss: 0.13406342267990112\n",
            "Epochs: 98, batch: 34 loss: 0.07538303732872009\n",
            "Epochs: 98, batch: 35 loss: 0.11928346753120422\n",
            "Epochs: 98, batch: 36 loss: 0.11153742671012878\n",
            "Epochs: 98, batch: 37 loss: 0.12992048263549805\n",
            "Epochs: 98, batch: 38 loss: 0.05453455448150635\n",
            "Epochs: 98, batch: 39 loss: 0.28359466791152954\n",
            "Epochs: 98, batch: 40 loss: 0.152102530002594\n",
            "Epochs: 98, batch: 41 loss: 0.21378028392791748\n",
            "Epochs: 98, batch: 42 loss: 0.16170784831047058\n",
            "Epochs: 98, batch: 43 loss: 0.14410465955734253\n",
            "Epochs: 98, batch: 44 loss: 0.17867104709148407\n",
            "Epochs: 98, batch: 45 loss: 0.24351346492767334\n",
            "Epochs: 98, batch: 46 loss: 0.26748019456863403\n",
            "Epochs: 98, batch: 47 loss: 0.08116239309310913\n",
            "Epochs: 98, batch: 48 loss: 0.0970817357301712\n",
            "Epochs: 98, batch: 49 loss: 0.09705907106399536\n",
            "Epochs: 98, batch: 50 loss: 0.05140462517738342\n",
            "Epochs: 98, batch: 51 loss: 0.1647084802389145\n",
            "Epochs: 98, batch: 52 loss: 0.1742796003818512\n",
            "Epochs: 98, batch: 53 loss: 0.12026222050189972\n",
            "Epochs: 98, batch: 54 loss: 0.19406117498874664\n",
            "Epochs: 98, batch: 55 loss: 0.2513502240180969\n",
            "Epochs: 98, batch: 56 loss: 0.17599666118621826\n",
            "Epochs: 98, batch: 57 loss: 0.17742760479450226\n",
            "Epochs: 98, batch: 58 loss: 0.13141173124313354\n",
            "Epochs: 98, batch: 59 loss: 0.10375085473060608\n",
            "Epochs: 98, batch: 60 loss: 0.1184651181101799\n",
            "Epochs: 98, batch: 61 loss: 0.07829073071479797\n",
            "Epochs: 98, batch: 62 loss: 0.10277295112609863\n",
            "Epochs: 98, batch: 63 loss: 0.15152490139007568\n",
            "Epochs: 98, batch: 64 loss: 0.1454249620437622\n",
            "Epochs: 98, batch: 65 loss: 0.1648774892091751\n",
            "Epochs: 98, batch: 66 loss: 0.1716916859149933\n",
            "Epochs: 98, batch: 67 loss: 0.0944962128996849\n",
            "Epochs: 98, batch: 68 loss: 0.10453734546899796\n",
            "Epochs: 98, batch: 69 loss: 0.25434935092926025\n",
            "Epochs: 98, batch: 70 loss: 0.05402760952711105\n",
            "Epochs: 98, batch: 71 loss: 0.19362875819206238\n",
            "Epochs: 98, batch: 72 loss: 0.19629335403442383\n",
            "Epochs: 98, batch: 73 loss: 0.3025681674480438\n",
            "Epochs: 98, batch: 74 loss: 0.21845895051956177\n",
            "Epochs: 98, batch: 75 loss: 0.2968863844871521\n",
            "Epochs: 98, batch: 76 loss: 0.1287032663822174\n",
            "Epochs: 98, batch: 77 loss: 0.04664758965373039\n",
            "Epochs: 98, batch: 78 loss: 0.20172341167926788\n",
            "Epochs: 98, batch: 79 loss: 0.19823376834392548\n",
            "Epochs: 98, batch: 80 loss: 0.15104685723781586\n",
            "Epochs: 98, batch: 81 loss: 0.12041071057319641\n",
            "Epochs: 98, batch: 82 loss: 0.14859899878501892\n",
            "Epochs: 98, batch: 83 loss: 0.14123181998729706\n",
            "Epochs: 98, batch: 84 loss: 0.07857050746679306\n",
            "Epochs: 98, batch: 85 loss: 0.06023364141583443\n",
            "Epochs: 98, batch: 86 loss: 0.1677708923816681\n",
            "Epochs: 98, batch: 87 loss: 0.09274499863386154\n",
            "Epochs: 98, batch: 88 loss: 0.09007928520441055\n",
            "Epochs: 98, batch: 89 loss: 0.11009478569030762\n",
            "Epochs: 98, batch: 90 loss: 0.11658421158790588\n",
            "Epochs: 98, batch: 91 loss: 0.1614581197500229\n",
            "Epochs: 98, batch: 92 loss: 0.08387617766857147\n",
            "Epochs: 98, batch: 93 loss: 0.06869588047266006\n",
            "Epochs: 98, batch: 94 loss: 0.11995898187160492\n",
            "Epochs: 98, batch: 95 loss: 0.11415351927280426\n",
            "Epochs: 98, batch: 96 loss: 0.08456882834434509\n",
            "Epochs: 98, batch: 97 loss: 0.12221795320510864\n",
            "Epochs: 98, batch: 98 loss: 0.14492154121398926\n",
            "Epochs: 98, batch: 99 loss: 0.12991809844970703\n",
            "Epochs: 98, batch: 101 loss: 0.1146969422698021\n",
            "Epochs: 98, batch: 102 loss: 0.2617540955543518\n",
            "Epochs: 98, batch: 103 loss: 0.1460793912410736\n",
            "Epochs: 98, batch: 104 loss: 0.18028752505779266\n",
            "Epochs: 98, batch: 105 loss: 0.1917404681444168\n",
            "Epochs: 98, batch: 106 loss: 0.10445844382047653\n",
            "Epochs: 98, batch: 107 loss: 0.11933216452598572\n",
            "Epochs: 98, batch: 108 loss: 0.23494896292686462\n",
            "Epochs: 98, batch: 109 loss: 0.04217049479484558\n",
            "Epochs: 98, batch: 110 loss: 0.1326398104429245\n",
            "Epochs: 98, batch: 111 loss: 0.07055418193340302\n",
            "Epochs: 98, batch: 112 loss: 0.1827619969844818\n",
            "Epochs: 98, batch: 113 loss: 0.0642506331205368\n",
            "Epochs: 98, batch: 114 loss: 0.10927408933639526\n",
            "Epochs: 98, batch: 115 loss: 0.1868508756160736\n",
            "Epochs: 98, batch: 116 loss: 0.13817542791366577\n",
            "Epochs: 98, batch: 117 loss: 0.2786519527435303\n",
            "Epochs: 98, batch: 118 loss: 0.1653372049331665\n",
            "Epochs: 98, batch: 119 loss: 0.1073208823800087\n",
            "Epochs: 98, batch: 120 loss: 0.15565015375614166\n",
            "Epochs: 98, batch: 121 loss: 0.11695167422294617\n",
            "Epochs: 98, batch: 122 loss: 0.08604616671800613\n",
            "Epochs: 98, batch: 123 loss: 0.11918015033006668\n",
            "Epochs: 98, batch: 124 loss: 0.12790854275226593\n",
            "Epochs: 98, batch: 125 loss: 0.07959933578968048\n",
            "Epochs: 98, batch: 126 loss: 0.07118774950504303\n",
            "Epochs: 98, batch: 127 loss: 0.14360934495925903\n",
            "Epochs: 98, batch: 128 loss: 0.14363020658493042\n",
            "Epochs: 98, batch: 129 loss: 0.10124419629573822\n",
            "Epochs: 98, batch: 130 loss: 0.19624561071395874\n",
            "Epochs: 98, batch: 131 loss: 0.08046119660139084\n",
            "Epochs: 98, batch: 132 loss: 0.14831089973449707\n",
            "Epochs: 98, batch: 133 loss: 0.14087119698524475\n",
            "Epochs: 98, batch: 134 loss: 0.09587780386209488\n",
            "Epochs: 98, batch: 135 loss: 0.16686376929283142\n",
            "Epochs: 98, batch: 136 loss: 0.11505268514156342\n",
            "Epochs: 98, batch: 137 loss: 0.2014361172914505\n",
            "Epochs: 98, batch: 138 loss: 0.10522693395614624\n",
            "Epochs: 98, batch: 139 loss: 0.03759855777025223\n",
            "Epochs: 98, batch: 140 loss: 0.0840568095445633\n",
            "Epochs: 98, batch: 141 loss: 0.11589724570512772\n",
            "Epochs: 98, batch: 142 loss: 0.09982873499393463\n",
            "Epochs: 98, batch: 143 loss: 0.11167417466640472\n",
            "Epochs: 98, batch: 144 loss: 0.04992200434207916\n",
            "Epochs: 98, batch: 145 loss: 0.12123630195856094\n",
            "Epochs: 98, batch: 146 loss: 0.17483527958393097\n",
            "Epochs: 98, batch: 147 loss: 0.07912489771842957\n",
            "Epochs: 98, batch: 148 loss: 0.10175210237503052\n",
            "Epochs: 98, batch: 149 loss: 0.2187812328338623\n",
            "Epochs: 98, batch: 150 loss: 0.0945238396525383\n",
            "Epochs: 98, batch: 151 loss: 0.10243474692106247\n",
            "Epochs: 98, batch: 152 loss: 0.09276041388511658\n",
            "Epochs: 98, batch: 153 loss: 0.09985293447971344\n",
            "Epochs: 98, batch: 154 loss: 0.39606377482414246\n",
            "Epochs: 98, batch: 155 loss: 0.13695409893989563\n",
            "Epochs: 98, batch: 156 loss: 0.07703118026256561\n",
            "Epochs: 98, batch: 157 loss: 0.19093690812587738\n",
            "Epochs: 98, batch: 158 loss: 0.024680357426404953\n",
            "Epochs: 98, batch: 159 loss: 0.18167449533939362\n",
            "Epochs: 98, batch: 160 loss: 0.05663084238767624\n",
            "Epochs: 98, batch: 161 loss: 0.09214730560779572\n",
            "Epochs: 98, batch: 162 loss: 0.1622714400291443\n",
            "Epochs: 98, batch: 163 loss: 0.22783443331718445\n",
            "Epochs: 98, batch: 164 loss: 0.27103424072265625\n",
            "Epochs: 98, batch: 165 loss: 0.09986168146133423\n",
            "Epochs: 98, batch: 166 loss: 0.07429791241884232\n",
            "Epochs: 98, batch: 167 loss: 0.11570820212364197\n",
            "Epochs: 98, batch: 168 loss: 0.08301769942045212\n",
            "Epochs: 98, batch: 169 loss: 0.07451346516609192\n",
            "Epochs: 98, batch: 170 loss: 0.0820704847574234\n",
            "Epochs: 98, batch: 171 loss: 0.045942340046167374\n",
            "Epochs: 98, batch: 172 loss: 0.09741657227277756\n",
            "Epochs: 98, batch: 173 loss: 0.11995957791805267\n",
            "Epochs: 98, batch: 174 loss: 0.09873954951763153\n",
            "Epochs: 98, batch: 175 loss: 0.07115566730499268\n",
            "Epochs: 98, batch: 176 loss: 0.15259359776973724\n",
            "Epochs: 98, batch: 177 loss: 0.19520093500614166\n",
            "Epochs: 98, batch: 178 loss: 0.11489050090312958\n",
            "Epochs: 98, batch: 179 loss: 0.0881495326757431\n",
            "Epochs: 98, batch: 180 loss: 0.13308386504650116\n",
            "Epochs: 98, batch: 181 loss: 0.09738565981388092\n",
            "Epochs: 98, batch: 182 loss: 0.09569211304187775\n",
            "Epochs: 98, batch: 183 loss: 0.060743894428014755\n",
            "Epochs: 98, batch: 184 loss: 0.12020266056060791\n",
            "Epochs: 98, batch: 185 loss: 0.11774329096078873\n",
            "Epochs: 98, batch: 186 loss: 0.27780792117118835\n",
            "Epochs: 98, batch: 187 loss: 0.09234770387411118\n",
            "Epochs: 98, batch: 188 loss: 0.1500803530216217\n",
            "Epochs: 98, batch: 189 loss: 0.2137903869152069\n",
            "Epochs: 98, batch: 190 loss: 0.07340478152036667\n",
            "Epochs: 98, batch: 191 loss: 0.18784552812576294\n",
            "Epochs: 98, batch: 192 loss: 0.20110246539115906\n",
            "Epochs: 98, batch: 193 loss: 0.17045699059963226\n",
            "Epochs: 98, batch: 194 loss: 0.12810692191123962\n",
            "Epochs: 98, batch: 195 loss: 0.10988333821296692\n",
            "Epochs: 98, batch: 196 loss: 0.049330443143844604\n",
            "Epochs: 98, batch: 197 loss: 0.10773134976625443\n",
            "Epochs: 98, batch: 198 loss: 0.06724172830581665\n",
            "Epochs: 98, batch: 199 loss: 0.1744568794965744\n",
            "Epochs: 98, batch: 201 loss: 0.06396780163049698\n",
            "Epochs: 98, batch: 202 loss: 0.2903329133987427\n",
            "Epochs: 98, batch: 203 loss: 0.21071657538414001\n",
            "Epochs: 98, batch: 204 loss: 0.1517009735107422\n",
            "Epochs: 98, batch: 205 loss: 0.23471331596374512\n",
            "Epochs: 98, batch: 206 loss: 0.12181193381547928\n",
            "Epochs: 98, batch: 207 loss: 0.051824070513248444\n",
            "Epochs: 98, batch: 208 loss: 0.06994032859802246\n",
            "Epochs: 98, batch: 209 loss: 0.17257381975650787\n",
            "Epochs: 98, batch: 210 loss: 0.056084223091602325\n",
            "Epochs: 98, batch: 211 loss: 0.1360880732536316\n",
            "Epochs: 98, batch: 212 loss: 0.0751466155052185\n",
            "Epochs: 98, batch: 213 loss: 0.16658808290958405\n",
            "Epochs: 98, batch: 214 loss: 0.0836217924952507\n",
            "Epochs: 98, batch: 215 loss: 0.1604205071926117\n",
            "Epochs: 98, batch: 216 loss: 0.1662319302558899\n",
            "Epochs: 98, batch: 217 loss: 0.2031458467245102\n",
            "Epochs: 98, batch: 218 loss: 0.05764058232307434\n",
            "Epochs: 98, batch: 219 loss: 0.14662861824035645\n",
            "Epochs: 98, batch: 220 loss: 0.14250215888023376\n",
            "Epochs: 98, batch: 221 loss: 0.14210759103298187\n",
            "Epochs: 98, batch: 222 loss: 0.1466015726327896\n",
            "Epochs: 98, batch: 223 loss: 0.1089937835931778\n",
            "Epochs: 98, batch: 224 loss: 0.04334629327058792\n",
            "Epochs: 98, batch: 225 loss: 0.21081914007663727\n",
            "Epochs: 98, batch: 226 loss: 0.19714292883872986\n",
            "Epochs: 98, batch: 227 loss: 0.0758882462978363\n",
            "Epochs: 98, batch: 228 loss: 0.06890846788883209\n",
            "Epochs: 98, batch: 229 loss: 0.03337983787059784\n",
            "Epochs: 98, batch: 230 loss: 0.054807256907224655\n",
            "Epochs: 98, batch: 231 loss: 0.26541823148727417\n",
            "Epochs: 98, batch: 232 loss: 0.14762406051158905\n",
            "Epochs: 98, batch: 233 loss: 0.07000725716352463\n",
            "Epochs: 98, batch: 234 loss: 0.08623401820659637\n",
            "Epochs: 98, batch: 235 loss: 0.1834896206855774\n",
            "Epochs: 98, batch: 236 loss: 0.10148147493600845\n",
            "Epochs: 98, batch: 237 loss: 0.18124109506607056\n",
            "Epochs: 98, batch: 238 loss: 0.060760173946619034\n",
            "Epochs: 98, batch: 239 loss: 0.21876762807369232\n",
            "Epochs: 98, batch: 240 loss: 0.10374989360570908\n",
            "Epochs: 98, batch: 241 loss: 0.10122446715831757\n",
            "Epochs: 98, batch: 242 loss: 0.02810574509203434\n",
            "Epochs: 98, batch: 243 loss: 0.07747103273868561\n",
            "Epochs: 98, batch: 244 loss: 0.09009716659784317\n",
            "Epochs: 98, batch: 245 loss: 0.061401210725307465\n",
            "Epochs: 98, batch: 246 loss: 0.11526800692081451\n",
            "Epochs: 98, batch: 247 loss: 0.14327527582645416\n",
            "Epochs: 98, batch: 248 loss: 0.14948439598083496\n",
            "Epochs: 98, batch: 249 loss: 0.06709585338830948\n",
            "Epochs: 98, batch: 250 loss: 0.20872420072555542\n",
            "Epochs: 98, batch: 251 loss: 0.12314903736114502\n",
            "Epochs: 98, batch: 252 loss: 0.21909144520759583\n",
            "Epochs: 98, batch: 253 loss: 0.13078460097312927\n",
            "Epochs: 98, batch: 254 loss: 0.09788806736469269\n",
            "Epochs: 98, batch: 255 loss: 0.18934659659862518\n",
            "Epochs: 98, batch: 256 loss: 0.054152850061655045\n",
            "Epochs: 98, batch: 257 loss: 0.0981990247964859\n",
            "Epochs: 98, batch: 258 loss: 0.09727537631988525\n",
            "Epochs: 98, batch: 259 loss: 0.047101154923439026\n",
            "Epochs: 98, batch: 260 loss: 0.10042283684015274\n",
            "Epochs: 98, batch: 261 loss: 0.11240354180335999\n",
            "Epochs: 98, batch: 262 loss: 0.11458507180213928\n",
            "Epochs: 98, batch: 263 loss: 0.38775378465652466\n",
            "Epochs: 98, batch: 264 loss: 0.2211279571056366\n",
            "Epochs: 98, batch: 265 loss: 0.09400123357772827\n",
            "Epochs: 98, batch: 266 loss: 0.04381773620843887\n",
            "Epochs: 98, batch: 267 loss: 0.09890888631343842\n",
            "Epochs: 98, batch: 268 loss: 0.14225855469703674\n",
            "Epochs: 98, batch: 269 loss: 0.1126413345336914\n",
            "Epochs: 98, batch: 270 loss: 0.14939267933368683\n",
            "Epochs: 98, batch: 271 loss: 0.09932877123355865\n",
            "Epochs: 98, batch: 272 loss: 0.1727454960346222\n",
            "Epochs: 98, batch: 273 loss: 0.033116862177848816\n",
            "Epochs: 98, batch: 274 loss: 0.23923233151435852\n",
            "Epochs: 98, batch: 275 loss: 0.2781684994697571\n",
            "Epochs: 98, batch: 276 loss: 0.06338793784379959\n",
            "Epochs: 98, batch: 277 loss: 0.09103402495384216\n",
            "Epochs: 98, batch: 278 loss: 0.2260122448205948\n",
            "Epochs: 98, batch: 279 loss: 0.08715115487575531\n",
            "Epochs: 98, batch: 280 loss: 0.14685122668743134\n",
            "Epochs: 98, batch: 281 loss: 0.24488770961761475\n",
            "Epochs: 98, batch: 282 loss: 0.08009995520114899\n",
            "Epochs: 98, batch: 283 loss: 0.09539347887039185\n",
            "Epochs: 98, batch: 284 loss: 0.10912366211414337\n",
            "Epochs: 98, batch: 285 loss: 0.12322969734668732\n",
            "Epochs: 98, batch: 286 loss: 0.24269425868988037\n",
            "Epochs: 98, batch: 287 loss: 0.10892491787672043\n",
            "Epochs: 98, batch: 288 loss: 0.08545240014791489\n",
            "Epochs: 98, batch: 289 loss: 0.051961254328489304\n",
            "Epochs: 98, batch: 290 loss: 0.11466319859027863\n",
            "Epochs: 98, batch: 291 loss: 0.17219772934913635\n",
            "Epochs: 98, batch: 292 loss: 0.15200448036193848\n",
            "Epochs: 98, batch: 293 loss: 0.1715710461139679\n",
            "Epochs: 98, batch: 294 loss: 0.15106430649757385\n",
            "Epochs: 98, batch: 295 loss: 0.049412406980991364\n",
            "Epochs: 98, batch: 296 loss: 0.09859083592891693\n",
            "Epochs: 98, batch: 297 loss: 0.15623418986797333\n",
            "Epochs: 98, batch: 298 loss: 0.0383831150829792\n",
            "Epochs: 98, batch: 299 loss: 0.08712343871593475\n",
            "Epochs: 98, batch: 301 loss: 0.16469871997833252\n",
            "Epochs: 98, batch: 302 loss: 0.12497704476118088\n",
            "Epochs: 98, batch: 303 loss: 0.18331880867481232\n",
            "Epochs: 98, batch: 304 loss: 0.0882960855960846\n",
            "Epochs: 98, batch: 305 loss: 0.11637695133686066\n",
            "Epochs: 98, batch: 306 loss: 0.09503255784511566\n",
            "Epochs: 98, batch: 307 loss: 0.1211254671216011\n",
            "Epochs: 98, batch: 308 loss: 0.14982905983924866\n",
            "Epochs: 98, batch: 309 loss: 0.18257799744606018\n",
            "Epochs: 98, batch: 310 loss: 0.1294531226158142\n",
            "Epochs: 98, batch: 311 loss: 0.09509986639022827\n",
            "Epochs: 98, batch: 312 loss: 0.10946555435657501\n",
            "Epochs: 98, batch: 313 loss: 0.11801283061504364\n",
            "Epochs: 98, batch: 314 loss: 0.17632773518562317\n",
            "Epochs: 98, batch: 315 loss: 0.11622641235589981\n",
            "Epochs: 98, batch: 316 loss: 0.2372468262910843\n",
            "Epochs: 98, batch: 317 loss: 0.046608444303274155\n",
            "Epochs: 98, batch: 318 loss: 0.06295272707939148\n",
            "Epochs: 98, batch: 319 loss: 0.23552706837654114\n",
            "Epochs: 98, batch: 320 loss: 0.10434211790561676\n",
            "Epochs: 98, batch: 321 loss: 0.12681907415390015\n",
            "Epochs: 98, batch: 322 loss: 0.1660420298576355\n",
            "Epochs: 98, batch: 323 loss: 0.13183236122131348\n",
            "Epochs: 98, batch: 324 loss: 0.18666280806064606\n",
            "Epochs: 98, batch: 325 loss: 0.16171644628047943\n",
            "Epochs: 98, batch: 326 loss: 0.15598686039447784\n",
            "Epochs: 98, batch: 327 loss: 0.14476224780082703\n",
            "Epochs: 98, batch: 328 loss: 0.1925145983695984\n",
            "Epochs: 98, batch: 329 loss: 0.11570364236831665\n",
            "Epochs: 98, batch: 330 loss: 0.1480635106563568\n",
            "Epochs: 98, batch: 331 loss: 0.10113345086574554\n",
            "Epochs: 98, batch: 332 loss: 0.07695868611335754\n",
            "Epochs: 98, batch: 333 loss: 0.1066012904047966\n",
            "Epochs: 98, batch: 334 loss: 0.16076987981796265\n",
            "Epochs: 98, batch: 335 loss: 0.16136404871940613\n",
            "Epochs: 98, batch: 336 loss: 0.1617719531059265\n",
            "Epochs: 98, batch: 337 loss: 0.13781163096427917\n",
            "Epochs: 98, batch: 338 loss: 0.06035727262496948\n",
            "Epochs: 98, batch: 339 loss: 0.1164773628115654\n",
            "Epochs: 98, batch: 340 loss: 0.08980929851531982\n",
            "Epochs: 98, batch: 341 loss: 0.23126943409442902\n",
            "Epochs: 98, batch: 342 loss: 0.13928651809692383\n",
            "Epochs: 98, batch: 343 loss: 0.07922300696372986\n",
            "Epochs: 98, batch: 344 loss: 0.07669243961572647\n",
            "Epochs: 98, batch: 345 loss: 0.23068073391914368\n",
            "Epochs: 98, batch: 346 loss: 0.0628013163805008\n",
            "Epochs: 98, batch: 347 loss: 0.14443868398666382\n",
            "Epochs: 98, batch: 348 loss: 0.0994669646024704\n",
            "Epochs: 98, batch: 349 loss: 0.08001118898391724\n",
            "Epochs: 98, batch: 350 loss: 0.05617155134677887\n",
            "Epochs: 98, batch: 351 loss: 0.1724679321050644\n",
            "Epochs: 98, batch: 352 loss: 0.09916345775127411\n",
            "Epochs: 98, batch: 353 loss: 0.20876386761665344\n",
            "Epochs: 98, batch: 354 loss: 0.08063152432441711\n",
            "Epochs: 98, batch: 355 loss: 0.0963125079870224\n",
            "Epochs: 98, batch: 356 loss: 0.11355680227279663\n",
            "Epochs: 98, batch: 357 loss: 0.13989600539207458\n",
            "Epochs: 98, batch: 358 loss: 0.17585782706737518\n",
            "Epochs: 99, batch: 1 loss: 0.09969215095043182\n",
            "Epochs: 99, batch: 2 loss: 0.08753463625907898\n",
            "Epochs: 99, batch: 3 loss: 0.2715444564819336\n",
            "Epochs: 99, batch: 4 loss: 0.05682368203997612\n",
            "Epochs: 99, batch: 5 loss: 0.20365282893180847\n",
            "Epochs: 99, batch: 6 loss: 0.16088518500328064\n",
            "Epochs: 99, batch: 7 loss: 0.07642965018749237\n",
            "Epochs: 99, batch: 8 loss: 0.251341313123703\n",
            "Epochs: 99, batch: 9 loss: 0.06753218173980713\n",
            "Epochs: 99, batch: 10 loss: 0.16193535923957825\n",
            "Epochs: 99, batch: 11 loss: 0.03735386207699776\n",
            "Epochs: 99, batch: 12 loss: 0.10523305833339691\n",
            "Epochs: 99, batch: 13 loss: 0.1916719526052475\n",
            "Epochs: 99, batch: 14 loss: 0.1444968283176422\n",
            "Epochs: 99, batch: 15 loss: 0.05874612182378769\n",
            "Epochs: 99, batch: 16 loss: 0.07491068542003632\n",
            "Epochs: 99, batch: 17 loss: 0.04640033096075058\n",
            "Epochs: 99, batch: 18 loss: 0.024470414966344833\n",
            "Epochs: 99, batch: 19 loss: 0.1508091688156128\n",
            "Epochs: 99, batch: 20 loss: 0.1099199503660202\n",
            "Epochs: 99, batch: 21 loss: 0.14721965789794922\n",
            "Epochs: 99, batch: 22 loss: 0.2413032352924347\n",
            "Epochs: 99, batch: 23 loss: 0.1401572972536087\n",
            "Epochs: 99, batch: 24 loss: 0.16675013303756714\n",
            "Epochs: 99, batch: 25 loss: 0.16701394319534302\n",
            "Epochs: 99, batch: 26 loss: 0.12458419799804688\n",
            "Epochs: 99, batch: 27 loss: 0.11276926845312119\n",
            "Epochs: 99, batch: 28 loss: 0.20130190253257751\n",
            "Epochs: 99, batch: 29 loss: 0.12798452377319336\n",
            "Epochs: 99, batch: 30 loss: 0.1092657744884491\n",
            "Epochs: 99, batch: 31 loss: 0.12806665897369385\n",
            "Epochs: 99, batch: 32 loss: 0.18022382259368896\n",
            "Epochs: 99, batch: 33 loss: 0.2241658866405487\n",
            "Epochs: 99, batch: 34 loss: 0.1775892674922943\n",
            "Epochs: 99, batch: 35 loss: 0.16940267384052277\n",
            "Epochs: 99, batch: 36 loss: 0.11403726041316986\n",
            "Epochs: 99, batch: 37 loss: 0.03965546935796738\n",
            "Epochs: 99, batch: 38 loss: 0.05433579534292221\n",
            "Epochs: 99, batch: 39 loss: 0.13285645842552185\n",
            "Epochs: 99, batch: 40 loss: 0.18605715036392212\n",
            "Epochs: 99, batch: 41 loss: 0.2392890453338623\n",
            "Epochs: 99, batch: 42 loss: 0.14923274517059326\n",
            "Epochs: 99, batch: 43 loss: 0.11021122336387634\n",
            "Epochs: 99, batch: 44 loss: 0.09531208872795105\n",
            "Epochs: 99, batch: 45 loss: 0.1792563498020172\n",
            "Epochs: 99, batch: 46 loss: 0.10016381740570068\n",
            "Epochs: 99, batch: 47 loss: 0.05862068384885788\n",
            "Epochs: 99, batch: 48 loss: 0.08838330209255219\n",
            "Epochs: 99, batch: 49 loss: 0.25699979066848755\n",
            "Epochs: 99, batch: 50 loss: 0.08723048120737076\n",
            "Epochs: 99, batch: 51 loss: 0.08810698240995407\n",
            "Epochs: 99, batch: 52 loss: 0.06272818148136139\n",
            "Epochs: 99, batch: 53 loss: 0.055816762149333954\n",
            "Epochs: 99, batch: 54 loss: 0.12025041878223419\n",
            "Epochs: 99, batch: 55 loss: 0.06162101775407791\n",
            "Epochs: 99, batch: 56 loss: 0.06309779733419418\n",
            "Epochs: 99, batch: 57 loss: 0.1106095239520073\n",
            "Epochs: 99, batch: 58 loss: 0.07946495711803436\n",
            "Epochs: 99, batch: 59 loss: 0.15975412726402283\n",
            "Epochs: 99, batch: 60 loss: 0.041393592953681946\n",
            "Epochs: 99, batch: 61 loss: 0.1784525215625763\n",
            "Epochs: 99, batch: 62 loss: 0.15330864489078522\n",
            "Epochs: 99, batch: 63 loss: 0.10481580346822739\n",
            "Epochs: 99, batch: 64 loss: 0.14264152944087982\n",
            "Epochs: 99, batch: 65 loss: 0.07011882960796356\n",
            "Epochs: 99, batch: 66 loss: 0.04670040309429169\n",
            "Epochs: 99, batch: 67 loss: 0.12135867774486542\n",
            "Epochs: 99, batch: 68 loss: 0.11561319231987\n",
            "Epochs: 99, batch: 69 loss: 0.04849638044834137\n",
            "Epochs: 99, batch: 70 loss: 0.23864737153053284\n",
            "Epochs: 99, batch: 71 loss: 0.14441674947738647\n",
            "Epochs: 99, batch: 72 loss: 0.15770122408866882\n",
            "Epochs: 99, batch: 73 loss: 0.20914936065673828\n",
            "Epochs: 99, batch: 74 loss: 0.07564224302768707\n",
            "Epochs: 99, batch: 75 loss: 0.11614752560853958\n",
            "Epochs: 99, batch: 76 loss: 0.16515234112739563\n",
            "Epochs: 99, batch: 77 loss: 0.022933196276426315\n",
            "Epochs: 99, batch: 78 loss: 0.05491238087415695\n",
            "Epochs: 99, batch: 79 loss: 0.0729902982711792\n",
            "Epochs: 99, batch: 80 loss: 0.07089273631572723\n",
            "Epochs: 99, batch: 81 loss: 0.17252784967422485\n",
            "Epochs: 99, batch: 82 loss: 0.061229102313518524\n",
            "Epochs: 99, batch: 83 loss: 0.17161303758621216\n",
            "Epochs: 99, batch: 84 loss: 0.1887822151184082\n",
            "Epochs: 99, batch: 85 loss: 0.40895211696624756\n",
            "Epochs: 99, batch: 86 loss: 0.04166684299707413\n",
            "Epochs: 99, batch: 87 loss: 0.12768778204917908\n",
            "Epochs: 99, batch: 88 loss: 0.2406410574913025\n",
            "Epochs: 99, batch: 89 loss: 0.11677315831184387\n",
            "Epochs: 99, batch: 90 loss: 0.09303810447454453\n",
            "Epochs: 99, batch: 91 loss: 0.14916542172431946\n",
            "Epochs: 99, batch: 92 loss: 0.05680859461426735\n",
            "Epochs: 99, batch: 93 loss: 0.08968830108642578\n",
            "Epochs: 99, batch: 94 loss: 0.043116018176078796\n",
            "Epochs: 99, batch: 95 loss: 0.0606282614171505\n",
            "Epochs: 99, batch: 96 loss: 0.07338837534189224\n",
            "Epochs: 99, batch: 97 loss: 0.11101514101028442\n",
            "Epochs: 99, batch: 98 loss: 0.12797151505947113\n",
            "Epochs: 99, batch: 99 loss: 0.043815977871418\n",
            "Epochs: 99, batch: 101 loss: 0.15926721692085266\n",
            "Epochs: 99, batch: 102 loss: 0.1533232033252716\n",
            "Epochs: 99, batch: 103 loss: 0.06563965231180191\n",
            "Epochs: 99, batch: 104 loss: 0.08809054642915726\n",
            "Epochs: 99, batch: 105 loss: 0.10966463387012482\n",
            "Epochs: 99, batch: 106 loss: 0.1921195238828659\n",
            "Epochs: 99, batch: 107 loss: 0.03697914630174637\n",
            "Epochs: 99, batch: 108 loss: 0.13312029838562012\n",
            "Epochs: 99, batch: 109 loss: 0.1049155741930008\n",
            "Epochs: 99, batch: 110 loss: 0.0886136069893837\n",
            "Epochs: 99, batch: 111 loss: 0.0857154130935669\n",
            "Epochs: 99, batch: 112 loss: 0.21767781674861908\n",
            "Epochs: 99, batch: 113 loss: 0.11612799763679504\n",
            "Epochs: 99, batch: 114 loss: 0.06896664202213287\n",
            "Epochs: 99, batch: 115 loss: 0.2617614269256592\n",
            "Epochs: 99, batch: 116 loss: 0.12500381469726562\n",
            "Epochs: 99, batch: 117 loss: 0.12803246080875397\n",
            "Epochs: 99, batch: 118 loss: 0.02845093607902527\n",
            "Epochs: 99, batch: 119 loss: 0.060906365513801575\n",
            "Epochs: 99, batch: 120 loss: 0.09600018709897995\n",
            "Epochs: 99, batch: 121 loss: 0.10426157712936401\n",
            "Epochs: 99, batch: 122 loss: 0.15131348371505737\n",
            "Epochs: 99, batch: 123 loss: 0.14385490119457245\n",
            "Epochs: 99, batch: 124 loss: 0.090645432472229\n",
            "Epochs: 99, batch: 125 loss: 0.09573787450790405\n",
            "Epochs: 99, batch: 126 loss: 0.08132817596197128\n",
            "Epochs: 99, batch: 127 loss: 0.08065956085920334\n",
            "Epochs: 99, batch: 128 loss: 0.22559773921966553\n",
            "Epochs: 99, batch: 129 loss: 0.2076306939125061\n",
            "Epochs: 99, batch: 130 loss: 0.0840245932340622\n",
            "Epochs: 99, batch: 131 loss: 0.11056138575077057\n",
            "Epochs: 99, batch: 132 loss: 0.08359705656766891\n",
            "Epochs: 99, batch: 133 loss: 0.09012462198734283\n",
            "Epochs: 99, batch: 134 loss: 0.12538081407546997\n",
            "Epochs: 99, batch: 135 loss: 0.1247076541185379\n",
            "Epochs: 99, batch: 136 loss: 0.07796141505241394\n",
            "Epochs: 99, batch: 137 loss: 0.06423307955265045\n",
            "Epochs: 99, batch: 138 loss: 0.13402192294597626\n",
            "Epochs: 99, batch: 139 loss: 0.15280677378177643\n",
            "Epochs: 99, batch: 140 loss: 0.152976393699646\n",
            "Epochs: 99, batch: 141 loss: 0.16983361542224884\n",
            "Epochs: 99, batch: 142 loss: 0.1329318732023239\n",
            "Epochs: 99, batch: 143 loss: 0.06607896834611893\n",
            "Epochs: 99, batch: 144 loss: 0.19854198396205902\n",
            "Epochs: 99, batch: 145 loss: 0.1289082020521164\n",
            "Epochs: 99, batch: 146 loss: 0.13607576489448547\n",
            "Epochs: 99, batch: 147 loss: 0.21493399143218994\n",
            "Epochs: 99, batch: 148 loss: 0.0629529058933258\n",
            "Epochs: 99, batch: 149 loss: 0.13731864094734192\n",
            "Epochs: 99, batch: 150 loss: 0.18388855457305908\n",
            "Epochs: 99, batch: 151 loss: 0.2514720559120178\n",
            "Epochs: 99, batch: 152 loss: 0.05825860798358917\n",
            "Epochs: 99, batch: 153 loss: 0.15305709838867188\n",
            "Epochs: 99, batch: 154 loss: 0.08932697772979736\n",
            "Epochs: 99, batch: 155 loss: 0.13866889476776123\n",
            "Epochs: 99, batch: 156 loss: 0.0918397530913353\n",
            "Epochs: 99, batch: 157 loss: 0.05264144018292427\n",
            "Epochs: 99, batch: 158 loss: 0.043486353009939194\n",
            "Epochs: 99, batch: 159 loss: 0.13589608669281006\n",
            "Epochs: 99, batch: 160 loss: 0.10774223506450653\n",
            "Epochs: 99, batch: 161 loss: 0.11193673312664032\n",
            "Epochs: 99, batch: 162 loss: 0.10270226001739502\n",
            "Epochs: 99, batch: 163 loss: 0.2484116554260254\n",
            "Epochs: 99, batch: 164 loss: 0.18451985716819763\n",
            "Epochs: 99, batch: 165 loss: 0.11393702775239944\n",
            "Epochs: 99, batch: 166 loss: 0.12784209847450256\n",
            "Epochs: 99, batch: 167 loss: 0.16494391858577728\n",
            "Epochs: 99, batch: 168 loss: 0.13923826813697815\n",
            "Epochs: 99, batch: 169 loss: 0.09623583406209946\n",
            "Epochs: 99, batch: 170 loss: 0.2015056610107422\n",
            "Epochs: 99, batch: 171 loss: 0.1410253643989563\n",
            "Epochs: 99, batch: 172 loss: 0.1627553105354309\n",
            "Epochs: 99, batch: 173 loss: 0.12753741443157196\n",
            "Epochs: 99, batch: 174 loss: 0.16558130085468292\n",
            "Epochs: 99, batch: 175 loss: 0.15579289197921753\n",
            "Epochs: 99, batch: 176 loss: 0.1936371624469757\n",
            "Epochs: 99, batch: 177 loss: 0.08722339570522308\n",
            "Epochs: 99, batch: 178 loss: 0.12758484482765198\n",
            "Epochs: 99, batch: 179 loss: 0.12308639287948608\n",
            "Epochs: 99, batch: 180 loss: 0.10649991780519485\n",
            "Epochs: 99, batch: 181 loss: 0.23539888858795166\n",
            "Epochs: 99, batch: 182 loss: 0.05669707804918289\n",
            "Epochs: 99, batch: 183 loss: 0.12302722036838531\n",
            "Epochs: 99, batch: 184 loss: 0.13957656919956207\n",
            "Epochs: 99, batch: 185 loss: 0.22789624333381653\n",
            "Epochs: 99, batch: 186 loss: 0.1780657321214676\n",
            "Epochs: 99, batch: 187 loss: 0.15207433700561523\n",
            "Epochs: 99, batch: 188 loss: 0.1812405288219452\n",
            "Epochs: 99, batch: 189 loss: 0.176179900765419\n",
            "Epochs: 99, batch: 190 loss: 0.08083999902009964\n",
            "Epochs: 99, batch: 191 loss: 0.08924949169158936\n",
            "Epochs: 99, batch: 192 loss: 0.06423284113407135\n",
            "Epochs: 99, batch: 193 loss: 0.1443023979663849\n",
            "Epochs: 99, batch: 194 loss: 0.1607934534549713\n",
            "Epochs: 99, batch: 195 loss: 0.025040987879037857\n",
            "Epochs: 99, batch: 196 loss: 0.19425055384635925\n",
            "Epochs: 99, batch: 197 loss: 0.14869730174541473\n",
            "Epochs: 99, batch: 198 loss: 0.1319354772567749\n",
            "Epochs: 99, batch: 199 loss: 0.09508011490106583\n",
            "Epochs: 99, batch: 201 loss: 0.0925561785697937\n",
            "Epochs: 99, batch: 202 loss: 0.10598723590373993\n",
            "Epochs: 99, batch: 203 loss: 0.15475857257843018\n",
            "Epochs: 99, batch: 204 loss: 0.2122185230255127\n",
            "Epochs: 99, batch: 205 loss: 0.09919744729995728\n",
            "Epochs: 99, batch: 206 loss: 0.10163209587335587\n",
            "Epochs: 99, batch: 207 loss: 0.10475042462348938\n",
            "Epochs: 99, batch: 208 loss: 0.17174312472343445\n",
            "Epochs: 99, batch: 209 loss: 0.15331387519836426\n",
            "Epochs: 99, batch: 210 loss: 0.03806190937757492\n",
            "Epochs: 99, batch: 211 loss: 0.06732171773910522\n",
            "Epochs: 99, batch: 212 loss: 0.25655895471572876\n",
            "Epochs: 99, batch: 213 loss: 0.14047043025493622\n",
            "Epochs: 99, batch: 214 loss: 0.09157176315784454\n",
            "Epochs: 99, batch: 215 loss: 0.23404866456985474\n",
            "Epochs: 99, batch: 216 loss: 0.14455419778823853\n",
            "Epochs: 99, batch: 217 loss: 0.15059790015220642\n",
            "Epochs: 99, batch: 218 loss: 0.16646459698677063\n",
            "Epochs: 99, batch: 219 loss: 0.07925943285226822\n",
            "Epochs: 99, batch: 220 loss: 0.15699496865272522\n",
            "Epochs: 99, batch: 221 loss: 0.14380744099617004\n",
            "Epochs: 99, batch: 222 loss: 0.13104207813739777\n",
            "Epochs: 99, batch: 223 loss: 0.0972452238202095\n",
            "Epochs: 99, batch: 224 loss: 0.1700884997844696\n",
            "Epochs: 99, batch: 225 loss: 0.07401730120182037\n",
            "Epochs: 99, batch: 226 loss: 0.15018610656261444\n",
            "Epochs: 99, batch: 227 loss: 0.06890195608139038\n",
            "Epochs: 99, batch: 228 loss: 0.16333279013633728\n",
            "Epochs: 99, batch: 229 loss: 0.08922090381383896\n",
            "Epochs: 99, batch: 230 loss: 0.17668601870536804\n",
            "Epochs: 99, batch: 231 loss: 0.12763512134552002\n",
            "Epochs: 99, batch: 232 loss: 0.057891737669706345\n",
            "Epochs: 99, batch: 233 loss: 0.039119403809309006\n",
            "Epochs: 99, batch: 234 loss: 0.11915925145149231\n",
            "Epochs: 99, batch: 235 loss: 0.1560281366109848\n",
            "Epochs: 99, batch: 236 loss: 0.1331178843975067\n",
            "Epochs: 99, batch: 237 loss: 0.1948452591896057\n",
            "Epochs: 99, batch: 238 loss: 0.11938787251710892\n",
            "Epochs: 99, batch: 239 loss: 0.06858955323696136\n",
            "Epochs: 99, batch: 240 loss: 0.10718881338834763\n",
            "Epochs: 99, batch: 241 loss: 0.06288871169090271\n",
            "Epochs: 99, batch: 242 loss: 0.08744142949581146\n",
            "Epochs: 99, batch: 243 loss: 0.11261492222547531\n",
            "Epochs: 99, batch: 244 loss: 0.0757482498884201\n",
            "Epochs: 99, batch: 245 loss: 0.11541200429201126\n",
            "Epochs: 99, batch: 246 loss: 0.08117888867855072\n",
            "Epochs: 99, batch: 247 loss: 0.15667463839054108\n",
            "Epochs: 99, batch: 248 loss: 0.18597638607025146\n",
            "Epochs: 99, batch: 249 loss: 0.06405475735664368\n",
            "Epochs: 99, batch: 250 loss: 0.07224486023187637\n",
            "Epochs: 99, batch: 251 loss: 0.21664267778396606\n",
            "Epochs: 99, batch: 252 loss: 0.10665076971054077\n",
            "Epochs: 99, batch: 253 loss: 0.14550253748893738\n",
            "Epochs: 99, batch: 254 loss: 0.2755758762359619\n",
            "Epochs: 99, batch: 255 loss: 0.02322784997522831\n",
            "Epochs: 99, batch: 256 loss: 0.11069869995117188\n",
            "Epochs: 99, batch: 257 loss: 0.14033429324626923\n",
            "Epochs: 99, batch: 258 loss: 0.2348058819770813\n",
            "Epochs: 99, batch: 259 loss: 0.10049170255661011\n",
            "Epochs: 99, batch: 260 loss: 0.048808753490448\n",
            "Epochs: 99, batch: 261 loss: 0.12545424699783325\n",
            "Epochs: 99, batch: 262 loss: 0.10138185322284698\n",
            "Epochs: 99, batch: 263 loss: 0.14040549099445343\n",
            "Epochs: 99, batch: 264 loss: 0.12931978702545166\n",
            "Epochs: 99, batch: 265 loss: 0.13037869334220886\n",
            "Epochs: 99, batch: 266 loss: 0.12930768728256226\n",
            "Epochs: 99, batch: 267 loss: 0.1663465052843094\n",
            "Epochs: 99, batch: 268 loss: 0.18902219831943512\n",
            "Epochs: 99, batch: 269 loss: 0.11699028313159943\n",
            "Epochs: 99, batch: 270 loss: 0.08828554302453995\n",
            "Epochs: 99, batch: 271 loss: 0.17093002796173096\n",
            "Epochs: 99, batch: 272 loss: 0.205825075507164\n",
            "Epochs: 99, batch: 273 loss: 0.08312886953353882\n",
            "Epochs: 99, batch: 274 loss: 0.10376280546188354\n",
            "Epochs: 99, batch: 275 loss: 0.11488847434520721\n",
            "Epochs: 99, batch: 276 loss: 0.21440070867538452\n",
            "Epochs: 99, batch: 277 loss: 0.1659955531358719\n",
            "Epochs: 99, batch: 278 loss: 0.11267058551311493\n",
            "Epochs: 99, batch: 279 loss: 0.09046521782875061\n",
            "Epochs: 99, batch: 280 loss: 0.05700752139091492\n",
            "Epochs: 99, batch: 281 loss: 0.06105746328830719\n",
            "Epochs: 99, batch: 282 loss: 0.060518067330121994\n",
            "Epochs: 99, batch: 283 loss: 0.15140622854232788\n",
            "Epochs: 99, batch: 284 loss: 0.08808466792106628\n",
            "Epochs: 99, batch: 285 loss: 0.16817724704742432\n",
            "Epochs: 99, batch: 286 loss: 0.10099035501480103\n",
            "Epochs: 99, batch: 287 loss: 0.07909591495990753\n",
            "Epochs: 99, batch: 288 loss: 0.06026418134570122\n",
            "Epochs: 99, batch: 289 loss: 0.2053069770336151\n",
            "Epochs: 99, batch: 290 loss: 0.17198988795280457\n",
            "Epochs: 99, batch: 291 loss: 0.1337035894393921\n",
            "Epochs: 99, batch: 292 loss: 0.10066878795623779\n",
            "Epochs: 99, batch: 293 loss: 0.18119627237319946\n",
            "Epochs: 99, batch: 294 loss: 0.22136443853378296\n",
            "Epochs: 99, batch: 295 loss: 0.18220356106758118\n",
            "Epochs: 99, batch: 296 loss: 0.17074257135391235\n",
            "Epochs: 99, batch: 297 loss: 0.10094964504241943\n",
            "Epochs: 99, batch: 298 loss: 0.1526009440422058\n",
            "Epochs: 99, batch: 299 loss: 0.14467620849609375\n",
            "Epochs: 99, batch: 301 loss: 0.12383757531642914\n",
            "Epochs: 99, batch: 302 loss: 0.198207288980484\n",
            "Epochs: 99, batch: 303 loss: 0.10309656709432602\n",
            "Epochs: 99, batch: 304 loss: 0.15815061330795288\n",
            "Epochs: 99, batch: 305 loss: 0.08531911671161652\n",
            "Epochs: 99, batch: 306 loss: 0.06290309131145477\n",
            "Epochs: 99, batch: 307 loss: 0.21626541018486023\n",
            "Epochs: 99, batch: 308 loss: 0.14574368298053741\n",
            "Epochs: 99, batch: 309 loss: 0.08876089751720428\n",
            "Epochs: 99, batch: 310 loss: 0.21728841960430145\n",
            "Epochs: 99, batch: 311 loss: 0.17821139097213745\n",
            "Epochs: 99, batch: 312 loss: 0.09828939288854599\n",
            "Epochs: 99, batch: 313 loss: 0.12444119155406952\n",
            "Epochs: 99, batch: 314 loss: 0.07442101836204529\n",
            "Epochs: 99, batch: 315 loss: 0.0596577413380146\n",
            "Epochs: 99, batch: 316 loss: 0.039517566561698914\n",
            "Epochs: 99, batch: 317 loss: 0.10028956830501556\n",
            "Epochs: 99, batch: 318 loss: 0.09450244903564453\n",
            "Epochs: 99, batch: 319 loss: 0.045647650957107544\n",
            "Epochs: 99, batch: 320 loss: 0.07687303423881531\n",
            "Epochs: 99, batch: 321 loss: 0.08075708895921707\n",
            "Epochs: 99, batch: 322 loss: 0.04419758915901184\n",
            "Epochs: 99, batch: 323 loss: 0.1622607409954071\n",
            "Epochs: 99, batch: 324 loss: 0.14614799618721008\n",
            "Epochs: 99, batch: 325 loss: 0.06214460730552673\n",
            "Epochs: 99, batch: 326 loss: 0.03605867177248001\n",
            "Epochs: 99, batch: 327 loss: 0.04352393373847008\n",
            "Epochs: 99, batch: 328 loss: 0.15224330127239227\n",
            "Epochs: 99, batch: 329 loss: 0.11304600536823273\n",
            "Epochs: 99, batch: 330 loss: 0.11440907418727875\n",
            "Epochs: 99, batch: 331 loss: 0.0794859305024147\n",
            "Epochs: 99, batch: 332 loss: 0.032945435494184494\n",
            "Epochs: 99, batch: 333 loss: 0.1669006645679474\n",
            "Epochs: 99, batch: 334 loss: 0.1561887264251709\n",
            "Epochs: 99, batch: 335 loss: 0.08737780153751373\n",
            "Epochs: 99, batch: 336 loss: 0.219038724899292\n",
            "Epochs: 99, batch: 337 loss: 0.08935265243053436\n",
            "Epochs: 99, batch: 338 loss: 0.12993532419204712\n",
            "Epochs: 99, batch: 339 loss: 0.07554894685745239\n",
            "Epochs: 99, batch: 340 loss: 0.18085166811943054\n",
            "Epochs: 99, batch: 341 loss: 0.11761859804391861\n",
            "Epochs: 99, batch: 342 loss: 0.2145601361989975\n",
            "Epochs: 99, batch: 343 loss: 0.1879168152809143\n",
            "Epochs: 99, batch: 344 loss: 0.06414071470499039\n",
            "Epochs: 99, batch: 345 loss: 0.17707614600658417\n",
            "Epochs: 99, batch: 346 loss: 0.10761308670043945\n",
            "Epochs: 99, batch: 347 loss: 0.10005827993154526\n",
            "Epochs: 99, batch: 348 loss: 0.049822062253952026\n",
            "Epochs: 99, batch: 349 loss: 0.05849180370569229\n",
            "Epochs: 99, batch: 350 loss: 0.23719772696495056\n",
            "Epochs: 99, batch: 351 loss: 0.16290247440338135\n",
            "Epochs: 99, batch: 352 loss: 0.0648026093840599\n",
            "Epochs: 99, batch: 353 loss: 0.09857936203479767\n",
            "Epochs: 99, batch: 354 loss: 0.09220705926418304\n",
            "Epochs: 99, batch: 355 loss: 0.07634942978620529\n",
            "Epochs: 99, batch: 356 loss: 0.07311403006315231\n",
            "Epochs: 99, batch: 357 loss: 0.07103107124567032\n",
            "Epochs: 99, batch: 358 loss: 0.06449779868125916\n",
            "Epochs: 99, batch: 1 loss: 0.12670384347438812\n",
            "Epochs: 99, batch: 2 loss: 0.04563214257359505\n",
            "Epochs: 99, batch: 3 loss: 0.1180562674999237\n",
            "Epochs: 99, batch: 4 loss: 0.0966237485408783\n",
            "Epochs: 99, batch: 5 loss: 0.10915857553482056\n",
            "Epochs: 99, batch: 6 loss: 0.10599850118160248\n",
            "Epochs: 99, batch: 7 loss: 0.13125497102737427\n",
            "Epochs: 99, batch: 8 loss: 0.14563944935798645\n",
            "Epochs: 99, batch: 9 loss: 0.10949815064668655\n",
            "Epochs: 99, batch: 10 loss: 0.021004032343626022\n",
            "Epochs: 99, batch: 11 loss: 0.09895337373018265\n",
            "Epochs: 99, batch: 12 loss: 0.04296502098441124\n",
            "Epochs: 99, batch: 13 loss: 0.21698948740959167\n",
            "Epochs: 99, batch: 14 loss: 0.023583615198731422\n",
            "Epochs: 99, batch: 15 loss: 0.08720482885837555\n",
            "Epochs: 99, batch: 16 loss: 0.19549259543418884\n",
            "Epochs: 99, batch: 17 loss: 0.08592996746301651\n",
            "Epochs: 99, batch: 18 loss: 0.08919946104288101\n",
            "Epochs: 99, batch: 19 loss: 0.08339478820562363\n",
            "Epochs: 99, batch: 20 loss: 0.26009857654571533\n",
            "Epochs: 99, batch: 21 loss: 0.03474501520395279\n",
            "Epochs: 99, batch: 22 loss: 0.0841028243303299\n",
            "Epochs: 99, batch: 23 loss: 0.10945667326450348\n",
            "Epochs: 99, batch: 24 loss: 0.10508111119270325\n",
            "Epochs: 99, batch: 25 loss: 0.22116822004318237\n",
            "Epochs: 99, batch: 26 loss: 0.12944641709327698\n",
            "Epochs: 99, batch: 27 loss: 0.1250162422657013\n",
            "Epochs: 99, batch: 28 loss: 0.06499706953763962\n",
            "Epochs: 99, batch: 29 loss: 0.07397855818271637\n",
            "Epochs: 99, batch: 30 loss: 0.19029462337493896\n",
            "Epochs: 99, batch: 31 loss: 0.1897771656513214\n",
            "Epochs: 99, batch: 32 loss: 0.1709471046924591\n",
            "Epochs: 99, batch: 33 loss: 0.05893261730670929\n",
            "Epochs: 99, batch: 34 loss: 0.19554679095745087\n",
            "Epochs: 99, batch: 35 loss: 0.08230898529291153\n",
            "Epochs: 99, batch: 36 loss: 0.09302391111850739\n",
            "Epochs: 99, batch: 37 loss: 0.1130039393901825\n",
            "Epochs: 99, batch: 38 loss: 0.10294300317764282\n",
            "Epochs: 99, batch: 39 loss: 0.0696517825126648\n",
            "Epochs: 99, batch: 40 loss: 0.1922239363193512\n",
            "Epochs: 99, batch: 41 loss: 0.09472231566905975\n",
            "Epochs: 99, batch: 42 loss: 0.10636787116527557\n",
            "Epochs: 99, batch: 43 loss: 0.07860222458839417\n",
            "Epochs: 99, batch: 44 loss: 0.03293696045875549\n",
            "Epochs: 99, batch: 45 loss: 0.07421612739562988\n",
            "Epochs: 99, batch: 46 loss: 0.05057854950428009\n",
            "Epochs: 99, batch: 47 loss: 0.11668959259986877\n",
            "Epochs: 99, batch: 48 loss: 0.18639317154884338\n",
            "Epochs: 99, batch: 49 loss: 0.10036434978246689\n",
            "Epochs: 99, batch: 50 loss: 0.061934396624565125\n",
            "Epochs: 99, batch: 51 loss: 0.15386377274990082\n",
            "Epochs: 99, batch: 52 loss: 0.06698598712682724\n",
            "Epochs: 99, batch: 53 loss: 0.1400793343782425\n",
            "Epochs: 99, batch: 54 loss: 0.176252543926239\n",
            "Epochs: 99, batch: 55 loss: 0.09868286550045013\n",
            "Epochs: 99, batch: 56 loss: 0.08220864832401276\n",
            "Epochs: 99, batch: 57 loss: 0.12027134001255035\n",
            "Epochs: 99, batch: 58 loss: 0.07313331961631775\n",
            "Epochs: 99, batch: 59 loss: 0.12674731016159058\n",
            "Epochs: 99, batch: 60 loss: 0.03840957581996918\n",
            "Epochs: 99, batch: 61 loss: 0.0430009663105011\n",
            "Epochs: 99, batch: 62 loss: 0.1156957745552063\n",
            "Epochs: 99, batch: 63 loss: 0.08588862419128418\n",
            "Epochs: 99, batch: 64 loss: 0.057456593960523605\n",
            "Epochs: 99, batch: 65 loss: 0.08084467798471451\n",
            "Epochs: 99, batch: 66 loss: 0.07375585287809372\n",
            "Epochs: 99, batch: 67 loss: 0.1177406832575798\n",
            "Epochs: 99, batch: 68 loss: 0.12445072084665298\n",
            "Epochs: 99, batch: 69 loss: 0.12063530087471008\n",
            "Epochs: 99, batch: 70 loss: 0.11182980239391327\n",
            "Epochs: 99, batch: 71 loss: 0.14685773849487305\n",
            "Epochs: 99, batch: 72 loss: 0.07850097119808197\n",
            "Epochs: 99, batch: 73 loss: 0.10553088039159775\n",
            "Epochs: 99, batch: 74 loss: 0.15246713161468506\n",
            "Epochs: 99, batch: 75 loss: 0.14700281620025635\n",
            "Epochs: 99, batch: 76 loss: 0.09004445374011993\n",
            "Epochs: 99, batch: 77 loss: 0.12860159575939178\n",
            "Epochs: 99, batch: 78 loss: 0.11272483319044113\n",
            "Epochs: 99, batch: 79 loss: 0.1108444556593895\n",
            "Epochs: 99, batch: 80 loss: 0.07910282164812088\n",
            "Epochs: 99, batch: 81 loss: 0.09854799509048462\n",
            "Epochs: 99, batch: 82 loss: 0.18112266063690186\n",
            "Epochs: 99, batch: 83 loss: 0.2378844916820526\n",
            "Epochs: 99, batch: 84 loss: 0.090024933218956\n",
            "Epochs: 99, batch: 85 loss: 0.08876344561576843\n",
            "Epochs: 99, batch: 86 loss: 0.06297080218791962\n",
            "Epochs: 99, batch: 87 loss: 0.05958782881498337\n",
            "Epochs: 99, batch: 88 loss: 0.03256247192621231\n",
            "Epochs: 99, batch: 89 loss: 0.05545542389154434\n",
            "Epochs: 99, batch: 90 loss: 0.03794940561056137\n",
            "Epochs: 99, batch: 91 loss: 0.2553761601448059\n",
            "Epochs: 99, batch: 92 loss: 0.12011804431676865\n",
            "Epochs: 99, batch: 93 loss: 0.08704088628292084\n",
            "Epochs: 99, batch: 94 loss: 0.11996259540319443\n",
            "Epochs: 99, batch: 95 loss: 0.1888393610715866\n",
            "Epochs: 99, batch: 96 loss: 0.261810839176178\n",
            "Epochs: 99, batch: 97 loss: 0.13127809762954712\n",
            "Epochs: 99, batch: 98 loss: 0.06205526366829872\n",
            "Epochs: 99, batch: 99 loss: 0.09693681448698044\n",
            "Epochs: 99, batch: 101 loss: 0.08749360591173172\n",
            "Epochs: 99, batch: 102 loss: 0.10982844233512878\n",
            "Epochs: 99, batch: 103 loss: 0.07057659327983856\n",
            "Epochs: 99, batch: 104 loss: 0.18486708402633667\n",
            "Epochs: 99, batch: 105 loss: 0.06813320517539978\n",
            "Epochs: 99, batch: 106 loss: 0.10112328827381134\n",
            "Epochs: 99, batch: 107 loss: 0.07845184206962585\n",
            "Epochs: 99, batch: 108 loss: 0.06903739273548126\n",
            "Epochs: 99, batch: 109 loss: 0.06768040359020233\n",
            "Epochs: 99, batch: 110 loss: 0.064496248960495\n",
            "Epochs: 99, batch: 111 loss: 0.1290682852268219\n",
            "Epochs: 99, batch: 112 loss: 0.06318139284849167\n",
            "Epochs: 99, batch: 113 loss: 0.18815231323242188\n",
            "Epochs: 99, batch: 114 loss: 0.05398331955075264\n",
            "Epochs: 99, batch: 115 loss: 0.08400475978851318\n",
            "Epochs: 99, batch: 116 loss: 0.051949869841337204\n",
            "Epochs: 99, batch: 117 loss: 0.18465574085712433\n",
            "Epochs: 99, batch: 118 loss: 0.09143620729446411\n",
            "Epochs: 99, batch: 119 loss: 0.06205890327692032\n",
            "Epochs: 99, batch: 120 loss: 0.22827452421188354\n",
            "Epochs: 99, batch: 121 loss: 0.16539663076400757\n",
            "Epochs: 99, batch: 122 loss: 0.1660982370376587\n",
            "Epochs: 99, batch: 123 loss: 0.12116958200931549\n",
            "Epochs: 99, batch: 124 loss: 0.15832971036434174\n",
            "Epochs: 99, batch: 125 loss: 0.13448643684387207\n",
            "Epochs: 99, batch: 126 loss: 0.1397152543067932\n",
            "Epochs: 99, batch: 127 loss: 0.16759110987186432\n",
            "Epochs: 99, batch: 128 loss: 0.06348767876625061\n",
            "Epochs: 99, batch: 129 loss: 0.15513013303279877\n",
            "Epochs: 99, batch: 130 loss: 0.11225063353776932\n",
            "Epochs: 99, batch: 131 loss: 0.24017006158828735\n",
            "Epochs: 99, batch: 132 loss: 0.05473506450653076\n",
            "Epochs: 99, batch: 133 loss: 0.06903277337551117\n",
            "Epochs: 99, batch: 134 loss: 0.052758000791072845\n",
            "Epochs: 99, batch: 135 loss: 0.05660875886678696\n",
            "Epochs: 99, batch: 136 loss: 0.13110503554344177\n",
            "Epochs: 99, batch: 137 loss: 0.11886642873287201\n",
            "Epochs: 99, batch: 138 loss: 0.10700458288192749\n",
            "Epochs: 99, batch: 139 loss: 0.20865407586097717\n",
            "Epochs: 99, batch: 140 loss: 0.06314976513385773\n",
            "Epochs: 99, batch: 141 loss: 0.09468650072813034\n",
            "Epochs: 99, batch: 142 loss: 0.06036606431007385\n",
            "Epochs: 99, batch: 143 loss: 0.05191819369792938\n",
            "Epochs: 99, batch: 144 loss: 0.04104406386613846\n",
            "Epochs: 99, batch: 145 loss: 0.08169814944267273\n",
            "Epochs: 99, batch: 146 loss: 0.16926710307598114\n",
            "Epochs: 99, batch: 147 loss: 0.11302933096885681\n",
            "Epochs: 99, batch: 148 loss: 0.21255767345428467\n",
            "Epochs: 99, batch: 149 loss: 0.14206266403198242\n",
            "Epochs: 99, batch: 150 loss: 0.12108476459980011\n",
            "Epochs: 99, batch: 151 loss: 0.05583317577838898\n",
            "Epochs: 99, batch: 152 loss: 0.07588781416416168\n",
            "Epochs: 99, batch: 153 loss: 0.14742085337638855\n",
            "Epochs: 99, batch: 154 loss: 0.19230681657791138\n",
            "Epochs: 99, batch: 155 loss: 0.20263688266277313\n",
            "Epochs: 99, batch: 156 loss: 0.12631119787693024\n",
            "Epochs: 99, batch: 157 loss: 0.06601658463478088\n",
            "Epochs: 99, batch: 158 loss: 0.07553169876337051\n",
            "Epochs: 99, batch: 159 loss: 0.05936317518353462\n",
            "Epochs: 99, batch: 160 loss: 0.1018761396408081\n",
            "Epochs: 99, batch: 161 loss: 0.11600296199321747\n",
            "Epochs: 99, batch: 162 loss: 0.09256455302238464\n",
            "Epochs: 99, batch: 163 loss: 0.08050503581762314\n",
            "Epochs: 99, batch: 164 loss: 0.14695215225219727\n",
            "Epochs: 99, batch: 165 loss: 0.06280166655778885\n",
            "Epochs: 99, batch: 166 loss: 0.0854296088218689\n",
            "Epochs: 99, batch: 167 loss: 0.26517295837402344\n",
            "Epochs: 99, batch: 168 loss: 0.06712031364440918\n",
            "Epochs: 99, batch: 169 loss: 0.06653864681720734\n",
            "Epochs: 99, batch: 170 loss: 0.21186092495918274\n",
            "Epochs: 99, batch: 171 loss: 0.17934919893741608\n",
            "Epochs: 99, batch: 172 loss: 0.08718787878751755\n",
            "Epochs: 99, batch: 173 loss: 0.045243896543979645\n",
            "Epochs: 99, batch: 174 loss: 0.07659227401018143\n",
            "Epochs: 99, batch: 175 loss: 0.059147611260414124\n",
            "Epochs: 99, batch: 176 loss: 0.1411534547805786\n",
            "Epochs: 99, batch: 177 loss: 0.08325545489788055\n",
            "Epochs: 99, batch: 178 loss: 0.07242638617753983\n",
            "Epochs: 99, batch: 179 loss: 0.15482687950134277\n",
            "Epochs: 99, batch: 180 loss: 0.08666236698627472\n",
            "Epochs: 99, batch: 181 loss: 0.028521990403532982\n",
            "Epochs: 99, batch: 182 loss: 0.13421553373336792\n",
            "Epochs: 99, batch: 183 loss: 0.11912001669406891\n",
            "Epochs: 99, batch: 184 loss: 0.037006814032793045\n",
            "Epochs: 99, batch: 185 loss: 0.05270608514547348\n",
            "Epochs: 99, batch: 186 loss: 0.08987082540988922\n",
            "Epochs: 99, batch: 187 loss: 0.1542869508266449\n",
            "Epochs: 99, batch: 188 loss: 0.06293800473213196\n",
            "Epochs: 99, batch: 189 loss: 0.03728887066245079\n",
            "Epochs: 99, batch: 190 loss: 0.19997552037239075\n",
            "Epochs: 99, batch: 191 loss: 0.17368900775909424\n",
            "Epochs: 99, batch: 192 loss: 0.06885389238595963\n",
            "Epochs: 99, batch: 193 loss: 0.02801559306681156\n",
            "Epochs: 99, batch: 194 loss: 0.08110617101192474\n",
            "Epochs: 99, batch: 195 loss: 0.0472634956240654\n",
            "Epochs: 99, batch: 196 loss: 0.22448699176311493\n",
            "Epochs: 99, batch: 197 loss: 0.11162581294775009\n",
            "Epochs: 99, batch: 198 loss: 0.13263212144374847\n",
            "Epochs: 99, batch: 199 loss: 0.09899310767650604\n",
            "Epochs: 99, batch: 201 loss: 0.28112655878067017\n",
            "Epochs: 99, batch: 202 loss: 0.06232403218746185\n",
            "Epochs: 99, batch: 203 loss: 0.07979552447795868\n",
            "Epochs: 99, batch: 204 loss: 0.1181957870721817\n",
            "Epochs: 99, batch: 205 loss: 0.05540775880217552\n",
            "Epochs: 99, batch: 206 loss: 0.141510471701622\n",
            "Epochs: 99, batch: 207 loss: 0.13162419199943542\n",
            "Epochs: 99, batch: 208 loss: 0.16120481491088867\n",
            "Epochs: 99, batch: 209 loss: 0.1638486385345459\n",
            "Epochs: 99, batch: 210 loss: 0.15509548783302307\n",
            "Epochs: 99, batch: 211 loss: 0.057562895119190216\n",
            "Epochs: 99, batch: 212 loss: 0.08877880871295929\n",
            "Epochs: 99, batch: 213 loss: 0.10197006911039352\n",
            "Epochs: 99, batch: 214 loss: 0.16052408516407013\n",
            "Epochs: 99, batch: 215 loss: 0.1915150135755539\n",
            "Epochs: 99, batch: 216 loss: 0.04236519709229469\n",
            "Epochs: 99, batch: 217 loss: 0.1128251850605011\n",
            "Epochs: 99, batch: 218 loss: 0.09245865046977997\n",
            "Epochs: 99, batch: 219 loss: 0.07900699973106384\n",
            "Epochs: 99, batch: 220 loss: 0.13133400678634644\n",
            "Epochs: 99, batch: 221 loss: 0.22091424465179443\n",
            "Epochs: 99, batch: 222 loss: 0.11234939098358154\n",
            "Epochs: 99, batch: 223 loss: 0.18374350666999817\n",
            "Epochs: 99, batch: 224 loss: 0.14460045099258423\n",
            "Epochs: 99, batch: 225 loss: 0.09947257488965988\n",
            "Epochs: 99, batch: 226 loss: 0.19417189061641693\n",
            "Epochs: 99, batch: 227 loss: 0.0819241851568222\n",
            "Epochs: 99, batch: 228 loss: 0.1309029757976532\n",
            "Epochs: 99, batch: 229 loss: 0.1707301139831543\n",
            "Epochs: 99, batch: 230 loss: 0.08527316153049469\n",
            "Epochs: 99, batch: 231 loss: 0.16847410798072815\n",
            "Epochs: 99, batch: 232 loss: 0.10114745050668716\n",
            "Epochs: 99, batch: 233 loss: 0.1325228065252304\n",
            "Epochs: 99, batch: 234 loss: 0.08801200985908508\n",
            "Epochs: 99, batch: 235 loss: 0.14353704452514648\n",
            "Epochs: 99, batch: 236 loss: 0.15397754311561584\n",
            "Epochs: 99, batch: 237 loss: 0.04485546424984932\n",
            "Epochs: 99, batch: 238 loss: 0.10400798171758652\n",
            "Epochs: 99, batch: 239 loss: 0.12217313051223755\n",
            "Epochs: 99, batch: 240 loss: 0.2167995572090149\n",
            "Epochs: 99, batch: 241 loss: 0.05891629308462143\n",
            "Epochs: 99, batch: 242 loss: 0.07437441498041153\n",
            "Epochs: 99, batch: 243 loss: 0.14814019203186035\n",
            "Epochs: 99, batch: 244 loss: 0.10432237386703491\n",
            "Epochs: 99, batch: 245 loss: 0.10908542573451996\n",
            "Epochs: 99, batch: 246 loss: 0.12626531720161438\n",
            "Epochs: 99, batch: 247 loss: 0.08406419306993484\n",
            "Epochs: 99, batch: 248 loss: 0.08896943926811218\n",
            "Epochs: 99, batch: 249 loss: 0.14616356790065765\n",
            "Epochs: 99, batch: 250 loss: 0.12144872546195984\n",
            "Epochs: 99, batch: 251 loss: 0.0977533608675003\n",
            "Epochs: 99, batch: 252 loss: 0.10874877870082855\n",
            "Epochs: 99, batch: 253 loss: 0.08889210224151611\n",
            "Epochs: 99, batch: 254 loss: 0.08276449143886566\n",
            "Epochs: 99, batch: 255 loss: 0.05060858279466629\n",
            "Epochs: 99, batch: 256 loss: 0.04351930692791939\n",
            "Epochs: 99, batch: 257 loss: 0.1496974229812622\n",
            "Epochs: 99, batch: 258 loss: 0.07455537468194962\n",
            "Epochs: 99, batch: 259 loss: 0.118939109146595\n",
            "Epochs: 99, batch: 260 loss: 0.05187796801328659\n",
            "Epochs: 99, batch: 261 loss: 0.2660980224609375\n",
            "Epochs: 99, batch: 262 loss: 0.14840412139892578\n",
            "Epochs: 99, batch: 263 loss: 0.11576137691736221\n",
            "Epochs: 99, batch: 264 loss: 0.31193065643310547\n",
            "Epochs: 99, batch: 265 loss: 0.14070262014865875\n",
            "Epochs: 99, batch: 266 loss: 0.10670837759971619\n",
            "Epochs: 99, batch: 267 loss: 0.2282169908285141\n",
            "Epochs: 99, batch: 268 loss: 0.17068569362163544\n",
            "Epochs: 99, batch: 269 loss: 0.1486664116382599\n",
            "Epochs: 99, batch: 270 loss: 0.1225976049900055\n",
            "Epochs: 99, batch: 271 loss: 0.04243557155132294\n",
            "Epochs: 99, batch: 272 loss: 0.05224539339542389\n",
            "Epochs: 99, batch: 273 loss: 0.053445689380168915\n",
            "Epochs: 99, batch: 274 loss: 0.19080118834972382\n",
            "Epochs: 99, batch: 275 loss: 0.07386858761310577\n",
            "Epochs: 99, batch: 276 loss: 0.07494812458753586\n",
            "Epochs: 99, batch: 277 loss: 0.1330537647008896\n",
            "Epochs: 99, batch: 278 loss: 0.12992408871650696\n",
            "Epochs: 99, batch: 279 loss: 0.12803001701831818\n",
            "Epochs: 99, batch: 280 loss: 0.12488548457622528\n",
            "Epochs: 99, batch: 281 loss: 0.06344084441661835\n",
            "Epochs: 99, batch: 282 loss: 0.09709575772285461\n",
            "Epochs: 99, batch: 283 loss: 0.034616440534591675\n",
            "Epochs: 99, batch: 284 loss: 0.13697177171707153\n",
            "Epochs: 99, batch: 285 loss: 0.2395986169576645\n",
            "Epochs: 99, batch: 286 loss: 0.08305646479129791\n",
            "Epochs: 99, batch: 287 loss: 0.10618528723716736\n",
            "Epochs: 99, batch: 288 loss: 0.24624967575073242\n",
            "Epochs: 99, batch: 289 loss: 0.12434297800064087\n",
            "Epochs: 99, batch: 290 loss: 0.1690039485692978\n",
            "Epochs: 99, batch: 291 loss: 0.08305545151233673\n",
            "Epochs: 99, batch: 292 loss: 0.0778818130493164\n",
            "Epochs: 99, batch: 293 loss: 0.07158169895410538\n",
            "Epochs: 99, batch: 294 loss: 0.08301503956317902\n",
            "Epochs: 99, batch: 295 loss: 0.20380675792694092\n",
            "Epochs: 99, batch: 296 loss: 0.16621309518814087\n",
            "Epochs: 99, batch: 297 loss: 0.09011541306972504\n",
            "Epochs: 99, batch: 298 loss: 0.07567476481199265\n",
            "Epochs: 99, batch: 299 loss: 0.09889417886734009\n",
            "Epochs: 99, batch: 301 loss: 0.042608294636011124\n",
            "Epochs: 99, batch: 302 loss: 0.09223126620054245\n",
            "Epochs: 99, batch: 303 loss: 0.22051694989204407\n",
            "Epochs: 99, batch: 304 loss: 0.05143657699227333\n",
            "Epochs: 99, batch: 305 loss: 0.29303106665611267\n",
            "Epochs: 99, batch: 306 loss: 0.14328643679618835\n",
            "Epochs: 99, batch: 307 loss: 0.0758223831653595\n",
            "Epochs: 99, batch: 308 loss: 0.08570922166109085\n",
            "Epochs: 99, batch: 309 loss: 0.06772289425134659\n",
            "Epochs: 99, batch: 310 loss: 0.190564826130867\n",
            "Epochs: 99, batch: 311 loss: 0.0750928670167923\n",
            "Epochs: 99, batch: 312 loss: 0.057395726442337036\n",
            "Epochs: 99, batch: 313 loss: 0.0681736022233963\n",
            "Epochs: 99, batch: 314 loss: 0.058047909289598465\n",
            "Epochs: 99, batch: 315 loss: 0.16567520797252655\n",
            "Epochs: 99, batch: 316 loss: 0.045737795531749725\n",
            "Epochs: 99, batch: 317 loss: 0.14997629821300507\n",
            "Epochs: 99, batch: 318 loss: 0.03698012977838516\n",
            "Epochs: 99, batch: 319 loss: 0.07850116491317749\n",
            "Epochs: 99, batch: 320 loss: 0.1069449856877327\n",
            "Epochs: 99, batch: 321 loss: 0.2746686637401581\n",
            "Epochs: 99, batch: 322 loss: 0.051573462784290314\n",
            "Epochs: 99, batch: 323 loss: 0.06205445155501366\n",
            "Epochs: 99, batch: 324 loss: 0.10702726244926453\n",
            "Epochs: 99, batch: 325 loss: 0.07241587340831757\n",
            "Epochs: 99, batch: 326 loss: 0.05632513016462326\n",
            "Epochs: 99, batch: 327 loss: 0.2012517750263214\n",
            "Epochs: 99, batch: 328 loss: 0.1070471853017807\n",
            "Epochs: 99, batch: 329 loss: 0.15852713584899902\n",
            "Epochs: 99, batch: 330 loss: 0.08440041542053223\n",
            "Epochs: 99, batch: 331 loss: 0.2230757772922516\n",
            "Epochs: 99, batch: 332 loss: 0.09054088592529297\n",
            "Epochs: 99, batch: 333 loss: 0.19282357394695282\n",
            "Epochs: 99, batch: 334 loss: 0.051796361804008484\n",
            "Epochs: 99, batch: 335 loss: 0.1298241913318634\n",
            "Epochs: 99, batch: 336 loss: 0.06180321052670479\n",
            "Epochs: 99, batch: 337 loss: 0.25176307559013367\n",
            "Epochs: 99, batch: 338 loss: 0.068519726395607\n",
            "Epochs: 99, batch: 339 loss: 0.044190652668476105\n",
            "Epochs: 99, batch: 340 loss: 0.06395348906517029\n",
            "Epochs: 99, batch: 341 loss: 0.06991279125213623\n",
            "Epochs: 99, batch: 342 loss: 0.14493528008460999\n",
            "Epochs: 99, batch: 343 loss: 0.13284850120544434\n",
            "Epochs: 99, batch: 344 loss: 0.10370603948831558\n",
            "Epochs: 99, batch: 345 loss: 0.15599867701530457\n",
            "Epochs: 99, batch: 346 loss: 0.22315126657485962\n",
            "Epochs: 99, batch: 347 loss: 0.08870238065719604\n",
            "Epochs: 99, batch: 348 loss: 0.08794791251420975\n",
            "Epochs: 99, batch: 349 loss: 0.1390886902809143\n",
            "Epochs: 99, batch: 350 loss: 0.2247937023639679\n",
            "Epochs: 99, batch: 351 loss: 0.06837938725948334\n",
            "Epochs: 99, batch: 352 loss: 0.202911376953125\n",
            "Epochs: 99, batch: 353 loss: 0.11957207322120667\n",
            "Epochs: 99, batch: 354 loss: 0.05399685353040695\n",
            "Epochs: 99, batch: 355 loss: 0.13382679224014282\n",
            "Epochs: 99, batch: 356 loss: 0.08853979408740997\n",
            "Epochs: 99, batch: 357 loss: 0.11289288103580475\n",
            "Epochs: 99, batch: 358 loss: 0.02080381102859974\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l-Ylx4bjRAr"
      },
      "source": [
        "# create dataset for lightgbm\n",
        "lgb_train = lgb.Dataset(df_X_train, df_y_train)\n",
        "lgb_eval = lgb.Dataset(df_X_val, df_y_val, reference=lgb_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55A5e36RiUE5"
      },
      "source": [
        "# specify your configurations as a dict\n",
        "params={}\n",
        "params['learning_rate']=0.03\n",
        "params['boosting_type']='gbdt' #GradientBoostingDecisionTree\n",
        "params['objective']='binary' #Binary target feature\n",
        "params['metric']='binary_logloss' #metric for binary classification\n",
        "params['max_depth']=10\n",
        "\n",
        "print('Starting training...')\n",
        "\n",
        "gbm = lgb.train(params,\n",
        "                lgb_train,\n",
        "                num_boost_round=20,\n",
        "                valid_sets=lgb_eval,\n",
        "                early_stopping_rounds=20)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1OAMPSL6YXc"
      },
      "source": [
        "# Validation with downsampleing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-S0TPLZi66G"
      },
      "source": [
        "print('Starting predicting...')\n",
        "# predict\n",
        "y_pred = gbm.predict(df_X_val, num_iteration=gbm.best_iteration)\n",
        "# eval\n",
        "print('auc:', roc_auc_score(df_y_val, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTGjxWm2jo-K"
      },
      "source": [
        "confusion_matrix(df_y_val, (y_pred > 0.5).astype(int))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN0JzEY40qVv"
      },
      "source": [
        "tn, fp, fn, tp  = confusion_matrix(df_y_val, (y_pred > 0.5).astype(int)).ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXKOn4_0syk"
      },
      "source": [
        "tn, fp, fn, tp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3dhXPwr5rJ6"
      },
      "source": [
        "# Testing : verify with real distribution data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOPN6XmD5t7U"
      },
      "source": [
        "X_test = pd.read_csv(\"./data/X_test.csv\")\n",
        "X_test = X_test.set_index(\"txkey\")\n",
        "y_test = pd.read_csv(\"./data/y_test.csv\")\n",
        "y_test = y_test.set_index(\"txkey\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOdAMGW8Lxm2",
        "outputId": "3cdd95c5-24d2-4eeb-aae2-cddb4f798c92"
      },
      "source": [
        "y_pred = net(torch.from_numpy(X_test.values).float().cuda()).detach().cpu().numpy()\n",
        "y_test = y_test.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQViPLvA59i4"
      },
      "source": [
        "\n",
        "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
        "y_test.mean()\n",
        "print('auc:', roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIGZq2CB6k3d",
        "outputId": "305024f5-9b96-4518-e628-694f81310243"
      },
      "source": [
        "cm = confusion_matrix(y_test, (y_pred > 0.5).astype(int), labels=[0,1])\n",
        "cm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[339736,  35639],\n",
              "       [   352,   4720]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtfsE_nfQ-fW",
        "outputId": "caa51b42-785e-477c-80f8-f282165e598a"
      },
      "source": [
        "th = .6\n",
        "print(\"precision_score\", precision_score(y_test,(y_pred > th).astype(int)))\n",
        "print(\"recall_score\",    recall_score(y_test,(y_pred > th).astype(int)))\n",
        "print(\"f1_score\",        f1_score(y_test,(y_pred > th).astype(int)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision_score 0.12348354698030924\n",
            "recall_score 0.9211356466876972\n",
            "f1_score 0.21777332370009556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xy9gmzoHmvx"
      },
      "source": [
        "#LGB\n",
        "precision, recall, thresholds = \\\n",
        "    precision_recall_curve(y_test,y_pred)\n",
        "average_precision = \\\n",
        "    average_precision_score(y_test,y_pred)\n",
        "\n",
        "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
        "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlim([0.0, 1.0])\n",
        "\n",
        "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
        "          average_precision))\n",
        "\n",
        "fpr, tpr, thresholds = \\\n",
        "    roc_curve(y_test,y_pred)\n",
        "areaUnderROC = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='r', lw=2, label='ROC curve')\n",
        "plt.plot([0, 1], [0, 1], color='k', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic: \\\n",
        "Area under the curve = {0:0.2f}'.format(areaUnderROC))\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtO1Kj2t5Igd"
      },
      "source": [
        "fnscore =  [ (fname,socre) for fname,socre in zip(gbm.feature_name(),gbm.feature_importance())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GWpVGv15wVs"
      },
      "source": [
        "top_feature = sorted(fnscore, key=lambda tup: tup[1], reverse=True)[:25]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LROaO45ebOaK"
      },
      "source": [
        "# Bias and Variance ，[參考資料1](https://machinelearningmastery.com/gentle-introduction-to-the-bias-variance-trade-off-in-machine-learning/), [參考資料二]\n",
        "* 一般來模型的 Bias 和 Variance 會呈現互斥的現像\n",
        "* 通常來說 Bias 越低，代表可能產生 Overfitting ，而 Overfitting 通常代表 Vairance 越高，其意義代表對於 Input 資料的敏感到越高。\n",
        "## How to Caculate the Model's Bias\n",
        "* Bias 的定義: Bias 是模型的預測(產出)的均值與實際值的差異(Bias is the difference between the mean of these estimates and the actual value.)\n",
        "* Model Bias Formula : $$ {1 \\over n}\\sum\\limits_{k=1}^n \\{{\\hat{y}-y_i}\\}^2 $$\n",
        "## How to Caculate the Model's Variance\n",
        "* Variance 定義：這與實際(y label)的 value 沒關係，而是這個組模型的穩定度，在不同 sub training set 所產出相對應的 model 對於 同一組 testing data 所預測(產出)的值的 variance .\n",
        "* Variance Defintion: Variance is the amount that the estimate of the target function will change if different training data was used.\n",
        "*  Model Variance Formula:$$ {1 \\over N}\\sum\\limits_{n=1}^N {1 \\over L}\\sum\\limits_{l=1}^l \\{{ y^l(x_n) -  \\bar{y}(x_n) }\\}^2 $$\n",
        "* N 為 testing data 的數(筆)量，L 將 training data 折成多少個 sub trainin set (N is the number of rows that is in testing set . L is the number of subset that is splited from all training set. )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajHqCt90j_7E"
      },
      "source": [
        "## 使用不同的模型來看 Bias 與 Variance 的變化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4FPhMdKj_XG"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(df_X_train,df_y_train)\n",
        "y_pred = lr.predict(X_test,)\n",
        "print('auc:', roc_auc_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1DzmED8qEuJ"
      },
      "source": [
        "df_X_train = df_X_train.reset_index(drop=True)\n",
        "df_y_train = df_y_train.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d90S2KJWqRmt"
      },
      "source": [
        "X_test = X_test.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRdg395Tqe5X"
      },
      "source": [
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TQHDDc6ly45"
      },
      "source": [
        "from mlxtend.evaluate import bias_variance_decomp\n",
        "lr = LogisticRegression()\n",
        "\n",
        "\n",
        "# first calculate all the statistical parameters before pruning\n",
        "mse_decision_tree, bias_decision_tree, var_decision_tree = bias_variance_decomp(lr,\n",
        "        df_X_train.to_numpy(), df_y_train.to_numpy(), X_test.to_numpy(), y_test.to_numpy(),\n",
        "        '0-1_loss', random_seed=123 )\n",
        "\n",
        "# random_seed : Used to initialize a pseudo-random\n",
        "# number generator for the bias-variance decomposition\n",
        "print('Original Bias from un-pruned data ', np.round(bias_decision_tree, 2))\n",
        "print('Original Variance from un-pruned data ', np.round(var_decision_tree, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNetGA-cp4-O"
      },
      "source": [
        "df_X_train.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}